{"meta":{"title":"CallMe_star","subtitle":"","description":"","author":"John Doe","url":"http://yoursite.com","root":"/callme-star.github.io/"},"pages":[{"title":"所有分类","date":"2020-08-16T15:23:21.601Z","updated":"2020-08-15T13:51:09.258Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"帮助过我的大佬们","date":"2020-08-16T15:23:12.282Z","updated":"2020-08-15T15:06:29.119Z","comments":true,"path":"friends/index.html","permalink":"http://yoursite.com/friends/index.html","excerpt":"","text":""},{"title":"About Me. || 关于我","date":"2020-08-18T15:00:56.008Z","updated":"2020-08-18T15:00:56.002Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"本人技术小白一个，刚刚入坑，望大家多指教。 搭建博客的目的就是为了有个自己的独立空间，记点学习笔记，记录自己的成长历程。 在接下来的时间里面我会慢慢更新一些java相关的学习经历，和后续的成果。 因为接下来主要学习图像处理和深度学习的相关内容，所以博客主旋律是图像和机器学习。 还请大佬们多多指教 123456#include&lt;iostream&gt;using nemespace std;int main()&#123; cout&lt;&lt;&quot;Hello world!&quot;&lt;&lt;&quot;\\n&quot;&lt;&lt;&quot;Hello every one!&quot;&#125; Hello world! Hello every one! Contact Me qq: 1024422413"},{"title":"所有分类","date":"2020-08-18T09:47:15.981Z","updated":"2020-08-15T14:47:15.240Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"福利图","date":"2020-08-16T15:24:09.000Z","updated":"2020-08-28T02:16:30.218Z","comments":true,"path":"福利图/index.html","permalink":"http://yoursite.com/%E7%A6%8F%E5%88%A9%E5%9B%BE/index.html","excerpt":"","text":"风景图 动漫 人物 汽车"}],"posts":[{"title":"matlab基础操作第二节","slug":"matlab基本操作2","date":"2020-08-26T10:54:19.489Z","updated":"2020-08-26T15:50:04.443Z","comments":true,"path":"2020/08/26/matlab基本操作2/","link":"","permalink":"http://yoursite.com/2020/08/26/matlab%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C2/","excerpt":"一、形态学操作&lt;1&gt;形态学基础","text":"一、形态学操作&lt;1&gt;形态学基础 上节记录了怎么用fspecial做滤波器（也就是掩膜），这次我们要生成的叫结构元素SE 主要用来构建形态学运算中的结构元素，使用的语法为strel(shape,parameters)。shape为形状参数，即设置什么样的结构元素；parameters为控制形状参数大小方向的参数。 就像上一节的滤波器我们也可以手动绘制，这一节的结构元素我们一样可以绘制，但是太过麻烦,下面举例子做一个正45°，长度为6的结构元素 12345678910SE = [0,0,0,0,0,1;0,0,0,0,1,0;0,0,0,1,0,0;0,0,1,0,0,0;0,1,0,0,0,0;1,0,0,0,0,0;]SE = 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 这样自己写太麻烦了，matlab为我们提供了一个函数，采用strel()函数则能够快速地构建如上所示的结构元素。 使用方法： SE = strel(‘arbitrary’,NHOOD) SE = strel(‘arbitrary’,NHOOD,HEIGHT) SE = strel(‘ball’,R,H,N) SE = strel(‘diamond’,R) SE = strel(‘disk’,R,N) SE = strel(‘line’,LEN,DEG) SE = strel(‘octagon’,R) SE = strel(‘pair’,OFFSET) SE = strel(‘periodicline’,P,V) SE = strel(‘rectangle’,MN) SE = strel(‘square’,W) 可以构建出各种形状的结构元素。 &lt;2&gt;下面我们开始用结构元素对图像进行膨胀腐蚀操作。123456img = imread(&#x27;.......jpg&#x27;);SE = strel(&#x27;ball&#x27;,20);dst1 = imdilate(img, SE);dst2 = imerode(img, SE);figure,imshow(dst1);figure,imshow(dst2); &lt;3&gt;顶帽变换，底帽变换","categories":[{"name":"matlab","slug":"matlab","permalink":"http://yoursite.com/categories/matlab/"}],"tags":[{"name":"matlab","slug":"matlab","permalink":"http://yoursite.com/tags/matlab/"}]},{"title":"matlab基础操作第一节","slug":"matlab基本操作1","date":"2020-08-25T01:59:22.132Z","updated":"2020-08-26T12:43:18.902Z","comments":true,"path":"2020/08/25/matlab基本操作1/","link":"","permalink":"http://yoursite.com/2020/08/25/matlab%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C1/","excerpt":"一、图像的读入与显示123img = imread(&#x27;图像在本地的地址.jpg&#x27;);figure(1),imshow(img);","text":"一、图像的读入与显示123img = imread(&#x27;图像在本地的地址.jpg&#x27;);figure(1),imshow(img); 以上就完成了最基本的图像读入与显示工作。但是为了操作简便我们经常不会对一个彩色图像进行处理，因为彩色图想有三个通道，会增加计算的复杂程度，所以我们第一步就是要对图像进行处理转换为灰度图像（简单地理解就是黑色和白色两种色彩的图像，只不过图像的黑和白的程度被细分成了256种不同程度的颜色）洗面我们来操作一下： 12img = imread(&#x27;图像在本地的地址.jpg&#x27;);img1 = rgb2gray(img); 如果单单对一个图片进行显示，那么我们就无法比较改变前后两个照片的细节上有什么差别，下面我们借用subplot函数，把两张或者多张图像显示在一个画布上： 123figure(2),subplot(1,2,1),imshow(img),title(&#x27;原图&#x27;)；subplot(1,2,2),imshow(img1),title(&#x27;灰度图&#x27;)； 二、相关函数调用1、把图像转换为二值图12345img = imread(&#x27;图像在本地的地址.jpg&#x27;);img1 = im2bw(img);figure,subplot(121),imshow(img);subplot(122),imshow(img1); 2、把一个对比度不清晰的图像转换成清晰的图像&lt;1&gt;下面用到两个函数imadjust()和stretchlim()①stretchlim函数是用来获取一个图像的最佳阈值分割矩阵的函数，将这个函数产生的矩阵直接带入下面的imadjust函数即可解决大部分对比度不清晰地问题 ②imadjust（）本来括号里面有四个参数（待处理的图像，待处理图像中的灰度范围，要装换到新图片中灰度被拉伸的区间，gamma） 举个例子imadjust(img, [0,1], [1,0], 1) 就是把原图中[0,1]灰度范围内的灰度以一定的映射规则转换到[1,0]内，也就是实现了一个灰度翻转，这个例子实现的功能跟一个函数类似Jmcomplement(); 123456img = imread(&#x27;图像在本地的地址.jpg&#x27;);img = rgb2gray(img);dst = imcomplement(img)figure,subplot(121),imshow(img);subplot(122),imshow(dst); gamma用来规定映射的规则，如图所示，gamma以1为界限，大于1的时候把灰度较高的部分拉伸的很长，相当于把图像中亮度较高的部分，灰度分配到了【0，255】范围内，因此我们可以看到更多光亮部分的细节，相反就能看到较暗部分的细节 123456789101112img = imread(&#x27;图像在本地的地址.jpg&#x27;);img = rgb2gray(img);%下面用到两个函数imadjust（）和strtchlim()h = stretchlim(img);dst = imgadjust(img,h,[])% 其中的[]是对图像对比度进行加深，让现实的图像是我们想象中的样子figure，subplot(221),imshow(img);subplot(222),imshow(dst);%下面用imhist函数看一下整幅图片的灰度分布图subplot(223),imhist(img),title(&#x27;原图灰度&#x27;);subplot(224),imhist(dst),title(&#x27;变换后的灰度&#x27;); &lt;2&gt;histeq()这个函数也是把图像进行一下智能的直方图均衡化，将对比度差的图像转换成能看到细节的图像 123456img = imread(&#x27;图像在本地的地址.jpg&#x27;);img = rgb2gray(img);dst = histeq(img);figure,subplot(121),imshow(dst);subplot(122),imhist(dst); 3、调用函数对图像进行去噪，求边缘等等①首先我们先认识一个函数medfilt2()123456789img = imread(&#x27;图像在本地的地址.jpg&#x27;);img = rgb2gray(img);%先用一个函数给一个图像加入椒盐噪声%或者还可以加高斯噪声imnoise(img,&#x27;guassian&#x27;, 0.02)img1=imnoise(img,‘salt &amp; pepper’,0.02) img2 = medfilt2(img1, [3,3]);figure,subplot(121),imshow(img1);subplot(122),imshow(img2); ②fspecial（）和imfilter（）fspecial()是用来做滤波器的他可以做出各种类型的滤波器 Fspecial(‘滤波器名字’，hesize，sigma) 均值滤波器：h = fspecial(‘average’,5) 高斯滤波器：h = fspecial(‘gaussian’,5) 拉普拉斯滤波器：h = fspecial(‘laplacian’) 拉普拉斯高斯：h = fspecial(‘log’,3,0.2) sobel边缘提取：h = fspecial(‘sobel’) imfilter()是用来滤波的imfilter（A, h, filtermode,boundary,size） 其中A是待处理图像 h是上边生成的滤波器 filtermode是滤波类型包括‘corr’即相关，还有‘conv’即卷积 boundary是边界补全的方式：有‘X’ 输入图像的边界通过用值X（无引号）来填充扩展 其默认值为0，‘repliacate’图像大小通过复制外边界的值来扩展，‘symmetric’图像大小通过镜像反射其边界来扩展，‘circular’图像大小通过将图像看成是一个二维周期函数的一个周期来扩展 size指的是：输出图像的大小，有‘same’和‘full’ 123456img = imread(&#x27;peppers.png&#x27;);h = fspecial(&#x27;average&#x27;);%创建一个滤波器dst = imfilter(img, h, &#x27;conv&#x27;, &#x27;replicate&#x27;,&#x27;same&#x27;);figure, imshow(img);imshow(dst);","categories":[{"name":"matlab","slug":"matlab","permalink":"http://yoursite.com/categories/matlab/"}],"tags":[{"name":"matlab","slug":"matlab","permalink":"http://yoursite.com/tags/matlab/"}]},{"title":"图像分割","slug":"图像处理——图像分割","date":"2020-08-25T01:58:50.359Z","updated":"2020-08-25T12:11:12.630Z","comments":true,"path":"2020/08/25/图像处理——图像分割/","link":"","permalink":"http://yoursite.com/2020/08/25/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/","excerpt":"一、图像分割分类按着先进程度分 传统分割方法 ①阈值分割","text":"一、图像分割分类按着先进程度分 传统分割方法 ①阈值分割 阈值法的基本思想是基于图像的灰度特征来计算一个或多个灰度阈值，并将图像中每个像素的灰度值与阈值作比较，最后将像素根据比较结果分到合适的类别中。因此，该方法最为关键的一步就是按照某个准则函数来求解最佳灰度阈值。阈值法特别适用于目标和背景占据不同灰度级范围的图。 ②基于区域的分割 基于区域的分割方法是以直接寻找区域为基础的分割技术，基于区域提取方法有两种基本形式：一种是区域生长，从单个像素出发，逐步合并以形成所需要的分割区域；另一种是从全局出发，逐步切割至所需的分割区域。 ③基于边缘检测的分割 小波变换是近年来得到的广泛应用的数学工具，也是现在数字图像处理必学部分，它在时间域和频率域上都有量高的局部化性质，能将时域和频域统一于一体来研究信号。而且小波变换具有多尺度特性，能够在不同尺度上对信号进行分析，因此在图像分割方面的得到了应用，而且小波变换具有检测二元函数的局部突变能力，因此可作为图像边缘检测工具。图像的边缘出现在图像局部灰度不连续处，对应于二进小波变换的模极大值点。通过检测小波变换模极大值点可以确定图像的边缘小波变换位于各个尺度上，而每个尺度上的小波变换都能提供一定的边缘信息，因此可进行多尺度边缘检测来得到比较理想的图像边缘。 深度学习分割①VGGNet ②FCN(Fully Convolutional Networks ) DeepLab DeconvNet SegNet PSPNet(Pyramid Scene Parsing Network) Mask-RCNN 按分割目的划分普通分割将不同分属不同物体的像素区域分开。如前景与后景分割开，狗的区域与猫的区域与背景分割开。 语义分割在普通分割的基础上，分类出每一块区域的语义（即这块区域是什么物体）。如把画面中的所有物体都指出它们各自的类别。 实例分割在语义分割的基础上，给每个物体编号。如这个是该画面中的狗A，那个是画面中的狗B。 二、基于深度学习分割&lt;1&gt;基于特征编码在特征提取领域中VGGnet和ResNet是两个非常有统治力的方法，接下来的一些篇幅会对这两个方法进行简短的介绍 VGGNet由牛津大学计算机视觉组合和Google DeepMind公司研究员一起研发的深度卷积神经网络。它探索了卷积神经网络的深度和其性能之间的关系，通过反复的堆叠3×3的小型卷积核和2×2的最大池化层，成功的构建了16~19层深的卷积神经网络。VGGNet获得了ILSVRC 2014年比赛的亚军和定位项目的冠军，在top5上的错误率为7.5%。目前为止，VGGNet依然被用来提取图像的特征。​ VGGNet的优缺点 ①由于参数量主要集中在最后的三个FC（全连接层）当中，所以网络加深并不会带来参数爆炸的问题； ②多个小核卷积层的感受野等同于一个大核卷积层（三个3x3等同于一个7x7）但是参数量远少于大核卷积层而且非线性操作也多于后者，使得其学习能力较强 ③VGG由于层数多而且最后的三个全连接层参数众多，导致其占用了更多的内存（140M） ResNet 随着深度学习的应用，各种深度学习模型随之出现，虽然在每年都会出现性能更好的新模型，但是对于前人工作的提升却不是那么明显，其中有重要问题就是深度学习网络在堆叠到一定深度的时候会出现梯度消失的现象，导致误差升高效果变差，后向传播时无法将梯度反馈到前面的网络层，使得前方的网络层的参数难以更新，训练效果变差。这个时候ResNet恰好站出来，成为深度学习发展历程中一个重要的转折点。​ ResNet是由微软研究院的Kaiming He等四名华人提出，他们通过自己提出的ResNet Unit成功训练出来152层的神经网络并在ILSVRC2015比赛中斩获冠军。ResNet语义分割领域最受欢迎且最广泛运用的神经网络.ResNet的核心思想就是在网络中引入恒等映射，允许原始输入信息直接传到后面的层中，在学习过程中可以只学习上一个网络输出的残差（F(x)），因此ResNet又叫做残差网络。、使用到ResNet的分割模型： Efficient Neural Network（ENet）：该网络类似于ResNet的bottleNeck方法； ResNet-38：该网络在训练or测试阶段增加并移除了一些层，是一种浅层网络，它的结构是ResNet+FCN； full-resolution residual network(FRRN)：FRRN网络具有和ResNet相同优越的训练特性，它由残差流和池化流两个处理流组成； AdapNey：根据ResNet-50的网络进行改进，让原本的ResNet网络能够在更短的时间内学习到更多高分辨率的特征；……ResNet的优缺点：1）引入了全新的网络结构（残差学习模块），形成了新的网络结构，可以使网络尽可能地加深；2）使得前馈/反馈传播算法能够顺利进行，结构更加简单；3）恒等映射地增加基本上不会降低网络的性能；4）建设性地解决了网络训练的越深，误差升高，梯度消失越明显的问题；5）由于ResNet搭建的层数众多，所以需要的训练时间也比平常网络要长。 &lt;2&gt;基于区域选择Regional proposal 在计算机视觉领域是一个非常常用的算法，尤其是在目标检测领域。其核心思想就是检测颜色空间和相似矩阵，根据这些来检测待检测的区域。然后根据检测结果可以进行分类预测。在语义分割领域，基于区域选择的几个算法主要是由前人的有关于目标检测的工作渐渐延伸到语义分割的领域的。其大致经过了以下几个阶段： ①R-CNN是首个开创性地将深度神经网络应用到目标检测的算法，由于进行特征提取时是串行，处理耗时过长。 ②Fast R-CNN节省了串行提取特征的时间. ③Faster R-CNN使用RPN替换了耗时的selective search算法，对整个网络结构有了突破性的优化；Faster R-CNN中使用的RPN和selective search比起来虽然速度更快，但是精度和selective search相比稍有不及，如果更注重速度而不是精度的话完全可以只使用RPN； ④Mask R-CNN是何恺明大神团队提出的一个基于Faster R-CNN模型的一种新型的分割模型，此论文斩获ICCV 2017的最佳论文，在Mask R-CNN的工作中，它主要完成了三件事情：目标检测，目标分类，像素级分割。 ⑤Mask Scoring R-CNN恺明大神的Mask R-CNN已经很好啦！但是有个小毛病，就是评价函数只对目标检测的候选框进行打分，而不是分割模板（就是上文提到的优缺点中最后一点），所以会出现分割模板效果很差但是打分很高的情况。所以黄同学增加了对模板进行打分的MaskIoU Head，并且最终的分割结果在COCO数据集上超越了恺明大神，下面就是MS R-CNN的网络结构啦~ &lt;3&gt;基于RNN的图像分割①ReSeg模型②MDRNNs模型（Multi-Dimensional Recurrent Neural Networks）&lt;4&gt;基于上采样/反卷积的分割方法卷积神经网络在进行采样的时候会丢失部分细节信息，这样的目的是得到更具特征的价值。但是这个过程是不可逆的，有的时候会导致后面进行操作的时候图像的分辨率太低，出现细节丢失等问题。因此我们通过上采样在一定程度上可以补全一些丢失的信息，从而得到更加准确的分割边界。接下来介绍几个非常著名的分割模型： FCN在图像分割领域已然成为一个业界标杆，大多数的分割方法多多少少都会利用到FCN或者其中的一部分，比如前面我们讲过的Mask R-CNN。在FCN当中的反卷积-升采样结构中，图片会先进性上采样（扩大像素）；再进行卷积——通过学习获得权值。FCN的网络结构如下图所示：优缺点： FCN对图像进行了像素级的分类，从而解决了语义级别的图像分割问题； FCN可以接受任意尺寸的输入图像，可以保留下原始输入图像中的空间信息； 得到的结果由于上采样的原因比较模糊和平滑，对图像中的细节不敏感； 对各个像素分别进行分类，没有充分考虑像素与像素的关系，缺乏空间一致性。 SegNet SegNet是剑桥提出的旨在解决自动驾驶或者智能机器人的图像语义分割深度网络，SegNet基于FCN，与FCN的思路十分相似，只是其编码-解码器和FCN的稍有不同，其解码器中使用去池化对特征图进行上采样，并保持高频细节的完整性；而编码器不使用全连接层，因此是拥有较少参数的轻量级网络。 SetNet的优缺点： 保存了高频部分的完整性； 网络不笨重，参数少，较为轻便； 对于分类的边界位置置信度较低； 对于难以分辨的类别，例如人与自行车，两者如果有相互重叠，不确定性会增加。以上两种网络结构就是基于反卷积/上采样的分割方法，当然其中最最最重要的就是FCN了，哪怕是后面大名鼎鼎的SegNet也是基于FCN架构的，而且FCN可谓是语义分割领域中开创级别的网络结构。 &lt;5&gt;基于提高特征分辨率的分割方法DeepLabGoogle提出的DeepLab ,DeepLab有v1 v2 v3，第一篇名字叫做DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs。这一系列论文引入了以下几点比较重要的方法： 第一个是带洞卷积，英文名叫做Dilated Convolution，或者Atrous Convolution。带洞卷积实际上就是普通的卷积核中间插入了几个洞，如下图。 它的运算量跟普通卷积保持一样，好处是它的“视野更大了”，比如普通3x3卷积的结果的视野是3x3，插入一个洞之后的视野是5x5。视野变大的作用是，在特征图缩小到同样倍数的情况下可以掌握更多图像的全局信息，这在语义分割中很重要。 解决了DCNN的几个关于分辨率的问题：1）内部数据结构丢失；空间曾计划信息丢失；2）小物体信息无法重建；当然空洞卷积也存在一定的问题，它的问题主要体现在以下两方面：1）网格效应加入我们仅仅多次叠加dilation rate 2的 3x3 的卷积核则会出现以下问题我们发现卷积核并不连续，也就是说并不是所有的像素都用来计算了，这样会丧失信息的连续性；2）小物体信息处理不当我们从空洞卷积的设计背景来看可以推测出它是设计来获取long-ranged information。然而空洞步频选取得大获取只有利于大物体得分割，而对于小物体的分割可能并没有好处。所以如何处理好不同大小物体之间的关系也是设计好空洞卷积网络的关键。 &lt;6&gt;基于特征增强的分割方法PSPNet(全局金字塔池化) 类似于我们那节课讲的sift算子：为了捕捉多尺度特征，高层特征包含了更多的语义和更少的位置信息。结合多分辨率图像和多尺度特征描述符的优点，在不丢失分辨率的情况下提取图像中的全局和局部信息，这样就能在一定程度上提升网络的性能 以上均摘自下面两篇博客： WeisongZhao 计算机视觉life","categories":[{"name":"图像处理笔记","slug":"图像处理笔记","permalink":"http://yoursite.com/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"图像处理笔记","slug":"图像处理笔记","permalink":"http://yoursite.com/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/"}]},{"title":"tensorflow第三节","slug":"tensorflow3","date":"2020-08-21T01:31:13.025Z","updated":"2020-08-25T01:57:44.847Z","comments":true,"path":"2020/08/21/tensorflow3/","link":"","permalink":"http://yoursite.com/2020/08/21/tensorflow3/","excerpt":"学习目标 预备知识 神经复杂度 指数衰减学习率","text":"学习目标 预备知识 神经复杂度 指数衰减学习率 激活函数 损失减数 欠拟合和过拟合 正则化减少过拟合 优化器更新网络参数 预备知识 tf.where() tf.where(条件语句，真返回A，假返回B) 1234a = tf.constant([1,2,3,1,1])b = tf.constant([0,1,3,4,5])c = tf.where(tf.greater(a,b),a,b) #若a&gt;b,返回a对应位置的元素，否则返回b对应位置的元素print(c) tf.random.RandomState.rand() tf.random.RandomState.rand(维度) 123456import numpya as nprdm = np.random.RandomState(seed=1) #seed相同生成的随机数相同a = rdm.rand() #返回一个随机标量b = rdm.rand(2,3) #返回一个两行三列的随机矩阵print(a)print(b) tf.vstack() 将两个数组按垂直方向叠加 np.vstack(数组1，数组2) 1234import numpy as npa = np.array([1,2,3])b = np.array([4,5,6])c = vstack(&#x27;c为：&#x27;，c) np.mgrid[] , .ravel() , np.c_[] 用来制表 np.mgrid[起始值，结束值，步长] x.ravel() 将x变为一维数组，把变量拉直 np.c_[数组1， 数组2] 将两个数组进行配对，补成一个大数组 123456import numpy as npx,y = np.mgrid[1:3:1, 2:4:0.5]grid = np.c_[x.ravel(),y.ravelz()]print(x)print(y)print(grid) 复杂度学习率在上节课中我们发现$$在式子中：w_{t+1} = w_t-lr*\\frac{\\partial loss}{\\partial w_t}$$ $$损失函数: loss = (w+1)^2$$ $$\\frac{\\partial loss}{\\partial w} = 2w+2$$ 参数w初始为5，学习率为若是太小则整个过程更新太慢，如果太大就会越过极值点，导致最后结果不收敛，在极值点附近跳跃。 在应用中可以通过指数衰减学习率来实现： 指数衰减学习率：先用较大的学习率，快速得到较优解，然后逐步减小学习率，使模型在训练后期稳定 $$指数衰减学习率 = 初始学习率*学习率衰减率^{(当前轮次/多少轮衰减一次)}$$ 123456789101112epoch = 40lr_base = 0.2 #初始学习率lr_decay = 0.99 #学习率衰减率lr_step = 1 #多少轮衰减一次 for epoch in range(epoch): lr = lr_base *lr_decay**(epoch / lr _step) with tf.Gradient() as tape: loss = tf.square(w+1) grads = tape.gradient(loss, w) w.assign_sub(lr*grads) print(&quot;after %s epoch, w is %f, loss is %5f, lr = %f&quot; % (epoch, w.numpy(), loss(), lr) 激活函数 下面介绍几种常用的激活函数 sigmoid函数$$f(x)= \\frac{1}{1+e^{-x}}$$特点:①因为需要反向求导，会造成梯度消失问题，使得参数无法更新 ​ ②输出非0均值，收敛慢 ​ ③幂运算复杂，训练时间长 tanh$$f(x) = \\frac{1-e^{-2x}}{1+e^{-2x}}$$特点：①输出是0均值 ​ ②易造成梯度消失 ​ ③幂运算复杂，训练时间长 Relu$$f(x) = max(x,0)\\$$ $$=\\begin{cases}0, x&lt;0\\x, x&gt;=0\\end{cases}$$优点： ①解决了梯度消失问题（在正区间） ②只需判断输入是否大于零，计算速度快 ③收敛速度远快于sigmoid和tanh 缺点： ①输出非零均值，收敛慢 ②某些神经元可能永远不会被激活，导致相应参数永远不更新 Leaky Relu 是对Relu在负区间上的改进$$f(x) = max(ax,x)$$理论上来讲，leaky relu有relu的所有优点，外加不会产生死神经元的问题，但是实际操作中，并没有完全证明他总是好于relu 对初学者的建议： 首选relu函数 学习率设置较小值 输入特征标准化，即让输入特征满足以零为均值，1为标准差的正态分布 $$初始函数中心化，即让随机生成的参数满足以零为均值，\\sqrt{\\frac{2}{当前输入特征个数}}为标准差的正态分布$$ 损失函数损失函数用来评价模型的预测值和真实值不一样的程度，损失函数越好，通常模型的性能越好。不同的模型用的损失函数一般也不一样。 损失函数分为经验风险损失函数和结构风险损失函数。经验风险损失函数指预测结果和实际结果的差别，结构风险损失函数是指经验风险损失函数加上正则项。 均方误差：$$MSE(y_均-y) = \\frac{\\sum_{i = 1}^{n}(y-y_均)^2}{n}$$loss_mean = tf.reduce_mean(tf.sqare(y-y_)) 自定义损失函数$$loss(y_均,y) = \\begin{cases}profit*(y_均 - y), y&lt;y_均\\cost*(y-y_均)， y&gt;y_均\\end{cases}$$ 1Loss = tf.reduce_sum(tf.where:(tf,greater(y,y_均),cost(y,y_均), profit(y,y_均))) 交叉熵损失函数 交叉熵损失函数CE表征两个概率分布之间的距离，原本的公式$$H（y_均，y） = -\\sum{y_均*lny}$$tensorflow有直接的公式： 1tf.losses.categorical_crossentropy(y_均,y) 一般我们要经过softmax函数然后计算y与y_的交叉熵损失函数 123456789101112tf.nn.softmax_cross_entropy_with_logits(y_,y)#下面用两种方式都进行运算y_ = np.array([[1,0,0],[0,0,1],[1,0,0],[0,1,0]])y = np.array([[12,3,2],[3,10,1],[1,2,5],[4,6.5,1.2],[3,6,1]])y_pro = tf.nn.softmax(y)loss_ce1 = tf.losses.categorical_crossentropy(y_,y_pro)loss_se2 = tf.nn.softmax_cross_entropy_with_logits(y_,y)print(&#x27;分布计算的结果&#x27;, loss_se1)print(&#x27;结合计算的结果&#x27;, loss_se2) 欠拟合和过拟合欠拟合图像不能有效表示出坐标点，而过拟合因为对一种情况过于细节，在另外的样本来临可能会很不准确，存在一个泛化性差的特点。 欠拟合的解决方法： ①增加输入特征项 ②增加网络参数 ③减少正则化参数 过拟合的解决方法： ①数据清洗 ②增大训练集 ③采用正则化 ④增大正则化参数 正则化缓解过拟合： 正则化在损失函数中引入模型复杂度指标，利用给w加权值，强化了训练数据的噪声（一般不正则化b，只对权重正则化）$$loss = loss(y与y_均) + REGULARIZER*loss(w)$$其中的REGULARIZER给出了w在总loss中的比例，即正则化的权重。","categories":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://yoursite.com/categories/TensorFlow/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://yoursite.com/tags/TensorFlow/"}]},{"title":"tensorflow第二节","slug":"tensorflow2","date":"2020-08-19T08:42:30.801Z","updated":"2020-08-25T01:57:16.707Z","comments":true,"path":"2020/08/19/tensorflow2/","link":"","permalink":"http://yoursite.com/2020/08/19/tensorflow2/","excerpt":"鸢尾花分类三种鸢尾花，有四种特征，四个数据同时输入，权重共有3*4=12组, [1,4]✖️[4,3]","text":"鸢尾花分类三种鸢尾花，有四种特征，四个数据同时输入，权重共有3*4=12组, [1,4]✖️[4,3] 鸢尾花数据读入从sklearn包dataset读入数据集，语法为： from sklearn.datasets import load_iris x_data = datasets.load_isis().data y_data = datasets.load_isis().target 1234567891011121314from sklearn import datasetsfrom pandas import DataFrameimport pandas as pdx_data = datasets.load_isis().data #.data返回数据集的输入特征y_data = datasets.load_isis().target # 。target返回数据集的所有标签print(x_data)print(y_data)x_data = DataFrame(x_data,columes=[&quot;花萼长&quot;，&quot;花萼宽&quot;，&quot;花瓣长&quot;，&quot;花瓣宽&quot;]) # 将数据转换成表格形式pd.set_option(&#x27;display.unicode.east_asian_width&#x27;,True) #设置列名对齐print(&quot;x_data add index: \\n&quot;,x_data)x_data[&#x27;类别&#x27;] = y_data #新增加一列，标签为类别，数据为y_dataprint(&quot;x_data add a colum: \\n&quot;,x_data) 在运行过程中会提示我们缺少数据包，然后我们用python自带的pip下载安装即可（比如：pip install sklearn） 神经网络实现鸢尾花分类 1、准备数据 数据集读入 数据集乱序 12345np.random.seed(116) #使用相同的seed使输入特征标签一一对应np.random.shuffle（x_data）np.random.seed(116)np.random.shuffle(y_data)tf.random.set_seed(116) 数据集分出永不相见的训练集和测试集 训练集为前120行，测试集为最后30行 1234x_train = x_data[:-30]y_train = y_data[:-30]x_test = x_data[-30:]y_test = y_data[-30:] 配成【输入特征， 标签】对，每次喂入一小撮（batch） 每32组数据打包成一个batch 12train_db = tf.data.Dataset.from_tensor_slice((x_train,y_train)).batch(32)test_db = tf.data.Dataset.from_tensor_slice((x_train,y_train)).batch(32) 搭建网络 定义神经网络中所有可训练参数 12w1 = tf.Variable(tf.random.truncated_normal([4,3],stddev = 0, seed =1))b1 = tf.Variable(tf.random.truncated_normal([3],stddev=0.1,seed=1)) 参数优化 嵌套循环迭代，with结构更新参数，显示当前loss 123456789101112131415for epoch in range(epoch): #数据集级别迭代 for step,(x_train,y_train) in enumerate(train_db): with tf.GradientTape() as tape: #记录梯度信息 #向前传播过程计算y #计算总的loss y = tf.matmul(x_train,w1)+b1 #神经网络乘加运算 y = tf.nn.softmax(y) #使输出y符和概率分布，此操作后和独热码同量级 y_ = tf.one_hot(y_train，depth = 3) #将标签转换为独热码形式 loss = tf.reduce_mean(tf.quare(y_-y)) loss_all += loss.numpy() grads = tap.gradient(loss.[w1,b1]) #计算loss对各个参数的梯度 #实现梯度的更新：w1=w1-lr*w1_grad, b1= b1-lr*b_grad w1.assign_sub(lr*grads[0]) #参数自更新 b1.assign_sub(lr*grads[1]) #其中的lr是学习率 print(&quot;Epoch &#123;&#125;,loss:&#123;&#125;&quot;.format(epoch,loss_all/4)) 测试效果 计算当前参数向前传播后的准确率，显示当前acc 1234567891011for x_test,y_test in test_db: y = tf.matmul(h,w)+b #y为预测结果 y = tf.nn.softmax(y) #是结果符合概率分布 pred= tf.argmax(y,axis=1) #返回y中最大值的索引，即预测的分类 pred= tf.case(pred,dtype=y_type.dtype) #调整数据类型，与标签一致 correct = tf.cast(tf.equal(pred,y_test),dtype = tf.int32) correct = tf.reduce_sum(correct) #将每个batch的correct数加起来 total_correct += int(correct) #将所有batch中的correct数加起来 total_number +=x_test.shape[0]acc = total_correct/total_numberprint(&quot;test_acc:&quot;, acc) acc/loss 可视化 123456plt.title(&quot;acc curve&quot;) #图片标题plt.xlabel(&quot;epoch&quot;) # x轴名字plt,ylabel(&quot;acc&quot;) #y轴名字plt.plot(test_acc,label=&quot;$Accuracy$&quot;) #逐点画出test_acc值并连线plt.legend()plt.show() 本文先对代码的整个大体流程有一个感性的认识，详细过程，下面会有讲解！","categories":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://yoursite.com/categories/TensorFlow/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://yoursite.com/tags/TensorFlow/"}]},{"title":"tensorflow第一节","slug":"tensorflow1","date":"2020-08-19T07:07:25.305Z","updated":"2020-08-25T01:57:02.802Z","comments":true,"path":"2020/08/19/tensorflow1/","link":"","permalink":"http://yoursite.com/2020/08/19/tensorflow1/","excerpt":"常用函数1、类型转换 强制tensor转换为该数据类型 tf.case(张量名, dtype=数据类型)","text":"常用函数1、类型转换 强制tensor转换为该数据类型 tf.case(张量名, dtype=数据类型) 计算张量维度上元素的最小值 tf.reduce_min(张量名) 计算张量维度上元素的最大值 tf.reduce_max(张量名) 12345x1 = tf.constant([1., 2., 3.], dtype = tf.float64)print(x1)x2 = tf.case(x1, tf.int32)print(x2)print(tf.reduce_min(x2), tf.reduce_max(x2)) 运行结果： 1234tf.Tensor([1.2.3.], shape = (3,), dtype = float64)tf.Tensor([1 2 3], shape = (3,), dtype = int32)tf.Tensor(1, shape = (), dtype = int32)tf.Tensor(3, shape = (), dtype = int32) 2、理解axis在一个二维向量中axis=0代表以列为单位求取最大值，axis代表以行为单位求取最大值，如果不指定，则所有元素都参与运算 计算张量沿着指定维度的平均值 tf.reduce_mean(张量名, axis=操作轴) 计算张量沿着指定维度的和 tf.reduce_sum(张量名, axis=操作轴) 1234x = tf.constant([[1, 2, 3], [2, 2, 3]])print(x)print(tf.reduce_mean(x))print(tf.reduce_sum(x,axis=1)) 3、运算 将变量标记为可训练 tf.Variable（初始值） 1tf.Variable(tf.random.normal([2,2], mean = 0, stddev = 1)) 12345678a = tf.ones([1, 3]) # 1*3的矩阵赋值为1b = tf.fill([1,3], 3.) # 1*3的矩阵赋值为3print(a)print(b)print(tf.add(a, b))print(tf.subtract(a, b))print(tf.multiply(a, b))print(tf.divide(b, a)) 12345a = tf.fill([1,2], 3.)print(a)print(tf.pow(a, 3))print(tf.square(a))print(tf.sqrt(a)) 4、对应标签和数据123456features = tf.constant([12, 23, 10 ,17]) #获取数据labels = tf.constant([0, 1, 1, 0]) #获取标签dataset = tf.data.Dataset.from_tensor_slices((features,labels))print(dataset)for element in dataset： print(element) 5、求导运算with结构记录计算过程，gradient求出张量的梯度 with tf.GradientTape() as tape: 若干计算过程 grad=tape.gradient(函数，对谁求导) 12345with tf.GradientTape() as tape: w = tf.Variable(tf.constant(3.0)) loss = tf.pow(w, 2)grad = tape.gradient(loss, w)print(grad) 6、enumerateenumerate是python的内建函数，他可以遍历元素，元组或字符串 123seq = [&#x27;one&#x27;, &#x27;two&#x27;, &#x27;three&#x27;]for i, element in enumerate(seq): print(i, element) 7、tf.one_hot 独热编码在分类问题中，常用独热码作为标签，标记类别：0代表非，1表示是 标签：1 独热码： （0， 1， 0） 表示是标签0的概率为0，是标签1的概率是百分百，是标签2的概率是0 8、tf.one_hot(待转换数据，depth=几分类)1234classes = 3labels = tf.constant([1,0,2])output = tf.one_hot(labels, depth = classes)print(output) 9、tf.nn.softmaxtf.nn.softmax能把n个分类的n个输出转换成0到1之间的概率值 123y = tf.constant([1.01, 2.01, -0.66]) #定义一些数值y_pro = tf.nn.softmax(y) #转换成标准概率print(&quot;result, y_pro is &quot;,y_pro) 10、tf.argmax返回张量最大值得索引，tf.argmax(张量名，axis=操作轴) 12345import numpy as nptest = np.array([[1,2,3],[2,3,4],[5,4,3],[8,7,2]])print(test)print(tf.argmax(test,axis=0))print(tf.argmax(test,axis=0))","categories":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://yoursite.com/categories/TensorFlow/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://yoursite.com/tags/TensorFlow/"}]},{"title":"理解边缘检测sift","slug":"图像处理——特征点检测sift","date":"2020-08-18T09:48:41.688Z","updated":"2020-08-18T14:48:02.589Z","comments":true,"path":"2020/08/18/图像处理——特征点检测sift/","link":"","permalink":"http://yoursite.com/2020/08/18/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E7%89%B9%E5%BE%81%E7%82%B9%E6%A3%80%E6%B5%8Bsift/","excerpt":"图像处理——sift理解 通俗的大致理解 首先，理解同一幅图像在不同的空间中有不同的表达方式。比如在RGB空间中，图像中的像素点可以用颜色值(r,g,b)来表示；在灰度空间中，图像中的像素点可以用灰度值来表示。类似的，你可以把梯度图像认为是图像在梯度空间中的一种表达，图像中的像素点可以用梯度方向来表示，即，梯度图像中的像素点表达的是该点的梯度方向（而不是灰度值/颜色值）。","text":"图像处理——sift理解 通俗的大致理解 首先，理解同一幅图像在不同的空间中有不同的表达方式。比如在RGB空间中，图像中的像素点可以用颜色值(r,g,b)来表示；在灰度空间中，图像中的像素点可以用灰度值来表示。类似的，你可以把梯度图像认为是图像在梯度空间中的一种表达，图像中的像素点可以用梯度方向来表示，即，梯度图像中的像素点表达的是该点的梯度方向（而不是灰度值/颜色值）。 其次，理解图像的灰度直方图是什么。图像的灰度直方图就是把灰度图像中灰度值分别为0,1,…,255的像素的个数统计起来，得到的一个一维向量。类似的，图像的梯度直方图就是把梯度图像中梯度方向分别为0°到360°的像素的个数统计起来，得到一个一维向量。 SIFT是什么？简单来说就是图像中某个局部区域（如16*16像素的一个区域）对应的梯度直方图，这就是最简单直观的理解。当然，SIFT还包括各种细节，如量化，尺度金字塔、旋转不变性、局部归一化等，这些东西很多博客上都有“教科书般”的介绍。 SURF是什么？SURF本身不是什么新的descriptor，而是对SIFT实现上的加速，核心点在于采用积分图对计算加速。 作者：大道至简知不语链接：https://www.zhihu.com/question/40736560/answer/358547318来源：知乎 知识点：积分图 sift深度剖析1、明确学习目的不管是Harris还是Shi-Tomas，角点检测检测即便做得再优化，也总是有不可克服的缺点： 对尺度很敏感，不具有尺度不变性 需要设计角点匹配算法 而SIFT算法是一种基于局部兴趣点的算法，因此 不仅对图片大小和旋转不敏感 而且对光照、噪声等影响的抗击能力也非常优秀 因此，该算法在性能和适用范围方面较于之前的算法有着质的改变。 在学习sift算法之前，我们先得搞明白这个算法目的是为了干什么，无非就是找到图像中的特征点，找到优质的特征点。 优质的特征点有什么特征呢？ 尺度不变性：人类在识别一个物体时，不管这个物体或远或近，都能对它进行正确的辨认，这就是所谓的尺度不变性。 旋转不变性：当这个物体发生旋转时，我们照样可以正确地辨认它，这就是所谓的旋转不变性。 2、sift过程构建多尺度的高斯金字塔 ①构建单尺度的空间，单尺度空间有6张图，六张图分别是经过方差大小不同的高斯滤波处理的图 ②然后对同一尺度的一组照片中的相邻滤波处理的照片做差得到的就是图像的轮廓，轮廓就是我们要得到的最基本的特征。做差得出的图像就叫做DoG。 ③然后再分成多个尺度，小尺度是通过上一层大尺度的第三张照片作为原图再次进行高斯滤波得到的。这一步就是要解决尺度的问题：构建金字塔，将特征值拓展到多分辨率上。 我的疑惑点：这么多尺度的图像他是怎样提取不同尺度的图像，然后融合在一起的 检测尺度空间的极值点 直接遍历找出极值点，极值点不但要根这个点周围的八个点比较，还要跟同一层相邻的另外两张图像作比较。一共比较26个点。注意做完这一步之后，应该就可以在原图上画出来极值点坐标了示意图了。 精确定位极值点 上一步我们已经找到了相关的特征点的大致坐标，接下来就要确定他们的准确位置，这里牵涉到很多数学运算。 选取特征点的方向 对我们已经用金字塔解决了尺度不变性问题，下面就要通过确定特征点的方向来解决旋转不变性问题。完成关键点的梯度计算后，使用直方图统计邻域内像素的梯度和方向。梯度直方图将0~360度的方向范围分为36个柱(bins)，其中每柱10度。如图所示，直方图的峰值方向代表了关键点的主方向，(为简化，图中只画了八个方向的直方图)。 直方图的峰值则代表了该关键点处邻域梯度的主方向，即作为该关键点的方向；其他的达到最大值80%的方向可作为辅助方向。到这里我们已经检测出的含有位置、尺度和方向的关键点即是该图像的SIFT特征点。 生成关键描述子到这里还没有结束 金字塔保证特征点的空间不变性， 严格删选保证了特征点的准确性， 方向信息保证了特征点的旋转不变性。我们如何把所有信息作为属性附加给关键点呢？ ①为什么要添加描述子：通过上面的步骤，对于每一个关键点，拥有三个信息：位置、尺度以及方向。接下来就是为每个关键点建立一个描述符，用一组向量将这个关键点描述出来，使其不随各种变化而改变，比如光照变化、视角变化等等。这个描述子不但包括关键点，也包含关键点周围对其有贡献的像素点，并且描述符应该有较高的独特性，以便于提高特征点正确匹配的概率。 ②添加过程：1) 确定计算描述子所需的图像区域特征描述子与特征点所在的尺度有关，因此，对梯度的求取应在特征点对应的高斯图像上进行。将关键点附近的邻域划分为d*d(Lowe建议d=4)个子区域，每个子区域做为一个种子点，每个种子点有8个方向。每个子区域的大小与关键点方向分配时相同。 以关键点为中心，4*4格为一个种子点，每个种子点8个方向。 每一个小格都代表了特征点邻域所在的尺度空间的一个像素 ，箭头方向代表了像素梯度方向，箭头长度代表该像素的幅值。然后在4×4的窗口内计算8个方向的梯度方向直方图。绘制每个梯度方向的累加可形成一个种子点。 2) 将坐标轴旋转为关键点的方向，以确保旋转不变性 3) 将邻域内的采样点分配到对应的子区域内，将子区域内的梯度值分配到8个方向上，计算其权值 其中a，b为关键点在高斯金字塔图像中的位置坐标。 4) 插值计算每个种子点八个方向的梯度 5) 归一化 如上统计的448=128个梯度信息即为该关键点的特征向量。特征向量形成后，为了去除光照变化的影响，需要对它们进行归一化处理，对于图像灰度值整体漂移，图像各点的梯度是邻域像素相减得到，所以也能去除。 6） 向量门限 描述子向量门限。非线性光照，相机饱和度变化对造成某些方向的梯度值过大，而对方向的影响微弱。因此设置门限值(向量归一化后，一般取0.2)截断较大的梯度值。然后，再进行一次归一化处理，提高特征的鉴别性。 7） 排序 按特征点的尺度对特征描述向量进行排序。 在每个44的1/16象限中，通过加权梯度值加到直方图8个方向区间中的一个，计算出一个梯度方向直方图。这样就可以对每个feature形成一个448=128维的描述子，每一维都可以表示44个格子中一个的scale/orientation. 将这个向量归一化之后，就进一步去除了光照的影响。 3.sift怎么匹配1、 首先还是要对图片生成特征点 一张图经过SIFT算法后，会得到多个特征点，每个特征点有128维的描述子属性。那么，匹配特征点都简单多啦！ 生成了A、B两幅图的描述子，（分别是k1128维和k2128维），就将两图中各个scale（所有scale）的描述子进行匹配，匹配上128维即可表示两个特征点match上了。 2、 然后考虑怎么匹配 当两幅图像的SIFT特征向量生成后，下一步我们采用关键点特征向量的欧式距离来作为两幅图像中关键点的相似性判定度量。取图像1中的某个关键点，并找出其与图像2中欧式距离最近的前两个关键点，在这两个关键点中，如果最近的距离除以次近的距离少于某个比例阈值，则接受这一对匹配点。降低这个比例阈值，SIFT匹配点数目会减少，但更加稳定。 1234567891011121314151617181920212223242526272829303132#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/xfeatures2d.hpp&gt;#include &lt;iostream&gt;using namespace cv;using namespace cv::xfeatures2d;using namespace std;int main(int argc, char** argv) &#123; Mat cat = imread(&quot;cat.png&quot;); Mat smallCat = imread(&quot;smallCat.png&quot;); imshow(&quot;cat image&quot;, cat); imshow(&quot;smallCat image&quot;, smallCat); auto detector = SIFT::create(); vector&lt;KeyPoint&gt; keypoints_cat, keypoints_smallCat; Mat descriptor_cat, descriptor_smallCat; detector-&gt;detectAndCompute(cat, Mat(), keypoints_cat, descriptor_cat); detector-&gt;detectAndCompute(smallCat, Mat(), keypoints_smallCat, descriptor_smallCat); Ptr&lt;FlannBasedMatcher&gt; matcher = FlannBasedMatcher::create(); vector&lt;DMatch&gt; matches; matcher-&gt;match(descriptor_cat, descriptor_smallCat, matches); Mat dst; drawMatches(cat, keypoints_cat, smallCat, keypoints_smallCat, matches, dst); imshow(&quot;match-demo&quot;, dst); waitKey(0); return 0;&#125; 作者: lowkeyway 转载自: https://zhuanlan.zhihu.com/p/90122194","categories":[{"name":"图像处理笔记","slug":"图像处理笔记","permalink":"http://yoursite.com/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"图像处理笔记","slug":"图像处理笔记","permalink":"http://yoursite.com/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/"}]},{"title":"傅里叶变换","slug":"图像处理——傅里叶变换","date":"2020-08-10T13:16:20.329Z","updated":"2020-08-19T02:00:44.828Z","comments":true,"path":"2020/08/10/图像处理——傅里叶变换/","link":"","permalink":"http://yoursite.com/2020/08/10/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/","excerpt":"图像处理——傅里叶 1.傅里叶变换的理解傅里叶变换的相关数学公式目前还没有搞懂，先不整那个东西，我们主要是研究傅里叶变换的一些思想和应用。这个思想起源于牛顿研究那个三棱镜，白光透过棱镜之后会被分解为七种颜色的光，这些光叠加又能形成白光，所以说可以把一种事物分解成好几种事物的加和。","text":"图像处理——傅里叶 1.傅里叶变换的理解傅里叶变换的相关数学公式目前还没有搞懂，先不整那个东西，我们主要是研究傅里叶变换的一些思想和应用。这个思想起源于牛顿研究那个三棱镜，白光透过棱镜之后会被分解为七种颜色的光，这些光叠加又能形成白光，所以说可以把一种事物分解成好几种事物的加和。 后来傅里叶就提出了**傅里叶级数**，一个等幅度不同频或者等频不同幅的波形可以由一组正弦波余弦波的加和得到（原话：任何连续周期信号可以由一组适当的正弦曲线组合而成） 2.傅里叶级数可以这么理解：原图像相当于在时间域中的一个曲线，坐标图是个二维坐标系，横轴是时间，纵轴是幅值的一个曲线，我们通过傅里叶变换可以把这条曲线变成多条正余弦函数相加的形式：傅里叶变换之后形成的是一个三维坐标系，他的x轴是频率（w），y轴是相位（因为每个正余弦函数的起点不同，有的是从零点开始，有的不是，这个曲线开始的那个幅值就是相位，相位就是后公式中的φ），z轴是振幅高度，。这样可以把一个图像从空间域转换到频率域，因为两者等价，所以可以逆变换回去。但这个傅里叶级数只能针对周期型函数才能拆分成多个正余弦函数相加，所以后来有了傅里叶变换。$$f(t) = \\frac{a_n}{2}+\\sum a_n*sin（nwt+φ_n）$$ 3.傅里叶变换其中推导公式中用到了欧拉公式，$$cos(x)+i*sin(x) = e^{ix}\\$$$$x = wt$$ $$F_T = \\int_{-\\infty}^{+\\infty}f(t)e^{jwt}dt\\$$ 然后通过逆变换可以再变回去。通过傅里叶变换就可以把一个随机的曲线，转换到频率域，只不过这次的三维坐标系对应的w和幅值的函数图像不再是离散的图像了，而是一个连续图像。y轴所对应的相位意义没变。 4.应用- 声音通过分析频率域，可以分析出低频可能是男生说话，高频可能是女生说话，再高的频率就是噪音了，除去这些高频信号，然后通过逆变换就可以得到处理后的音频。 在声音中，那刚才的傅里叶变换之前的x轴就是时间，y轴就是声音的振幅 如下图（copy from 知乎Heinrich） - 图像通过分析频率域，他的低频部分可能就是画像的主体部分，高频部分可能是图像中的噪点，比如说是画面中的斑点噪音，旧照片中的斑点，通过去掉高频信号，然后逆变换回去，就得到去除噪点之后的图像。 在图像中，傅里叶变换之前的x轴就是图像的空间坐标位置，y轴就是他的灰度？？？ 5.OpenCV ，Numpy中操作一下-numpy中操作 np.fft.fft2 实现傅里叶变换并且返回一个复数数组 np.fft.fftshift 将零频率分量移动到频谱的中心 np.log（np.abs(fshift)） 刚才返回的复数数组没办法用图像的形式展示出来需要用以上函数转换到[0, 255]范围 np.fft.ifftshift 把中心化的频谱再移动回左上角 np.fft.ifft2 实现逆变换，返回一个复数数组 np.abs（逆傅里叶变换的结果） ​ 变回能显示的[0, 255]的可显示图像 1234567891011121314151617181920212223import cv2import numpy as npimport matplotlib.pyplot as plt# 直接读为灰度图像img = cv2.imread(&#x27;你电脑本地的图像路径&#x27;, 0) f = np.fft.fft2(img)fshift = np.fft.fftshift(f)# 取绝对值：将复数变化成实数# 取对数的目的为了将数据变化到0-255s1 = np.log(np.abs(fshift))plt.subplot(131), plt.imshow(img, cmap=&#x27;gray&#x27;, interpolation=&#x27;bicubic&#x27;), plt.title(&#x27;original&#x27;)plt.xticks([]), plt.yticks([])plt.subplot(132), plt.imshow(s1, &#x27;gray&#x27;, interpolation=&#x27;bicubic&#x27;), plt.title(&#x27;center&#x27;)plt.xticks([]), plt.yticks([])# 逆变换f1shift = np.fft.ifftshift(fshift)img_back = np.fft.ifft2(f1shift)# 出来的是复数，无法显示img_back = np.abs(img_back)plt.subplot(133), plt.imshow(img_back, cmap=&#x27;gray&#x27;, interpolation=&#x27;bicubic&#x27;), plt.title(&#x27;img back&#x27;)plt.xticks([]), plt.yticks([])plt.show() OpenCV中操作 返回结果 = cv2.dft(原始图像， 转换标识) 返回结果是双通道的，第一通道是结果的实数部分，第二通道是虚数部分 原始图像一般是整型八位位图，要转换成32位的（np.float32(img)） 转换标识一般flags = cv2.DFT_COMPLEX_OUTPUT,输出一个复数阵列 np.fft.fftshift 将零频率分量转换频谱中心 返回值 = cv2.magnitude（参数1，参数2） 参数1：浮点的X坐标，也就是实部 参数2：浮点的Y坐标，也就是虚部 通过这个函数，将那个复数转换到[0, 255] 12345678910111213141516171819202122import cv2import numpy as npimport matplotlib.pyplot as pltimg = cv2.imread(&#x27;电脑本地的图像地址&#x27;， 0)dft = cv2.dft(np.float32(img), flags = cv2.DFT_COMPLEX_OUTPUT)dftshift = np.fft.fftshift(dft)result = 20*np.log(cv2.magnitude(dftshift[:,:,0], dftshift[:,:,1]))ishift = np.fft.ifftshift(dftshift)iimg = cv2.idft(ishift)iimg = cv2.magnitude(iimg[:, :, 0], iimg[:, :, 1])plt.subplot(221), plt.imshow(img,&#x27;gray&#x27;)plt.title(&#x27;img&#x27;), plt.axis(&#x27;off&#x27;)plt.subplot(222), plt.imshow(result,&#x27;gray&#x27;)plt.title(&#x27;result&#x27;), plt.axis(&#x27;off&#x27;)plt.subplot(223), plt.imshow(img, &#x27;gray&#x27;)plt.title(&#x27;img&#x27;), plt.axis(&#x27;off&#x27;)plt.subplot(224), plt.imshow(iimg, &#x27;gray&#x27;)plt.title(&#x27;result&#x27;), plt.axis(&#x27;off&#x27;)plt.show() 低通滤波1234567891011121314151617181920import cv2import numpy as npimport matplotlib.pyplot as pltimg = cv2.imread(&#x27;/Users/star/learning_python/picture/2.png&#x27;, 0)dft = cv2.dft(np.float32(img), flags=cv2.DFT_COMPLEX_OUTPUT)dshift = np.fft.fftshift(dft)rows, cols = img.shaperow, col = int(rows/2), int(cols/2)mask = np.zeros((rows, cols, 2), np.uint8)mask[row-50:row+50, col-50:col+50] = 1dst = dshift * maskidst = np.fft.ifftshift(dst)ishift = cv2.idft(idst)idst = cv2.magnitude(ishift[:, :, 0], ishift[:, :, 1])plt.subplot(121), plt.imshow(img, &#x27;gray&#x27;)plt.title(&#x27;img&#x27;), plt.axis(&#x27;off&#x27;)plt.subplot(122), plt.imshow(idst, &#x27;gray&#x27;)plt.title(&#x27;img&#x27;), plt.axis(&#x27;off&#x27;)plt.show() 高通滤波123456789101112131415161718import cv2import numpy as npimport matplotlib.pyplot as pltimg = cv2.imread(&#x27;电脑本地的图像地址&#x27;， 0)f = np.fft.fft2(img)fshift = np.fft.fftshift(f) rows,cols = img.shape[:2]crow,ccol = int(rows/2), int(cols/2)fshift[crow-30:crow+30, ccol-30:ccol+30] = 0ishift = np.fft.ifftshift(fshift)iimg = np.fft.ifft2(ishift)iimg = np.abs(iimg)plt.subplot(121),plt.imshow(img, &#x27;gray&#x27;)plt.title(&#x27;img&#x27;),plt.axis(&#x27;off&#x27;)plt.subplot(122),plt.imshow(iimg, &#x27;gray&#x27;)plt.title(&#x27;iimg&#x27;),plt.axis(&#x27;off&#x27;)plt.show()","categories":[{"name":"图像处理笔记","slug":"图像处理笔记","permalink":"http://yoursite.com/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"图像处理笔记","slug":"图像处理笔记","permalink":"http://yoursite.com/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/"}]},{"title":"学习java第三天——语言类型","slug":"学习java第三天——语言类型","date":"2020-08-10T02:05:32.378Z","updated":"2020-08-18T14:57:17.656Z","comments":true,"path":"2020/08/10/学习java第三天——语言类型/","link":"","permalink":"http://yoursite.com/2020/08/10/%E5%AD%A6%E4%B9%A0java%E7%AC%AC%E4%B8%89%E5%A4%A9%E2%80%94%E2%80%94%E8%AF%AD%E8%A8%80%E7%B1%BB%E5%9E%8B/","excerpt":"解释型语言解释型语言的典型：python、JavaScript、Ruby等。","text":"解释型语言解释型语言的典型：python、JavaScript、Ruby等。 解释型语言的特点，我理解的就是解释一句跑一句子，如果下边语句有错误，并不会影响上边语句的执行。要想写小的程序，基本上可以忽略执行效率的基础上，还想让程序能成功跑下去，解释型语言还是很香的。 编译型语言编译型语言的典型：C和C++等 汇编型语言的特点，我理解的就是把所有语句都从头理一遍，如果其中出现一句语句有错误，整个程序都无法运行。所以要想提高程序的执行效率，要想写大工程文件，还是要转换成编译型语言的。 编译型—解释型语言典型代表:Java 严格地说，Java其实就是解释型语言，其所谓的编译过程只是将.java文件编程成.class文件，并不是向C一样编译成可执行的机器语言，在此请读者注意Java中所谓的“编译”和传统的“编译”的区别；然后生成的.class文件再逐句进行解释，在Java的虚拟机JVM中运行。在现实中，java开发工具JDK提供了两个很重要的命令来完成上面的编译和解释（翻译）过程：javac.exe是将.java文件编译成.class文件，而java.exe是将.class文件解释执行吧 总结解释器与编译器两者各有优势：当程序需要迅速启动和执行的时候，解释器可以首先发挥作用，省去编译的时间，立即执行。在程序运行后，随着时间的推移，编译器逐渐发挥作用，把越来越多的代码编译成本地代码之后，可以获取更高的执行效率。 当程序运行环境中内存资源限制较大（如部分嵌入式系统中），可以使用解释执行节约内存，反之可以使用编译执行来提升效率。 但随着硬件的升级和设计思想的变革，编译型和解释型语言越来越笼统，主要体现在一些新兴的高级语言上，而解释型语言的自身特点也使得编译器厂商愿意花费更多成本来优化解释器，解释型语言性能超过编译型语言也是必然的。","categories":[{"name":"java笔记","slug":"java笔记","permalink":"http://yoursite.com/categories/java%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"java笔记","slug":"java笔记","permalink":"http://yoursite.com/tags/java%E7%AC%94%E8%AE%B0/"}]},{"title":"学习java第二天——终端命令","slug":"学习Java第二天——终端命令","date":"2020-08-06T14:50:23.339Z","updated":"2020-08-18T14:57:37.474Z","comments":true,"path":"2020/08/06/学习Java第二天——终端命令/","link":"","permalink":"http://yoursite.com/2020/08/06/%E5%AD%A6%E4%B9%A0Java%E7%AC%AC%E4%BA%8C%E5%A4%A9%E2%80%94%E2%80%94%E7%BB%88%E7%AB%AF%E5%91%BD%E4%BB%A4/","excerpt":"Dos和Linux的常用命令Dos命令——我用的windows 从默认的C盘切换到D盘或者其他盘符 命令：D:","text":"Dos和Linux的常用命令Dos命令——我用的windows 从默认的C盘切换到D盘或者其他盘符 命令：D: 磁盘操作，进入盘符下的文件夹 命令：cd + 文件夹名称 查看当前文件夹里面有哪些目录或者文件 命令：dir 显示当前文件夹 命令：chdir 返回上一级目录 命令：cd .. 创建文件夹 命令：mkdir 创建文件 命令：cd.&gt;a.txt 显示网络设置 命令：ipconfig 清屏 命令：cls Linux命令——我用的mac 从默认的C盘切换到D盘或者其他盘符 命令：D: 磁盘操作，进入盘符下的文件夹 命令：cd + 文件夹名称 查看当前文件夹里面有哪些目录或者文件 命令：ls 显示当前文件夹 命令：pwd 返回上一级目录 命令：cd .. 创建文件夹 命令：mkdir 创建文件 命令：touch a.txt 显示网络设置 命令：ifconfig 清屏 命令：clear 上边都是些基本入门常用的命令，用到其余的可以再找^-^ 通过cd命令和dir命令（mac下的ls命令），基本上就可以在终端自由访问文件夹了。 如果嫌弃文件或者文件夹名称过长，可以通过tab键来自动补全。","categories":[{"name":"java笔记","slug":"java笔记","permalink":"http://yoursite.com/categories/java%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"java笔记","slug":"java笔记","permalink":"http://yoursite.com/tags/java%E7%AC%94%E8%AE%B0/"}]},{"title":"学习java第一天——markdown基础","slug":"学习Java第一天——markdown基础","date":"2020-08-06T14:12:39.666Z","updated":"2020-08-18T14:56:21.041Z","comments":true,"path":"2020/08/06/学习Java第一天——markdown基础/","link":"","permalink":"http://yoursite.com/2020/08/06/%E5%AD%A6%E4%B9%A0Java%E7%AC%AC%E4%B8%80%E5%A4%A9%E2%80%94%E2%80%94markdown%E5%9F%BA%E7%A1%80/","excerpt":"markdown基础 本人是一个跨考生，本科学习的农学，现在研究生跨入了计算机专业，因为底子比较薄，所以想通过看一些课程，在博客上自己记录一下学习历程，以便于督促自己。","text":"markdown基础 本人是一个跨考生，本科学习的农学，现在研究生跨入了计算机专业，因为底子比较薄，所以想通过看一些课程，在博客上自己记录一下学习历程，以便于督促自己。 一.标题##+space+内容 三级标题###+space+内容 四级标题####+space+内容 二.字体hello，java ** + 内容 + ** hello，java * + 内容 + * hello，java ~ + 内容 + ~ hello，java ** * + 内容 + ** * 三.引用 学习java第一天，认认真真记笔记！ ‘&gt;’ + space + 内容 四.分割线 键盘输入“—”，也就是三个减号就可以了 或者也可以用三个星号，“***” ## 五.图片 先输入“!” + 英文状态下的“[ ]” + 图片的网络地址或者本地地址 六.超链接超链接 先输入“[ ]”+ “( )”在括号里面放要链接的网址就可以了 七.列表 第一个 第二个 这个就是直接写“1” + “.” + space 无序列表 第一个 第二个 输入“-”减号 + space 八.表格 右键插入 代码形式 姓名 性别 年龄 小明 男 18 mac下：输入 |名字|性别|生日| 即可 win下：输入 |名字|性别|生日| ​ |–|–|–| ​ |小明|男|18| 然后回车 九.代码123456789package hello;public class world&#123; public static void main(String[] args) &#123; System.out.println(&quot;Hello, world!&quot;); &#125;&#125; 输入“···” + “语言名称”，就会出现代码框了 其中的点 在键盘按键上的 Esc 的下边 语言名称指的是“java”，”c“，”python“等","categories":[{"name":"java笔记","slug":"java笔记","permalink":"http://yoursite.com/categories/java%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"java笔记","slug":"java笔记","permalink":"http://yoursite.com/tags/java%E7%AC%94%E8%AE%B0/"}]}],"categories":[{"name":"matlab","slug":"matlab","permalink":"http://yoursite.com/categories/matlab/"},{"name":"图像处理笔记","slug":"图像处理笔记","permalink":"http://yoursite.com/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://yoursite.com/categories/TensorFlow/"},{"name":"java笔记","slug":"java笔记","permalink":"http://yoursite.com/categories/java%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"matlab","slug":"matlab","permalink":"http://yoursite.com/tags/matlab/"},{"name":"图像处理笔记","slug":"图像处理笔记","permalink":"http://yoursite.com/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://yoursite.com/tags/TensorFlow/"},{"name":"java笔记","slug":"java笔记","permalink":"http://yoursite.com/tags/java%E7%AC%94%E8%AE%B0/"}]}