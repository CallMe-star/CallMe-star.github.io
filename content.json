{"meta":{"title":"CallMe_star","subtitle":"","description":"","author":"John Doe","url":"http://yoursite.com","root":"/callme-star.github.io/"},"pages":[{"title":"所有分类","date":"2020-08-16T15:23:21.601Z","updated":"2020-08-15T13:51:09.258Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"About Me. || 关于我","date":"2020-08-17T01:55:08.346Z","updated":"2020-08-17T01:55:08.337Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"本人技术小白一个，刚刚入坑，望大家多指教。 搭建博客的目的就是为了有个自己的独立空间，记点学习笔记，记录自己的成长历程。 在接下来的时间里面我会慢慢更新一些java相关的学习经历，和后续的成果。 因为接下来主要学习图像处理和深度学习的相关内容，所以博客主旋律是图像和机器学习。 还请大佬们多多指教 123456#include&lt;iostream&gt;using nemespace std;int main&#123; cout&lt;&lt;&quot;Hello world!&quot;&lt;&lt;&quot;\\n&quot;&lt;&lt;&quot;Hello every one!&quot;&#125; Hello world! Hello every one! Contact Me qq: 1024422413"},{"title":"帮助过我的大佬们","date":"2020-08-16T15:23:12.282Z","updated":"2020-08-15T15:06:29.119Z","comments":true,"path":"friends/index.html","permalink":"http://yoursite.com/friends/index.html","excerpt":"","text":""},{"title":"所有分类","date":"2020-08-15T14:47:15.248Z","updated":"2020-08-15T14:47:15.240Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"福利图","date":"2020-08-16T15:24:09.000Z","updated":"2020-08-18T01:52:29.446Z","comments":true,"path":"福利图/index.html","permalink":"http://yoursite.com/%E7%A6%8F%E5%88%A9%E5%9B%BE/index.html","excerpt":"","text":"风景图 动漫 汽车"}],"posts":[{"title":"理解边缘检测sift","slug":"图像处理——特征点检测sift","date":"2020-08-18T09:48:41.688Z","updated":"2020-08-18T14:48:02.589Z","comments":true,"path":"2020/08/18/图像处理——特征点检测sift/","link":"","permalink":"http://yoursite.com/2020/08/18/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E7%89%B9%E5%BE%81%E7%82%B9%E6%A3%80%E6%B5%8Bsift/","excerpt":"图像处理——sift理解 通俗的大致理解 首先，理解同一幅图像在不同的空间中有不同的表达方式。比如在RGB空间中，图像中的像素点可以用颜色值(r,g,b)来表示；在灰度空间中，图像中的像素点可以用灰度值来表示。类似的，你可以把梯度图像认为是图像在梯度空间中的一种表达，图像中的像素点可以用梯度方向来表示，即，梯度图像中的像素点表达的是该点的梯度方向（而不是灰度值/颜色值）。","text":"图像处理——sift理解 通俗的大致理解 首先，理解同一幅图像在不同的空间中有不同的表达方式。比如在RGB空间中，图像中的像素点可以用颜色值(r,g,b)来表示；在灰度空间中，图像中的像素点可以用灰度值来表示。类似的，你可以把梯度图像认为是图像在梯度空间中的一种表达，图像中的像素点可以用梯度方向来表示，即，梯度图像中的像素点表达的是该点的梯度方向（而不是灰度值/颜色值）。 其次，理解图像的灰度直方图是什么。图像的灰度直方图就是把灰度图像中灰度值分别为0,1,…,255的像素的个数统计起来，得到的一个一维向量。类似的，图像的梯度直方图就是把梯度图像中梯度方向分别为0°到360°的像素的个数统计起来，得到一个一维向量。 SIFT是什么？简单来说就是图像中某个局部区域（如16*16像素的一个区域）对应的梯度直方图，这就是最简单直观的理解。当然，SIFT还包括各种细节，如量化，尺度金字塔、旋转不变性、局部归一化等，这些东西很多博客上都有“教科书般”的介绍。 SURF是什么？SURF本身不是什么新的descriptor，而是对SIFT实现上的加速，核心点在于采用积分图对计算加速。 作者：大道至简知不语链接：https://www.zhihu.com/question/40736560/answer/358547318来源：知乎 知识点：积分图 sift深度剖析1、明确学习目的不管是Harris还是Shi-Tomas，角点检测检测即便做得再优化，也总是有不可克服的缺点： 对尺度很敏感，不具有尺度不变性 需要设计角点匹配算法 而SIFT算法是一种基于局部兴趣点的算法，因此 不仅对图片大小和旋转不敏感 而且对光照、噪声等影响的抗击能力也非常优秀 因此，该算法在性能和适用范围方面较于之前的算法有着质的改变。 在学习sift算法之前，我们先得搞明白这个算法目的是为了干什么，无非就是找到图像中的特征点，找到优质的特征点。 优质的特征点有什么特征呢？ 尺度不变性：人类在识别一个物体时，不管这个物体或远或近，都能对它进行正确的辨认，这就是所谓的尺度不变性。 旋转不变性：当这个物体发生旋转时，我们照样可以正确地辨认它，这就是所谓的旋转不变性。 2、sift过程构建多尺度的高斯金字塔 ①构建单尺度的空间，单尺度空间有6张图，六张图分别是经过方差大小不同的高斯滤波处理的图 ②然后对同一尺度的一组照片中的相邻滤波处理的照片做差得到的就是图像的轮廓，轮廓就是我们要得到的最基本的特征。做差得出的图像就叫做DoG。 ③然后再分成多个尺度，小尺度是通过上一层大尺度的第三张照片作为原图再次进行高斯滤波得到的。这一步就是要解决尺度的问题：构建金字塔，将特征值拓展到多分辨率上。 我的疑惑点：这么多尺度的图像他是怎样提取不同尺度的图像，然后融合在一起的 检测尺度空间的极值点 直接遍历找出极值点，极值点不但要根这个点周围的八个点比较，还要跟同一层相邻的另外两张图像作比较。一共比较26个点。注意做完这一步之后，应该就可以在原图上画出来极值点坐标了示意图了。 精确定位极值点 上一步我们已经找到了相关的特征点的大致坐标，接下来就要确定他们的准确位置，这里牵涉到很多数学运算。 选取特征点的方向 对我们已经用金字塔解决了尺度不变性问题，下面就要通过确定特征点的方向来解决旋转不变性问题。完成关键点的梯度计算后，使用直方图统计邻域内像素的梯度和方向。梯度直方图将0~360度的方向范围分为36个柱(bins)，其中每柱10度。如图所示，直方图的峰值方向代表了关键点的主方向，(为简化，图中只画了八个方向的直方图)。 直方图的峰值则代表了该关键点处邻域梯度的主方向，即作为该关键点的方向；其他的达到最大值80%的方向可作为辅助方向。到这里我们已经检测出的含有位置、尺度和方向的关键点即是该图像的SIFT特征点。 生成关键描述子到这里还没有结束 金字塔保证特征点的空间不变性， 严格删选保证了特征点的准确性， 方向信息保证了特征点的旋转不变性。我们如何把所有信息作为属性附加给关键点呢？ ①为什么要添加描述子：通过上面的步骤，对于每一个关键点，拥有三个信息：位置、尺度以及方向。接下来就是为每个关键点建立一个描述符，用一组向量将这个关键点描述出来，使其不随各种变化而改变，比如光照变化、视角变化等等。这个描述子不但包括关键点，也包含关键点周围对其有贡献的像素点，并且描述符应该有较高的独特性，以便于提高特征点正确匹配的概率。 ②添加过程：1) 确定计算描述子所需的图像区域特征描述子与特征点所在的尺度有关，因此，对梯度的求取应在特征点对应的高斯图像上进行。将关键点附近的邻域划分为d*d(Lowe建议d=4)个子区域，每个子区域做为一个种子点，每个种子点有8个方向。每个子区域的大小与关键点方向分配时相同。 以关键点为中心，4*4格为一个种子点，每个种子点8个方向。 每一个小格都代表了特征点邻域所在的尺度空间的一个像素 ，箭头方向代表了像素梯度方向，箭头长度代表该像素的幅值。然后在4×4的窗口内计算8个方向的梯度方向直方图。绘制每个梯度方向的累加可形成一个种子点。 2) 将坐标轴旋转为关键点的方向，以确保旋转不变性 3) 将邻域内的采样点分配到对应的子区域内，将子区域内的梯度值分配到8个方向上，计算其权值 其中a，b为关键点在高斯金字塔图像中的位置坐标。 4) 插值计算每个种子点八个方向的梯度 5) 归一化 如上统计的448=128个梯度信息即为该关键点的特征向量。特征向量形成后，为了去除光照变化的影响，需要对它们进行归一化处理，对于图像灰度值整体漂移，图像各点的梯度是邻域像素相减得到，所以也能去除。 6） 向量门限 描述子向量门限。非线性光照，相机饱和度变化对造成某些方向的梯度值过大，而对方向的影响微弱。因此设置门限值(向量归一化后，一般取0.2)截断较大的梯度值。然后，再进行一次归一化处理，提高特征的鉴别性。 7） 排序 按特征点的尺度对特征描述向量进行排序。 在每个44的1/16象限中，通过加权梯度值加到直方图8个方向区间中的一个，计算出一个梯度方向直方图。这样就可以对每个feature形成一个448=128维的描述子，每一维都可以表示44个格子中一个的scale/orientation. 将这个向量归一化之后，就进一步去除了光照的影响。 3.sift怎么匹配1、 首先还是要对图片生成特征点 一张图经过SIFT算法后，会得到多个特征点，每个特征点有128维的描述子属性。那么，匹配特征点都简单多啦！ 生成了A、B两幅图的描述子，（分别是k1128维和k2128维），就将两图中各个scale（所有scale）的描述子进行匹配，匹配上128维即可表示两个特征点match上了。 2、 然后考虑怎么匹配 当两幅图像的SIFT特征向量生成后，下一步我们采用关键点特征向量的欧式距离来作为两幅图像中关键点的相似性判定度量。取图像1中的某个关键点，并找出其与图像2中欧式距离最近的前两个关键点，在这两个关键点中，如果最近的距离除以次近的距离少于某个比例阈值，则接受这一对匹配点。降低这个比例阈值，SIFT匹配点数目会减少，但更加稳定。 1234567891011121314151617181920212223242526272829303132#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/xfeatures2d.hpp&gt;#include &lt;iostream&gt;using namespace cv;using namespace cv::xfeatures2d;using namespace std;int main(int argc, char** argv) &#123; Mat cat = imread(&quot;cat.png&quot;); Mat smallCat = imread(&quot;smallCat.png&quot;); imshow(&quot;cat image&quot;, cat); imshow(&quot;smallCat image&quot;, smallCat); auto detector = SIFT::create(); vector&lt;KeyPoint&gt; keypoints_cat, keypoints_smallCat; Mat descriptor_cat, descriptor_smallCat; detector-&gt;detectAndCompute(cat, Mat(), keypoints_cat, descriptor_cat); detector-&gt;detectAndCompute(smallCat, Mat(), keypoints_smallCat, descriptor_smallCat); Ptr&lt;FlannBasedMatcher&gt; matcher = FlannBasedMatcher::create(); vector&lt;DMatch&gt; matches; matcher-&gt;match(descriptor_cat, descriptor_smallCat, matches); Mat dst; drawMatches(cat, keypoints_cat, smallCat, keypoints_smallCat, matches, dst); imshow(&quot;match-demo&quot;, dst); waitKey(0); return 0;&#125; 作者: lowkeyway 转载自: https://zhuanlan.zhihu.com/p/90122194","categories":[{"name":"图像处理笔记","slug":"图像处理笔记","permalink":"http://yoursite.com/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"图像处理笔记","slug":"图像处理笔记","permalink":"http://yoursite.com/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/"}]},{"title":"傅里叶变换","slug":"图像处理——傅里叶变换","date":"2020-08-10T13:16:20.329Z","updated":"2020-08-18T14:48:48.364Z","comments":true,"path":"2020/08/10/图像处理——傅里叶变换/","link":"","permalink":"http://yoursite.com/2020/08/10/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/","excerpt":"图像处理——傅里叶 1.傅里叶变换的理解傅里叶变换的相关数学公式目前还没有搞懂，先不整那个东西，我们主要是研究傅里叶变换的一些思想和应用。这个思想起源于牛顿研究那个三棱镜，白光透过棱镜之后会被分解为七种颜色的光，这些光叠加又能形成白光，所以说可以把一种事物分解成好几种事物的加和。","text":"图像处理——傅里叶 1.傅里叶变换的理解傅里叶变换的相关数学公式目前还没有搞懂，先不整那个东西，我们主要是研究傅里叶变换的一些思想和应用。这个思想起源于牛顿研究那个三棱镜，白光透过棱镜之后会被分解为七种颜色的光，这些光叠加又能形成白光，所以说可以把一种事物分解成好几种事物的加和。 后来傅里叶就提出了**傅里叶级数**，一个等幅度不同频或者等频不同幅的波形可以由一组正弦波余弦波的加和得到（原话：任何连续周期信号可以由一组适当的正弦曲线组合而成） 2.傅里叶级数可以这么理解：原图像相当于在时间域中的一个曲线，坐标图是个二维坐标系，横轴是时间，纵轴是幅值的一个曲线，我们通过傅里叶变换可以把这条曲线变成多条正余弦函数相加的形式：傅里叶变换之后形成的是一个三维坐标系，他的x轴是频率（w），y轴是相位（因为每个正余弦函数的起点不同，有的是从零点开始，有的不是，这个曲线开始的那个幅值就是相位，相位就是后公式中的φ），z轴是振幅高度，。这样可以把一个图像从空间域转换到频率域，因为两者等价，所以可以逆变换回去。但这个傅里叶级数只能针对周期型函数才能拆分成多个正余弦函数相加，所以后来有了傅里叶变换。$$f(t) = \\frac{a_n}{2}+\\sum a_n*sin（nwt+φ_n）$$ 3.傅里叶变换其中推导公式中用到了欧拉公式，$$cos(x)+i*sin(x) = e^{ix}\\$$$$x = wt$$ $$F_T = \\int_{-\\infty}^{+\\infty}f(t)e^{jwt}dt\\$$ 然后通过逆变换可以再变回去。通过傅里叶变换就可以把一个随机的曲线，转换到频率域，只不过这次的三维坐标系对应的w和幅值的函数图像不再是离散的图像了，而是一个连续图像。y轴所对应的相位意义没变。 4.应用- 声音通过分析频率域，可以分析出低频可能是男生说话，高频可能是女生说话，再高的频率就是噪音了，除去这些高频信号，然后通过逆变换就可以得到处理后的音频。 在声音中，那刚才的傅里叶变换之前的x轴就是时间，y轴就是声音的振幅 如下图（copy from 知乎Heinrich） - 图像通过分析频率域，他的低频部分可能就是画像的主体部分，高频部分可能是图像中的噪点，比如说是画面中的斑点噪音，旧照片中的斑点，通过去掉高频信号，然后逆变换回去，就得到去除噪点之后的图像。 在图像中，傅里叶变换之前的x轴就是图像的空间坐标位置，y轴就是他的灰度？？？ 5.OpenCV ，Numpy中的操作一下-numpy中操作 np.fft.fft2 实现傅里叶变换并且返回一个复数数组 np.fft.fftshift 将零频率分量移动到频谱的中心 np.log（np.abs(fshift)） 刚才返回的复数数组没办法用图像的形式展示出来需要用以上函数转换到[0, 255]范围 np.fft.ifftshift 把中心化的频谱再移动回左上角 np.fft.ifft2 实现逆变换，返回一个复数数组 np.abs（逆傅里叶变换的结果） ​ 变回能显示的[0, 255]的可显示图像 1234567891011121314151617181920212223import cv2import numpy as npimport matplotlib.pyplot as plt# 直接读为灰度图像img = cv2.imread(&#x27;你电脑本地的图像路径&#x27;, 0) f = np.fft.fft2(img)fshift = np.fft.fftshift(f)# 取绝对值：将复数变化成实数# 取对数的目的为了将数据变化到0-255s1 = np.log(np.abs(fshift))plt.subplot(131), plt.imshow(img, cmap=&#x27;gray&#x27;, interpolation=&#x27;bicubic&#x27;), plt.title(&#x27;original&#x27;)plt.xticks([]), plt.yticks([])plt.subplot(132), plt.imshow(s1, &#x27;gray&#x27;, interpolation=&#x27;bicubic&#x27;), plt.title(&#x27;center&#x27;)plt.xticks([]), plt.yticks([])# 逆变换f1shift = np.fft.ifftshift(fshift)img_back = np.fft.ifft2(f1shift)# 出来的是复数，无法显示img_back = np.abs(img_back)plt.subplot(133), plt.imshow(img_back, cmap=&#x27;gray&#x27;, interpolation=&#x27;bicubic&#x27;), plt.title(&#x27;img back&#x27;)plt.xticks([]), plt.yticks([])plt.show() OpenCV中操作 返回结果 = cv2.dft(原始图像， 转换标识) 返回结果是双通道的，第一通道是结果的实数部分，第二通道是虚数部分 原始图像一般是整型八位位图，要转换成32位的（np.float32(img)） 转换标识一般flags = cv2.DFT_COMPLEX_OUTPUT,输出一个复数阵列 np.fft.fftshift 将零频率分量转换频谱中心 返回值 = cv2.magnitude（参数1，参数2） 参数1：浮点的X坐标，也就是实部 参数2：浮点的Y坐标，也就是虚部 通过这个函数，将那个复数转换到[0, 255] 12345678910111213141516171819202122import cv2import numpy as npimport matplotlib.pyplot as pltimg = cv2.imread(&#x27;电脑本地的图像地址&#x27;， 0)dft = cv2.dft(np.float32(img), flags = cv2.DFT_COMPLEX_OUTPUT)dftshift = np.fft.fftshift(dft)result = 20*np.log(cv2.magnitude(dftshift[:,:,0], dftshift[:,:,1]))ishift = np.fft.ifftshift(dftshift)iimg = cv2.idft(ishift)iimg = cv2.magnitude(iimg[:, :, 0], iimg[:, :, 1])plt.subplot(221), plt.imshow(img,&#x27;gray&#x27;)plt.title(&#x27;img&#x27;), plt.axis(&#x27;off&#x27;)plt.subplot(222), plt.imshow(result,&#x27;gray&#x27;)plt.title(&#x27;result&#x27;), plt.axis(&#x27;off&#x27;)plt.subplot(223), plt.imshow(img, &#x27;gray&#x27;)plt.title(&#x27;img&#x27;), plt.axis(&#x27;off&#x27;)plt.subplot(224), plt.imshow(iimg, &#x27;gray&#x27;)plt.title(&#x27;result&#x27;), plt.axis(&#x27;off&#x27;)plt.show() 低通滤波1234567891011121314151617181920import cv2import numpy as npimport matplotlib.pyplot as pltimg = cv2.imread(&#x27;/Users/star/learning_python/picture/2.png&#x27;, 0)dft = cv2.dft(np.float32(img), flags=cv2.DFT_COMPLEX_OUTPUT)dshift = np.fft.fftshift(dft)rows, cols = img.shaperow, col = int(rows/2), int(cols/2)mask = np.zeros((rows, cols, 2), np.uint8)mask[row-50:row+50, col-50:col+50] = 1dst = dshift * maskidst = np.fft.ifftshift(dst)ishift = cv2.idft(idst)idst = cv2.magnitude(ishift[:, :, 0], ishift[:, :, 1])plt.subplot(121), plt.imshow(img, &#x27;gray&#x27;)plt.title(&#x27;img&#x27;), plt.axis(&#x27;off&#x27;)plt.subplot(122), plt.imshow(idst, &#x27;gray&#x27;)plt.title(&#x27;img&#x27;), plt.axis(&#x27;off&#x27;)plt.show() 高通滤波123456789101112131415161718import cv2import numpy as npimport matplotlib.pyplot as pltimg = cv2.imread(&#x27;电脑本地的图像地址&#x27;， 0)f = np.fft.fft2(img)fshift = np.fft.fftshift(f) rows,cols = img.shape[:2]crow,ccol = int(rows/2), int(cols/2)fshift[crow-30:crow+30, ccol-30:ccol+30] = 0ishift = np.fft.ifftshift(fshift)iimg = np.fft.ifft2(ishift)iimg = np.abs(iimg)plt.subplot(121),plt.imshow(img, &#x27;gray&#x27;)plt.title(&#x27;img&#x27;),plt.axis(&#x27;off&#x27;)plt.subplot(122),plt.imshow(iimg, &#x27;gray&#x27;)plt.title(&#x27;iimg&#x27;),plt.axis(&#x27;off&#x27;)plt.show()","categories":[{"name":"图像处理笔记","slug":"图像处理笔记","permalink":"http://yoursite.com/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"图像处理笔记","slug":"图像处理笔记","permalink":"http://yoursite.com/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/"}]},{"title":"学习java第一天——语言类型","slug":"学习java第一天——语言类型","date":"2020-08-10T02:05:32.378Z","updated":"2020-08-18T14:48:55.681Z","comments":true,"path":"2020/08/10/学习java第一天——语言类型/","link":"","permalink":"http://yoursite.com/2020/08/10/%E5%AD%A6%E4%B9%A0java%E7%AC%AC%E4%B8%80%E5%A4%A9%E2%80%94%E2%80%94%E8%AF%AD%E8%A8%80%E7%B1%BB%E5%9E%8B/","excerpt":"解释型语言解释型语言的典型：python、JavaScript、Ruby等。","text":"解释型语言解释型语言的典型：python、JavaScript、Ruby等。 解释型语言的特点，我理解的就是解释一句跑一句子，如果下边语句有错误，并不会影响上边语句的执行。要想写小的程序，基本上可以忽略执行效率的基础上，还想让程序能成功跑下去，解释型语言还是很香的。 编译型语言编译型语言的典型：C和C++等 汇编型语言的特点，我理解的就是把所有语句都从头理一遍，如果其中出现一句语句有错误，整个程序都无法运行。所以要想提高程序的执行效率，要想写大工程文件，还是要转换成编译型语言的。 编译型—解释型语言典型代表:Java 严格地说，Java其实就是解释型语言，其所谓的编译过程只是将.java文件编程成.class文件，并不是向C一样编译成可执行的机器语言，在此请读者注意Java中所谓的“编译”和传统的“编译”的区别；然后生成的.class文件再逐句进行解释，在Java的虚拟机JVM中运行。在现实中，java开发工具JDK提供了两个很重要的命令来完成上面的编译和解释（翻译）过程：javac.exe是将.java文件编译成.class文件，而java.exe是将.class文件解释执行吧 总结解释器与编译器两者各有优势：当程序需要迅速启动和执行的时候，解释器可以首先发挥作用，省去编译的时间，立即执行。在程序运行后，随着时间的推移，编译器逐渐发挥作用，把越来越多的代码编译成本地代码之后，可以获取更高的执行效率。 当程序运行环境中内存资源限制较大（如部分嵌入式系统中），可以使用解释执行节约内存，反之可以使用编译执行来提升效率。 但随着硬件的升级和设计思想的变革，编译型和解释型语言越来越笼统，主要体现在一些新兴的高级语言上，而解释型语言的自身特点也使得编译器厂商愿意花费更多成本来优化解释器，解释型语言性能超过编译型语言也是必然的。","categories":[{"name":"java笔记","slug":"java笔记","permalink":"http://yoursite.com/categories/java%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"java笔记","slug":"java笔记","permalink":"http://yoursite.com/tags/java%E7%AC%94%E8%AE%B0/"}]}],"categories":[{"name":"图像处理笔记","slug":"图像处理笔记","permalink":"http://yoursite.com/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/"},{"name":"java笔记","slug":"java笔记","permalink":"http://yoursite.com/categories/java%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"图像处理笔记","slug":"图像处理笔记","permalink":"http://yoursite.com/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/"},{"name":"java笔记","slug":"java笔记","permalink":"http://yoursite.com/tags/java%E7%AC%94%E8%AE%B0/"}]}