<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title></title>
      <link href="/callme-star.github.io/2020/08/21/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E2%80%94%E2%80%94tensorflow3/"/>
      <url>/callme-star.github.io/2020/08/21/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E2%80%94%E2%80%94tensorflow3/</url>
      
        <content type="html"><![CDATA[<h3 id="学习目标"><a href="#学习目标" class="headerlink" title="学习目标"></a>学习目标</h3><ul><li>预备知识</li><li>神经复杂度</li><li>指数衰减学习率</li><li>激活函数</li><li>损失减数</li><li>欠拟合和过拟合</li><li>正则化减少过拟合</li><li>优化器更新网络参数</li></ul><h4 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h4><ul><li><p>tf.where()</p><p>tf.where(条件语句，真返回A，假返回B)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line">b = tf.constant([<span class="number">0</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">c = tf.where(tf.greater(a,b),a,b)    <span class="comment">#若a&gt;b,返回a对应位置的元素，否则返回b对应位置的元素</span></span><br><span class="line">print(c)</span><br></pre></td></tr></table></figure></li><li><p>tf.random.RandomState.rand()</p><p>tf.random.RandomState.rand(维度)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpya <span class="keyword">as</span> np</span><br><span class="line">rdm = np.random.RandomState(seed=<span class="number">1</span>)    <span class="comment">#seed相同生成的随机数相同</span></span><br><span class="line">a = rdm.rand()      <span class="comment">#返回一个随机标量</span></span><br><span class="line">b = rdm.rand(<span class="number">2</span>,<span class="number">3</span>)      <span class="comment">#返回一个两行三列的随机矩阵</span></span><br><span class="line">print(a)</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>tf.vstack()</p><p>将两个数组按垂直方向叠加</p><p>np.vstack(数组1，数组2)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">b = np.array([<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>])</span><br><span class="line">c = vstack(<span class="string">&#x27;c为：&#x27;</span>，c)</span><br></pre></td></tr></table></figure></li><li><p>np.mgrid[]  , .ravel()  , np.c_[]</p><p>用来制表</p><p>np.mgrid[起始值，结束值，步长]</p><p>x.ravel()</p><p>将x变为一维数组，把变量拉直</p><p>np.c_[数组1， 数组2]</p><p>将两个数组进行配对，补成一个大数组</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x,y = np.mgrid[<span class="number">1</span>:<span class="number">3</span>:<span class="number">1</span>, <span class="number">2</span>:<span class="number">4</span>:<span class="number">0.5</span>]</span><br><span class="line">grid = np.c_[x.ravel(),y.ravelz()]</span><br><span class="line">print(x)</span><br><span class="line">print(y)</span><br><span class="line">print(grid)</span><br></pre></td></tr></table></figure></li></ul><h4 id="复杂度学习率"><a href="#复杂度学习率" class="headerlink" title="复杂度学习率"></a>复杂度学习率</h4>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow第二节</title>
      <link href="/callme-star.github.io/2020/08/19/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E2%80%94%E2%80%94tensorflow2/"/>
      <url>/callme-star.github.io/2020/08/19/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E2%80%94%E2%80%94tensorflow2/</url>
      
        <content type="html"><![CDATA[<h3 id="鸢尾花分类"><a href="#鸢尾花分类" class="headerlink" title="鸢尾花分类"></a>鸢尾花分类</h3><p>三种鸢尾花，有四种特征，四个数据同时输入，权重共有3*4=12组, [1,4]✖️[4,3]</p><a id="more"></a><h4 id="鸢尾花数据读入"><a href="#鸢尾花数据读入" class="headerlink" title="鸢尾花数据读入"></a>鸢尾花数据读入</h4><p>从sklearn包dataset读入数据集，语法为：</p><blockquote><p>from sklearn.datasets import load_iris</p><p>x_data = datasets.load_isis().data</p><p>y_data = datasets.load_isis().target</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">x_data = datasets.load_isis().data    <span class="comment">#.data返回数据集的输入特征</span></span><br><span class="line">y_data = datasets.load_isis().target      <span class="comment"># 。target返回数据集的所有标签</span></span><br><span class="line">print(x_data)</span><br><span class="line">print(y_data)</span><br><span class="line"></span><br><span class="line">x_data = DataFrame(x_data,columes=[<span class="string">&quot;花萼长&quot;</span>，<span class="string">&quot;花萼宽&quot;</span>，<span class="string">&quot;花瓣长&quot;</span>，<span class="string">&quot;花瓣宽&quot;</span>])   <span class="comment"># 将数据转换成表格形式</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;display.unicode.east_asian_width&#x27;</span>,<span class="literal">True</span>)   <span class="comment">#设置列名对齐</span></span><br><span class="line">print(<span class="string">&quot;x_data add index: \n&quot;</span>,x_data)</span><br><span class="line">x_data[<span class="string">&#x27;类别&#x27;</span>] = y_data    <span class="comment">#新增加一列，标签为类别，数据为y_data</span></span><br><span class="line">print(<span class="string">&quot;x_data add a colum: \n&quot;</span>,x_data)</span><br></pre></td></tr></table></figure><p>在运行过程中会提示我们缺少数据包，然后我们用python自带的pip下载安装即可（比如：pip install sklearn）</p><h4 id="神经网络实现鸢尾花分类"><a href="#神经网络实现鸢尾花分类" class="headerlink" title="神经网络实现鸢尾花分类"></a>神经网络实现鸢尾花分类</h4><blockquote><p>1、准备数据</p></blockquote><ul><li>数据集读入</li><li>数据集乱序</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">116</span>)    <span class="comment">#使用相同的seed使输入特征标签一一对应</span></span><br><span class="line">np.random.shuffle（x_data）</span><br><span class="line">np.random.seed(<span class="number">116</span>)</span><br><span class="line">np.random.shuffle(y_data)</span><br><span class="line">tf.random.set_seed(<span class="number">116</span>)</span><br></pre></td></tr></table></figure><ul><li><p>数据集分出永不相见的训练集和测试集</p><p>训练集为前120行，测试集为最后30行</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_train = x_data[:<span class="number">-30</span>]</span><br><span class="line">y_train = y_data[:<span class="number">-30</span>]</span><br><span class="line">x_test = x_data[<span class="number">-30</span>:]</span><br><span class="line">y_test = y_data[<span class="number">-30</span>:]</span><br></pre></td></tr></table></figure><ul><li><p>配成【输入特征， 标签】对，每次喂入一小撮（batch）</p><p>每32组数据打包成一个batch</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_db = tf.data.Dataset.from_tensor_slice((x_train,y_train)).batch(<span class="number">32</span>)</span><br><span class="line">test_db = tf.data.Dataset.from_tensor_slice((x_train,y_train)).batch(<span class="number">32</span>)</span><br></pre></td></tr></table></figure><blockquote><p>搭建网络</p></blockquote><p>定义神经网络中所有可训练参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">w1 = tf.Variable(tf.random.truncated_normal([<span class="number">4</span>,<span class="number">3</span>],stddev = <span class="number">0</span>, seed =<span class="number">1</span>))</span><br><span class="line">b1 = tf.Variable(tf.random.truncated_normal([<span class="number">3</span>],stddev=<span class="number">0.1</span>,seed=<span class="number">1</span>))</span><br></pre></td></tr></table></figure><blockquote><p>参数优化</p></blockquote><p>嵌套循环迭代，with结构更新参数，显示当前loss</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epoch):   <span class="comment">#数据集级别迭代</span></span><br><span class="line">  <span class="keyword">for</span> step,(x_train,y_train) <span class="keyword">in</span> enumerate(train_db):</span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:     <span class="comment">#记录梯度信息</span></span><br><span class="line">      <span class="comment">#向前传播过程计算y</span></span><br><span class="line">      <span class="comment">#计算总的loss</span></span><br><span class="line">      y = tf.matmul(x_train,w1)+b1     <span class="comment">#神经网络乘加运算</span></span><br><span class="line">      y = tf.nn.softmax(y)    <span class="comment">#使输出y符和概率分布，此操作后和独热码同量级</span></span><br><span class="line">      y_ = tf.one_hot(y_train，depth = <span class="number">3</span>)  <span class="comment">#将标签转换为独热码形式</span></span><br><span class="line">      loss = tf.reduce_mean(tf.quare(y_-y))</span><br><span class="line">      loss_all += loss.numpy()</span><br><span class="line">    grads = tap.gradient(loss.[w1,b1])    <span class="comment">#计算loss对各个参数的梯度</span></span><br><span class="line">    <span class="comment">#实现梯度的更新：w1=w1-lr*w1_grad, b1= b1-lr*b_grad</span></span><br><span class="line">    w1.assign_sub(lr*grads[<span class="number">0</span>])     <span class="comment">#参数自更新</span></span><br><span class="line">    b1.assign_sub(lr*grads[<span class="number">1</span>])     <span class="comment">#其中的lr是学习率</span></span><br><span class="line">  print(<span class="string">&quot;Epoch &#123;&#125;,loss:&#123;&#125;&quot;</span>.format(epoch,loss_all/<span class="number">4</span>))</span><br></pre></td></tr></table></figure><blockquote><p>测试效果</p></blockquote><p>计算当前参数向前传播后的准确率，显示当前acc</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> x_test,y_test <span class="keyword">in</span> test_db:</span><br><span class="line">  y = tf.matmul(h,w)+b      <span class="comment">#y为预测结果</span></span><br><span class="line">  y = tf.nn.softmax(y)       <span class="comment">#是结果符合概率分布</span></span><br><span class="line">  pred= tf.argmax(y,axis=<span class="number">1</span>)    <span class="comment">#返回y中最大值的索引，即预测的分类</span></span><br><span class="line">  pred= tf.case(pred,dtype=y_type.dtype)    <span class="comment">#调整数据类型，与标签一致 </span></span><br><span class="line">  correct = tf.cast(tf.equal(pred,y_test),dtype = tf.int32)</span><br><span class="line">  correct = tf.reduce_sum(correct)     <span class="comment">#将每个batch的correct数加起来</span></span><br><span class="line">  total_correct += int(correct)    <span class="comment">#将所有batch中的correct数加起来</span></span><br><span class="line">  total_number +=x_test.shape[<span class="number">0</span>]</span><br><span class="line">acc = total_correct/total_number</span><br><span class="line">print(<span class="string">&quot;test_acc:&quot;</span>, acc)</span><br></pre></td></tr></table></figure><blockquote><p>acc/loss 可视化</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.title(<span class="string">&quot;acc curve&quot;</span>)  <span class="comment">#图片标题</span></span><br><span class="line">plt.xlabel(<span class="string">&quot;epoch&quot;</span>)   <span class="comment"># x轴名字</span></span><br><span class="line">plt,ylabel(<span class="string">&quot;acc&quot;</span>)      <span class="comment">#y轴名字</span></span><br><span class="line">plt.plot(test_acc,label=<span class="string">&quot;$Accuracy$&quot;</span>)    <span class="comment">#逐点画出test_acc值并连线</span></span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>本文先对代码的整个大体流程有一个感性的认识，详细过程，下面会有讲解！</p>]]></content>
      
      
      <categories>
          
          <category> 图像处理笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图像处理笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow第一节</title>
      <link href="/callme-star.github.io/2020/08/19/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E2%80%94%E2%80%94tensorflow1/"/>
      <url>/callme-star.github.io/2020/08/19/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E2%80%94%E2%80%94tensorflow1/</url>
      
        <content type="html"><![CDATA[<h3 id="常用函数"><a href="#常用函数" class="headerlink" title="常用函数"></a>常用函数</h3><h4 id="1、类型转换"><a href="#1、类型转换" class="headerlink" title="1、类型转换"></a>1、类型转换</h4><ul><li>强制tensor转换为该数据类型</li></ul><p>tf.case(张量名, dtype=数据类型)</p><a id="more"></a><ul><li>计算张量维度上元素的最小值</li></ul><p>tf.reduce_min(张量名)</p><ul><li>计算张量维度上元素的最大值</li></ul><p>tf.reduce_max(张量名)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x1 = tf.constant([<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>], dtype = tf.float64)</span><br><span class="line">print(x1)</span><br><span class="line">x2 = tf.case(x1, tf.int32)</span><br><span class="line">print(x2)</span><br><span class="line">print(tf.reduce_min(x2), tf.reduce_max(x2))</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.Tensor([<span class="number">1.2</span><span class="number">.3</span>.], shape = (<span class="number">3</span>,), dtype = float64)</span><br><span class="line">tf.Tensor([<span class="number">1</span> <span class="number">2</span> <span class="number">3</span>], shape = (<span class="number">3</span>,), dtype = int32)</span><br><span class="line">tf.Tensor(<span class="number">1</span>, shape = (), dtype = int32)</span><br><span class="line">tf.Tensor(<span class="number">3</span>, shape = (), dtype = int32)</span><br></pre></td></tr></table></figure><h4 id="2、理解axis"><a href="#2、理解axis" class="headerlink" title="2、理解axis"></a>2、理解axis</h4><p>在一个二维向量中axis=0代表以列为单位求取最大值，axis代表以行为单位求取最大值，如果不指定，则所有元素都参与运算</p><ul><li>计算张量沿着指定维度的平均值</li></ul><p>tf.reduce_mean(张量名, axis=操作轴)</p><ul><li>计算张量沿着指定维度的和</li></ul><p>tf.reduce_sum(张量名, axis=操作轴)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = tf.constant([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>]])</span><br><span class="line">print(x)</span><br><span class="line">print(tf.reduce_mean(x))</span><br><span class="line">print(tf.reduce_sum(x,axis=<span class="number">1</span>))</span><br></pre></td></tr></table></figure><h4 id="3、运算"><a href="#3、运算" class="headerlink" title="3、运算"></a>3、运算</h4><ul><li>将变量标记为可训练</li></ul><p>tf.Variable（初始值）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.Variable(tf.random.normal([<span class="number">2</span>,<span class="number">2</span>], mean = <span class="number">0</span>, stddev = <span class="number">1</span>))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a = tf.ones([<span class="number">1</span>, <span class="number">3</span>])   <span class="comment"># 1*3的矩阵赋值为1</span></span><br><span class="line">b = tf.fill([<span class="number">1</span>,<span class="number">3</span>], <span class="number">3.</span>)  <span class="comment"># 1*3的矩阵赋值为3</span></span><br><span class="line">print(a)</span><br><span class="line">print(b)</span><br><span class="line">print(tf.add(a, b))</span><br><span class="line">print(tf.subtract(a, b))</span><br><span class="line">print(tf.multiply(a, b))</span><br><span class="line">print(tf.divide(b, a))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = tf.fill([<span class="number">1</span>,<span class="number">2</span>], <span class="number">3.</span>)</span><br><span class="line">print(a)</span><br><span class="line">print(tf.pow(a, <span class="number">3</span>))</span><br><span class="line">print(tf.square(a))</span><br><span class="line">print(tf.sqrt(a))</span><br></pre></td></tr></table></figure><h4 id="4、对应标签和数据"><a href="#4、对应标签和数据" class="headerlink" title="4、对应标签和数据"></a>4、对应标签和数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">features = tf.constant([<span class="number">12</span>, <span class="number">23</span>, <span class="number">10</span> ,<span class="number">17</span>])     <span class="comment">#获取数据</span></span><br><span class="line">labels = tf.constant([<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>])       <span class="comment">#获取标签</span></span><br><span class="line">dataset = tf.data.Dataset.from_tensor_slices((features,labels))</span><br><span class="line">print(dataset)</span><br><span class="line"><span class="keyword">for</span> element <span class="keyword">in</span> dataset：</span><br><span class="line">    print(element)</span><br></pre></td></tr></table></figure><h4 id="5、求导运算"><a href="#5、求导运算" class="headerlink" title="5、求导运算"></a>5、求导运算</h4><p>with结构记录计算过程，gradient求出张量的梯度</p><blockquote><p>with tf.GradientTape() as tape:</p><p>若干计算过程</p><p>grad=tape.gradient(函数，对谁求导)</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">  w = tf.Variable(tf.constant(<span class="number">3.0</span>))</span><br><span class="line">  loss = tf.pow(w, <span class="number">2</span>)</span><br><span class="line">grad = tape.gradient(loss, w)</span><br><span class="line">print(grad)</span><br></pre></td></tr></table></figure><h4 id="6、enumerate"><a href="#6、enumerate" class="headerlink" title="6、enumerate"></a>6、enumerate</h4><p>enumerate是python的内建函数，他可以遍历元素，元组或字符串</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">seq = [<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;three&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> i, element <span class="keyword">in</span> enumerate(seq):</span><br><span class="line">  print(i, element)</span><br></pre></td></tr></table></figure><h4 id="7、tf-one-hot-独热编码"><a href="#7、tf-one-hot-独热编码" class="headerlink" title="7、tf.one_hot      独热编码"></a>7、tf.one_hot      独热编码</h4><p>在分类问题中，常用独热码作为标签，标记类别：0代表非，1表示是</p><blockquote><p>标签：1</p><p>独热码： （0， 1， 0）</p><p>表示是标签0的概率为0，是标签1的概率是百分百，是标签2的概率是0</p></blockquote><h4 id="8、tf-one-hot-待转换数据，depth-几分类"><a href="#8、tf-one-hot-待转换数据，depth-几分类" class="headerlink" title="8、tf.one_hot(待转换数据，depth=几分类)"></a>8、tf.one_hot(待转换数据，depth=几分类)</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">classes = <span class="number">3</span></span><br><span class="line">labels = tf.constant([<span class="number">1</span>,<span class="number">0</span>,<span class="number">2</span>])</span><br><span class="line">output = tf.one_hot(labels, depth = classes)</span><br><span class="line">print(output)</span><br></pre></td></tr></table></figure><h4 id="9、tf-nn-softmax"><a href="#9、tf-nn-softmax" class="headerlink" title="9、tf.nn.softmax"></a>9、tf.nn.softmax</h4><p>tf.nn.softmax能把n个分类的n个输出转换成0到1之间的概率值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y = tf.constant([<span class="number">1.01</span>, <span class="number">2.01</span>, <span class="number">-0.66</span>])     <span class="comment">#定义一些数值</span></span><br><span class="line">y_pro = tf.nn.softmax(y)      <span class="comment">#转换成标准概率</span></span><br><span class="line">print(<span class="string">&quot;result, y_pro is &quot;</span>,y_pro)</span><br></pre></td></tr></table></figure><h4 id="10、tf-argmax"><a href="#10、tf-argmax" class="headerlink" title="10、tf.argmax"></a>10、tf.argmax</h4><p>返回张量最大值得索引，tf.argmax(张量名，axis=操作轴)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">test = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">4</span>,<span class="number">3</span>],[<span class="number">8</span>,<span class="number">7</span>,<span class="number">2</span>]])</span><br><span class="line">print(test)</span><br><span class="line">print(tf.argmax(test,axis=<span class="number">0</span>))</span><br><span class="line">print(tf.argmax(test,axis=<span class="number">0</span>))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 图像处理笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图像处理笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>理解边缘检测sift</title>
      <link href="/callme-star.github.io/2020/08/18/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E7%89%B9%E5%BE%81%E7%82%B9%E6%A3%80%E6%B5%8Bsift/"/>
      <url>/callme-star.github.io/2020/08/18/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E7%89%B9%E5%BE%81%E7%82%B9%E6%A3%80%E6%B5%8Bsift/</url>
      
        <content type="html"><![CDATA[<p>图像处理——sift理解</p><h3 id="通俗的大致理解"><a href="#通俗的大致理解" class="headerlink" title="通俗的大致理解"></a>通俗的大致理解</h3><ol><li>首先，理解同一幅<strong>图像在不同的空间中有不同的表达方式</strong>。比如在RGB空间中，图像中的像素点可以用颜色值(r,g,b)来表示；在灰度空间中，图像中的像素点可以用灰度值来表示。类似的，你可以把梯度图像认为是图像在<strong>梯度空间</strong>中的一种表达，图像中的像素点可以<strong>用梯度方向</strong>来表示，即，梯度图像中的像素点表达的是该点的梯度方向（而不是灰度值/颜色值）。</li></ol><a id="more"></a><ol><li>其次，理解图像的<strong>灰度直方图是什么</strong>。图像的灰度直方图就是把<strong>灰度图像中灰度值分别为0,1,…,255的像素的个数统计起来</strong>，得到的一个一维向量。类似的，图像的梯度直方图就是把<strong>梯度图像中梯度方向分别为0°到360°的像素的个数统计起来</strong>，得到一个一维向量。</li></ol><p>SIFT是什么？简单来说就是图像中某个局部区域（如16*16像素的一个区域）对应的梯度直方图，这就是最简单直观的理解。当然，SIFT还包括各种细节，如量化，尺度金字塔、旋转不变性、局部归一化等，这些东西很多博客上都有“教科书般”的介绍。</p><p>SURF是什么？SURF本身不是什么新的descriptor，而是对SIFT实现上的加速，核心点在于采用<strong>积分图</strong>对计算加速。</p><p>作者：大道至简知不语<br>链接：<a href="https://www.zhihu.com/question/40736560/answer/358547318">https://www.zhihu.com/question/40736560/answer/358547318</a><br>来源：知乎</p><p><strong>知识点：积分图</strong></p><h3 id="sift深度剖析"><a href="#sift深度剖析" class="headerlink" title="sift深度剖析"></a>sift深度剖析</h3><h4 id="1、明确学习目的"><a href="#1、明确学习目的" class="headerlink" title="1、明确学习目的"></a>1、明确学习目的</h4><p>不管是Harris还是Shi-Tomas，角点检测检测即便做得再优化，也总是有不可克服的缺点：</p><ul><li><strong>对尺度很敏感，不具有尺度不变性</strong></li><li><strong>需要设计角点匹配算法</strong></li></ul><p>而SIFT算法是一种基于局部兴趣点的算法，因此</p><ul><li><strong>不仅对图片大小和旋转不敏感</strong></li><li><strong>而且对光照、噪声等影响的抗击能力也非常优秀</strong></li></ul><p>因此，该算法在性能和适用范围方面较于之前的算法有着质的改变。</p><p>在学习sift算法之前，我们先得搞明白这个算法目的是为了干什么，无非就是找到图像中的特征点，找到优质的特征点。</p><p>优质的特征点有什么特征呢？</p><ul><li><strong>尺度不变性：</strong>人类在识别一个物体时，不管这个物体或远或近，都能对它进行正确的辨认，这就是所谓的尺度不变性。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/CallMe-star/picbed@master/cat_scale.jpg"></p><ul><li><strong>旋转不变性：</strong>当这个物体发生旋转时，我们照样可以正确地辨认它，这就是所谓的旋转不变性。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/CallMe-star/picbed@master/cat_direct.jpg"></p><h4 id="2、sift过程"><a href="#2、sift过程" class="headerlink" title="2、sift过程"></a>2、sift过程</h4><h5 id="构建多尺度的高斯金字塔"><a href="#构建多尺度的高斯金字塔" class="headerlink" title="构建多尺度的高斯金字塔"></a>构建多尺度的高斯金字塔</h5><blockquote><p>①构建单尺度的空间，单尺度空间有6张图，六张图分别是经过方差大小不同的高斯滤波处理的图</p></blockquote><blockquote><p>②然后对同一尺度的一组照片中的相邻滤波处理的照片做差得到的就是图像的轮廓，轮廓就是我们要得到的最基本的特征。做差得出的图像就叫做DoG。</p></blockquote><blockquote><p>③然后再分成多个尺度，小尺度是通过上一层大尺度的第三张照片作为原图再次进行高斯滤波得到的。这一步就是要解决尺度的问题：构建金字塔，将特征值拓展到多分辨率上。</p><p><strong><em>我的疑惑点：这么多尺度的图像他是怎样提取不同尺度的图像，然后融合在一起的</em></strong></p></blockquote><h5 id="检测尺度空间的极值点"><a href="#检测尺度空间的极值点" class="headerlink" title="检测尺度空间的极值点"></a>检测尺度空间的极值点</h5><blockquote><p>直接遍历找出极值点，极值点不但要根这个点周围的八个点比较，还要跟同一层相邻的另外两张图像作比较。一共比较26个点。注意做完这一步之后，应该就可以在原图上画出来极值点坐标了示意图了。</p></blockquote><h5 id="精确定位极值点"><a href="#精确定位极值点" class="headerlink" title="精确定位极值点"></a>精确定位极值点</h5><blockquote><p>上一步我们已经找到了相关的特征点的大致坐标，接下来就要确定他们的准确位置，这里牵涉到很多数学运算。</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/CallMe-star/picbed@master/jingqueweizhi.jpg"></p><h5 id="选取特征点的方向"><a href="#选取特征点的方向" class="headerlink" title="选取特征点的方向"></a>选取特征点的方向</h5><blockquote><p>对我们已经用金字塔解决了尺度不变性问题，下面就要通过确定特征点的方向来解决旋转不变性问题。完成关键点的梯度计算后，使用直方图统计邻域内像素的梯度和方向。梯度直方图将0~360度的方向范围分为36个柱(bins)，其中每柱10度。如图所示，直方图的峰值方向代表了关键点的主方向，(为简化，图中只画了八个方向的直方图)。</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/CallMe-star/picbed@master/direction.jpg"></p><blockquote><p><strong>直方图的峰值则代表了该关键点处邻域梯度的主方向，即作为该关键点的方向；其他的达到最大值80%的方向可作为辅助方向。</strong>到这里我们已经检测出的含有位置、尺度和方向的关键点即是该图像的SIFT特征点。</p></blockquote><h5 id="生成关键描述子"><a href="#生成关键描述子" class="headerlink" title="生成关键描述子"></a>生成关键描述子</h5><p>到这里还没有结束</p><p>金字塔保证特征点的空间不变性， 严格删选保证了特征点的准确性， 方向信息保证了特征点的旋转不变性。我们如何把所有信息作为属性附加给关键点呢？</p><p>①为什么要添加描述子：通过上面的步骤，对于每一个关键点，拥有三个信息：<strong>位置、尺度以及方向</strong>。接下来就是为每个关键点建立一个描述符，用一组向量将这个关键点描述出来，使其不随各种变化而改变，比如光照变化、视角变化等等。这个描述子不但包括关键点，也包含关键点周围对其有贡献的像素点，并且描述符应该有较高的独特性，以便于提高特征点正确匹配的概率。</p><p>②添加过程：<strong>1) 确定计算描述子所需的图像区域</strong>特征描述子与特征点所在的尺度有关，因此，对梯度的求取应在特征点对应的高斯图像上进行。将关键点附近的邻域划分为d*d(Lowe建议d=4)个子区域，每个子区域做为一个种子点，每个种子点有8个方向。每个子区域的大小与关键点方向分配时相同。</p><p><img src="https://cdn.jsdelivr.net/gh/CallMe-star/picbed@master/miaoshuziimg.jpg"></p><p>以关键点为中心，4*4格为一个种子点，每个种子点8个方向。</p><p>每一个小格都代表了特征点邻域所在的尺度空间的一个像素 ，箭头方向代表了像素梯度方向，箭头长度代表该像素的幅值。然后在4×4的窗口内计算8个方向的梯度方向直方图。绘制每个梯度方向的累加可形成一个种子点。</p><ul><li><strong>2) 将坐标轴旋转为关键点的方向，以确保旋转不变性</strong></li></ul><p><img src="https://cdn.jsdelivr.net/gh/CallMe-star/picbed@master/xuanzhuanxy.jpg"></p><ul><li><strong>3) 将邻域内的采样点分配到对应的子区域内，将子区域内的梯度值分配到8个方向上，计算其权值</strong></li></ul><p><img src="https://www.zhihu.com/equation?tex=w=m(a+x,+b+y)+*+e%5E%7B-%5Cfrac%7B%5Cleft(x%5E%7B%5Cprime%7D%5Cright)%5E%7B2%7D+%5Cleft(y%5E%7B%5Cprime%7D%5Cright)%5E%7B2%7D%7D%7B2+%5Ctimes(0.5+d)%5E%7B2%7D%7D%7D" alt="[公式]"></p><p>其中a，b为关键点在高斯金字塔图像中的位置坐标。</p><ul><li><strong>4) 插值计算每个种子点八个方向的梯度</strong></li></ul><p><img src="https://cdn.jsdelivr.net/gh/CallMe-star/picbed@master/zhongzitidu.jpg"></p><ul><li><strong>5) 归一化</strong></li></ul><p>如上统计的4<em>4</em>8=128个梯度信息即为该关键点的特征向量。特征向量形成后，为了去除光照变化的影响，需要对它们进行归一化处理，对于图像灰度值整体漂移，图像各点的梯度是邻域像素相减得到，所以也能去除。</p><ul><li><strong>6） 向量门限</strong></li></ul><p>描述子向量门限。非线性光照，相机饱和度变化对造成某些方向的梯度值过大，而对方向的影响微弱。因此设置门限值(向量归一化后，一般取0.2)截断较大的梯度值。然后，再进行一次归一化处理，提高特征的鉴别性。</p><ul><li><strong>7） 排序</strong></li></ul><p>按特征点的尺度对特征描述向量进行排序。</p><p><img src="https://cdn.jsdelivr.net/gh/CallMe-star/picbed@master/paixu.jpg"></p><p>在每个4<em>4的1/16象限中，通过加权梯度值加到直方图8个方向区间中的一个，计算出一个梯度方向直方图。这样就可以对每个feature形成一个4</em>4<em>8=128维的描述子，每一维都可以表示4</em>4个格子中一个的scale/orientation. 将这个向量归一化之后，就进一步去除了光照的影响。</p><h4 id="3-sift怎么匹配"><a href="#3-sift怎么匹配" class="headerlink" title="3.sift怎么匹配"></a>3.sift怎么匹配</h4><p><strong>1、 首先还是要对图片生成特征点</strong></p><p>一张图经过SIFT算法后，会得到多个特征点，每个特征点有128维的描述子属性。那么，匹配特征点都简单多啦！</p><p>生成了A、B两幅图的描述子，（分别是k1<em>128维和k2</em>128维），就将两图中各个scale（所有scale）的描述子进行匹配，匹配上128维即可表示两个特征点match上了。</p><p><strong>2、 然后考虑怎么匹配</strong></p><p>当两幅图像的SIFT特征向量生成后，下一步我们采用关键点特征向量的欧式距离来作为两幅图像中关键点的相似性判定度量。取图像1中的某个关键点，并找出其与图像2中欧式距离最近的前两个关键点，在这两个关键点中，如果最近的距离除以次近的距离少于某个比例阈值，则接受这一对匹配点。降低这个比例阈值，SIFT匹配点数目会减少，但更加稳定。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/xfeatures2d.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv::xfeatures2d;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>** argv)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    Mat cat = imread(<span class="string">&quot;cat.png&quot;</span>);</span><br><span class="line">    Mat smallCat = imread(<span class="string">&quot;smallCat.png&quot;</span>);</span><br><span class="line">    imshow(<span class="string">&quot;cat image&quot;</span>, cat);</span><br><span class="line">    imshow(<span class="string">&quot;smallCat image&quot;</span>, smallCat);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> detector = SIFT::create();</span><br><span class="line">    <span class="built_in">vector</span>&lt;KeyPoint&gt; keypoints_cat, keypoints_smallCat;</span><br><span class="line">    Mat descriptor_cat, descriptor_smallCat;</span><br><span class="line">    detector-&gt;detectAndCompute(cat, Mat(), keypoints_cat, descriptor_cat);</span><br><span class="line">    detector-&gt;detectAndCompute(smallCat, Mat(), keypoints_smallCat, descriptor_smallCat);</span><br><span class="line"></span><br><span class="line">    Ptr&lt;FlannBasedMatcher&gt; matcher = FlannBasedMatcher::create();</span><br><span class="line">    <span class="built_in">vector</span>&lt;DMatch&gt; matches;</span><br><span class="line">    matcher-&gt;match(descriptor_cat, descriptor_smallCat, matches);</span><br><span class="line">    Mat dst;</span><br><span class="line">    drawMatches(cat, keypoints_cat, smallCat, keypoints_smallCat, matches, dst);</span><br><span class="line">    imshow(<span class="string">&quot;match-demo&quot;</span>, dst);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    waitKey(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://picb.zhimg.com/80/v2-295c77fc626560a0421be89e19516d6d_720w.jpg" alt="img"></p><p><img src="https://pic4.zhimg.com/80/v2-aac36afb03c30320918b8d3d9f7f986a_720w.jpg" alt="img"></p><p><img src="https://pic1.zhimg.com/80/v2-799a944fce5797047a6e8a18fb624d2e_720w.jpg" alt="img"></p><p>作者: lowkeyway</p><p>转载自: <a href="https://zhuanlan.zhihu.com/p/90122194">https://zhuanlan.zhihu.com/p/90122194</a></p>]]></content>
      
      
      <categories>
          
          <category> 图像处理笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图像处理笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>傅里叶变换</title>
      <link href="/callme-star.github.io/2020/08/10/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/"/>
      <url>/callme-star.github.io/2020/08/10/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/</url>
      
        <content type="html"><![CDATA[<p>图像处理——傅里叶</p><h3 id="1-傅里叶变换的理解"><a href="#1-傅里叶变换的理解" class="headerlink" title="1.傅里叶变换的理解"></a>1.傅里叶变换的理解</h3><p>傅里叶变换的相关数学公式目前还没有搞懂，先不整那个东西，我们主要是研究傅里叶变换的一些思想和应用。这个思想起源于牛顿研究那个三棱镜，白光透过棱镜之后会被分解为七种颜色的光，这些光叠加又能形成白光，所以说可以把一种事物分解成好几种事物的加和。</p><a id="more"></a><p>后来傅里叶就提出了**<em>傅里叶级数**</em>，一个等幅度不同频或者等频不同幅的波形可以由一组正弦波余弦波的加和得到（原话：任何连续周期信号可以由一组适当的正弦曲线组合而成）</p><h3 id="2-傅里叶级数"><a href="#2-傅里叶级数" class="headerlink" title="2.傅里叶级数"></a>2.傅里叶级数</h3><p>可以这么理解：原图像相当于在时间域中的一个曲线，坐标图是个二维坐标系，横轴是时间，纵轴是幅值的一个曲线，我们通过傅里叶变换可以把这条曲线变成多条正余弦函数相加的形式：傅里叶变换之后形成的是一个三维坐标系，他的x轴是频率（w），y轴是相位（因为每个正余弦函数的起点不同，有的是从零点开始，有的不是，这个曲线开始的那个幅值就是相位，相位就是后公式中的φ），z轴是振幅高度，。这样可以把一个图像从空间域转换到频率域，因为两者等价，所以可以逆变换回去。但这个傅里叶级数只能针对周期型函数才能拆分成多个正余弦函数相加，所以后来有了傅里叶变换。<br>$$<br>f(t) = \frac{a_n}{2}+\sum a_n*sin（nwt+φ_n）<br>$$</p><h3 id="3-傅里叶变换"><a href="#3-傅里叶变换" class="headerlink" title="3.傅里叶变换"></a>3.傅里叶变换</h3><p>其中推导公式中用到了欧拉公式，<br>$$<br>cos(x)+i*sin(x) = e^{ix}\<br>$$<br>$$<br>x = wt<br>$$</p><p>$$<br>F_T = \int_{-\infty}^{+\infty}f(t)e^{jwt}dt\<br>$$</p><p>然后通过逆变换可以再变回去。通过傅里叶变换就可以把一个随机的曲线，转换到频率域，只不过这次的三维坐标系对应的w和幅值的函数图像不再是离散的图像了，而是一个连续图像。y轴所对应的相位意义没变。</p><h3 id="4-应用"><a href="#4-应用" class="headerlink" title="4.应用"></a>4.应用</h3><h4 id="声音"><a href="#声音" class="headerlink" title="- 声音"></a>- 声音</h4><p>通过分析频率域，可以分析出低频可能是男生说话，高频可能是女生说话，再高的频率就是噪音了，除去这些高频信号，然后通过逆变换就可以得到处理后的音频。</p><p>在声音中，那刚才的傅里叶变换之前的x轴就是时间，y轴就是声音的振幅</p><p>如下图（copy from 知乎Heinrich）</p><p><img src="https://cdn.jsdelivr.net/gh/CallMe-star/picbed@master/fuliye1.jpg"></p><h4 id="图像"><a href="#图像" class="headerlink" title="- 图像"></a>- 图像</h4><p>通过分析频率域，他的低频部分可能就是画像的主体部分，高频部分可能是图像中的噪点，比如说是画面中的斑点噪音，旧照片中的斑点，通过去掉高频信号，然后逆变换回去，就得到去除噪点之后的图像。</p><p>在图像中，傅里叶变换之前的x轴就是图像的空间坐标位置，y轴就是他的灰度？？？</p><h3 id="5-OpenCV-，Numpy中操作一下"><a href="#5-OpenCV-，Numpy中操作一下" class="headerlink" title="5.OpenCV ，Numpy中操作一下"></a>5.OpenCV ，Numpy中操作一下</h3><h4 id="numpy中操作"><a href="#numpy中操作" class="headerlink" title="-numpy中操作"></a>-numpy中操作</h4><ol><li><p>np.fft.fft2</p><p>实现傅里叶变换并且返回一个复数数组</p></li><li><p>np.fft.fftshift</p><p>将零频率分量移动到频谱的中心</p></li><li><p>np.log（np.abs(fshift)）</p><p>刚才返回的复数数组没办法用图像的形式展示出来需要用以上函数转换到[0, 255]范围</p></li><li><p>np.fft.ifftshift</p><p>把中心化的频谱再移动回左上角</p></li><li><p>np.fft.ifft2</p><p>实现逆变换，返回一个复数数组</p></li><li><p>np.abs（逆傅里叶变换的结果）</p></li></ol><p>​        变回能显示的[0, 255]的可显示图像</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 直接读为灰度图像</span></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;你电脑本地的图像路径&#x27;</span>, <span class="number">0</span>)  </span><br><span class="line">f = np.fft.fft2(img)</span><br><span class="line">fshift = np.fft.fftshift(f)</span><br><span class="line"><span class="comment"># 取绝对值：将复数变化成实数</span></span><br><span class="line"><span class="comment"># 取对数的目的为了将数据变化到0-255</span></span><br><span class="line">s1 = np.log(np.abs(fshift))</span><br><span class="line">plt.subplot(<span class="number">131</span>), plt.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>, interpolation=<span class="string">&#x27;bicubic&#x27;</span>), plt.title(<span class="string">&#x27;original&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">132</span>), plt.imshow(s1, <span class="string">&#x27;gray&#x27;</span>, interpolation=<span class="string">&#x27;bicubic&#x27;</span>), plt.title(<span class="string">&#x27;center&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line"><span class="comment"># 逆变换</span></span><br><span class="line">f1shift = np.fft.ifftshift(fshift)</span><br><span class="line">img_back = np.fft.ifft2(f1shift)</span><br><span class="line"><span class="comment"># 出来的是复数，无法显示</span></span><br><span class="line">img_back = np.abs(img_back)</span><br><span class="line">plt.subplot(<span class="number">133</span>), plt.imshow(img_back, cmap=<span class="string">&#x27;gray&#x27;</span>, interpolation=<span class="string">&#x27;bicubic&#x27;</span>), plt.title(<span class="string">&#x27;img back&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h4 id="OpenCV中操作"><a href="#OpenCV中操作" class="headerlink" title="OpenCV中操作"></a>OpenCV中操作</h4><ol><li><p>返回结果 = cv2.dft(原始图像， 转换标识)</p><p>返回结果是双通道的，第一通道是结果的实数部分，第二通道是虚数部分</p><p>原始图像一般是整型八位位图，要转换成32位的（np.float32(img)）</p><p>转换标识一般flags = cv2.DFT_COMPLEX_OUTPUT,输出一个复数阵列</p></li><li><p>np.fft.fftshift</p><p>将零频率分量转换频谱中心</p></li><li><p>返回值 =  cv2.magnitude（参数1，参数2）</p><p>参数1：浮点的X坐标，也就是实部</p><p>参数2：浮点的Y坐标，也就是虚部</p><p>通过这个函数，将那个复数转换到[0, 255]</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;电脑本地的图像地址&#x27;</span>， <span class="number">0</span>)</span><br><span class="line">dft = cv2.dft(np.float32(img), flags = cv2.DFT_COMPLEX_OUTPUT)</span><br><span class="line">dftshift = np.fft.fftshift(dft)</span><br><span class="line">result = <span class="number">20</span>*np.log(cv2.magnitude(dftshift[:,:,<span class="number">0</span>], dftshift[:,:,<span class="number">1</span>]))</span><br><span class="line">ishift = np.fft.ifftshift(dftshift)</span><br><span class="line">iimg = cv2.idft(ishift)</span><br><span class="line">iimg = cv2.magnitude(iimg[:, :, <span class="number">0</span>], iimg[:, :, <span class="number">1</span>])</span><br><span class="line">plt.subplot(<span class="number">221</span>), plt.imshow(img,<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;img&#x27;</span>), plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">222</span>), plt.imshow(result,<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;result&#x27;</span>), plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">223</span>), plt.imshow(img, <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;img&#x27;</span>), plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">224</span>), plt.imshow(iimg, <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;result&#x27;</span>), plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="低通滤波"><a href="#低通滤波" class="headerlink" title="低通滤波"></a>低通滤波</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;/Users/star/learning_python/picture/2.png&#x27;</span>, <span class="number">0</span>)</span><br><span class="line">dft = cv2.dft(np.float32(img), flags=cv2.DFT_COMPLEX_OUTPUT)</span><br><span class="line">dshift = np.fft.fftshift(dft)</span><br><span class="line">rows, cols = img.shape</span><br><span class="line">row, col = int(rows/<span class="number">2</span>), int(cols/<span class="number">2</span>)</span><br><span class="line">mask = np.zeros((rows, cols, <span class="number">2</span>), np.uint8)</span><br><span class="line">mask[row<span class="number">-50</span>:row+<span class="number">50</span>, col<span class="number">-50</span>:col+<span class="number">50</span>] = <span class="number">1</span></span><br><span class="line">dst = dshift * mask</span><br><span class="line">idst = np.fft.ifftshift(dst)</span><br><span class="line">ishift = cv2.idft(idst)</span><br><span class="line">idst = cv2.magnitude(ishift[:, :, <span class="number">0</span>], ishift[:, :, <span class="number">1</span>])</span><br><span class="line">plt.subplot(<span class="number">121</span>), plt.imshow(img, <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;img&#x27;</span>), plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">122</span>), plt.imshow(idst, <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;img&#x27;</span>), plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h4 id="高通滤波"><a href="#高通滤波" class="headerlink" title="高通滤波"></a>高通滤波</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;电脑本地的图像地址&#x27;</span>， <span class="number">0</span>)</span><br><span class="line">f = np.fft.fft2(img)</span><br><span class="line">fshift = np.fft.fftshift(f)        </span><br><span class="line">rows,cols = img.shape[:<span class="number">2</span>]</span><br><span class="line">crow,ccol = int(rows/<span class="number">2</span>), int(cols/<span class="number">2</span>)</span><br><span class="line">fshift[crow<span class="number">-30</span>:crow+<span class="number">30</span>, ccol<span class="number">-30</span>:ccol+<span class="number">30</span>] = <span class="number">0</span></span><br><span class="line">ishift = np.fft.ifftshift(fshift)</span><br><span class="line">iimg = np.fft.ifft2(ishift)</span><br><span class="line">iimg = np.abs(iimg)</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(img, <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;img&#x27;</span>),plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">122</span>),plt.imshow(iimg, <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;iimg&#x27;</span>),plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 图像处理笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图像处理笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>学习java第三天——语言类型</title>
      <link href="/callme-star.github.io/2020/08/10/%E5%AD%A6%E4%B9%A0java%E7%AC%AC%E4%B8%89%E5%A4%A9%E2%80%94%E2%80%94%E8%AF%AD%E8%A8%80%E7%B1%BB%E5%9E%8B/"/>
      <url>/callme-star.github.io/2020/08/10/%E5%AD%A6%E4%B9%A0java%E7%AC%AC%E4%B8%89%E5%A4%A9%E2%80%94%E2%80%94%E8%AF%AD%E8%A8%80%E7%B1%BB%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="解释型语言"><a href="#解释型语言" class="headerlink" title="解释型语言"></a>解释型语言</h2><p>解释型语言的典型：python、JavaScript、Ruby等。</p><a id="more"></a><p>解释型语言的特点，我理解的就是解释一句跑一句子，如果下边语句有错误，并不会影响上边语句的执行。要想写小的程序，基本上可以忽略执行效率的基础上，还想让程序能成功跑下去，解释型语言还是很香的。</p><h2 id="编译型语言"><a href="#编译型语言" class="headerlink" title="编译型语言"></a>编译型语言</h2><p>编译型语言的典型：C和C++等</p><p>汇编型语言的特点，我理解的就是把所有语句都从头理一遍，如果其中出现一句语句有错误，整个程序都无法运行。所以要想提高程序的执行效率，要想写大工程文件，还是要转换成编译型语言的。</p><h2 id="编译型—解释型语言"><a href="#编译型—解释型语言" class="headerlink" title="编译型—解释型语言"></a>编译型—解释型语言</h2><p>典型代表:Java</p><p>严格地说，Java其实就是解释型语言，其所谓的编译过程只是将.java文件编程成.class文件，并不是向C一样编译成可执行的机器语言，在此请读者注意Java中所谓的“编译”和传统的“编译”的区别；然后生成的.class文件再逐句进行解释，在Java的虚拟机JVM中运行。在现实中，java开发工具JDK提供了两个很重要的命令来完成上面的编译和解释（翻译）过程：javac.exe是将.java文件编译成.class文件，而java.exe是将.class文件解释执行吧</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>解释器与编译器两者各有优势：当程序需要迅速启动和执行的时候，解释器可以首先发挥作用，省去编译的时间，立即执行。在程序运行后，随着时间的推移，编译器逐渐发挥作用，把越来越多的代码编译成本地代码之后，可以获取更高的执行效率。 当程序运行环境中内存资源限制较大（如部分嵌入式系统中），可以使用解释执行节约内存，反之可以使用编译执行来提升效率。</p><p>但随着硬件的升级和设计思想的变革，编译型和解释型语言越来越笼统，主要体现在一些新兴的高级语言上，而解释型语言的自身特点也使得编译器厂商愿意花费更多成本来优化解释器，解释型语言性能超过编译型语言也是必然的。</p>]]></content>
      
      
      <categories>
          
          <category> java笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>学习java第二天——终端命令</title>
      <link href="/callme-star.github.io/2020/08/06/%E5%AD%A6%E4%B9%A0Java%E7%AC%AC%E4%BA%8C%E5%A4%A9%E2%80%94%E2%80%94%E7%BB%88%E7%AB%AF%E5%91%BD%E4%BB%A4/"/>
      <url>/callme-star.github.io/2020/08/06/%E5%AD%A6%E4%B9%A0Java%E7%AC%AC%E4%BA%8C%E5%A4%A9%E2%80%94%E2%80%94%E7%BB%88%E7%AB%AF%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<h3 id="Dos和Linux的常用命令"><a href="#Dos和Linux的常用命令" class="headerlink" title="Dos和Linux的常用命令"></a>Dos和Linux的常用命令</h3><h4 id="Dos命令——我用的windows"><a href="#Dos命令——我用的windows" class="headerlink" title="Dos命令——我用的windows"></a>Dos命令——我用的windows</h4><ol><li><p>从默认的C盘切换到D盘或者其他盘符</p><p>命令：D:</p></li></ol><a id="more"></a><ol start="2"><li><p>磁盘操作，进入盘符下的文件夹</p><p>命令：cd + 文件夹名称</p></li><li><p>查看当前文件夹里面有哪些目录或者文件</p><p>命令：dir</p></li><li><p>显示当前文件夹</p><p>命令：chdir</p></li><li><p>返回上一级目录</p><p>命令：cd ..</p></li><li><p>创建文件夹</p><p>命令：mkdir</p></li><li><p>创建文件</p><p>命令：cd.&gt;a.txt</p></li><li><p>显示网络设置</p><p>命令：ipconfig</p></li><li><p>清屏</p><p>命令：cls</p></li></ol><h4 id="Linux命令——我用的mac"><a href="#Linux命令——我用的mac" class="headerlink" title="Linux命令——我用的mac"></a>Linux命令——我用的mac</h4><ol><li><p>从默认的C盘切换到D盘或者其他盘符</p><p>命令：D:</p></li><li><p>磁盘操作，进入盘符下的文件夹</p><p>命令：cd + 文件夹名称</p></li><li><p>查看当前文件夹里面有哪些目录或者文件</p><p>命令：ls</p></li><li><p>显示当前文件夹</p><p>命令：pwd</p></li><li><p>返回上一级目录</p><p>命令：cd ..</p></li><li><p>创建文件夹</p><p>命令：mkdir</p></li><li><p>创建文件</p><p>命令：touch a.txt</p></li><li><p>显示网络设置</p><p>命令：ifconfig</p></li><li><p>清屏</p><p>命令：clear</p></li></ol><hr><p>上边都是些基本入门常用的命令，用到其余的可以再找^-^</p><p>通过cd命令和dir命令（mac下的ls命令），基本上就可以在终端自由访问文件夹了。</p><p>如果嫌弃文件或者文件夹名称过长，可以通过tab键来自动补全。</p>]]></content>
      
      
      <categories>
          
          <category> java笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>学习java第一天——markdown基础</title>
      <link href="/callme-star.github.io/2020/08/06/%E5%AD%A6%E4%B9%A0Java%E7%AC%AC%E4%B8%80%E5%A4%A9%E2%80%94%E2%80%94markdown%E5%9F%BA%E7%A1%80/"/>
      <url>/callme-star.github.io/2020/08/06/%E5%AD%A6%E4%B9%A0Java%E7%AC%AC%E4%B8%80%E5%A4%A9%E2%80%94%E2%80%94markdown%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h1 id="markdown基础"><a href="#markdown基础" class="headerlink" title="markdown基础"></a>markdown基础</h1><p>　　本人是一个跨考生，本科学习的农学，现在研究生跨入了计算机专业，因为底子比较薄，所以想通过看一些课程，在博客上自己记录一下学习历程，以便于督促自己。</p><a id="more"></a><h2 id="一-标题"><a href="#一-标题" class="headerlink" title="一.标题"></a>一.标题</h2><p>##+space+内容</p><h3 id="三级标题"><a href="#三级标题" class="headerlink" title="三级标题"></a>三级标题</h3><p>###+space+内容</p><h4 id="四级标题"><a href="#四级标题" class="headerlink" title="四级标题"></a>四级标题</h4><p>####+space+内容</p><h2 id="二-字体"><a href="#二-字体" class="headerlink" title="二.字体"></a>二.字体</h2><p><strong>hello，java</strong>            ** + 内容 + **</p><p><em>hello，java</em>                * + 内容 + *</p><p><del>hello，java</del>             <del>~ + 内容 + ~</del></p><p><strong><em>hello，java</em></strong>            ** *  +   内容   + ** *</p><h2 id="三-引用"><a href="#三-引用" class="headerlink" title="三.引用"></a>三.引用</h2><blockquote><p>学习java第一天，认认真真记笔记！</p><p>‘&gt;’ + space + 内容</p></blockquote><h2 id="四-分割线"><a href="#四-分割线" class="headerlink" title="四.分割线"></a>四.分割线</h2><hr><p>键盘输入“—”，也就是三个减号就可以了</p><p>或者也可以用三个星号，“***”</p><p>##　五.图片</p><p><img src="https://ss0.bdstatic.com/94oJfD_bAAcT8t7mm9GUKT-xh_/timg?image&quality=100&size=b4000_4000&sec=1596721861&di=2eb592e5a35f908fb45fd4b25ad82e17&src=http://a1.att.hudong.com/05/00/01300000194285122188000535877.jpg" alt="截图"></p><p>先输入“!” + 英文状态下的“[ ]” + 图片的网络地址或者本地地址</p><h2 id="六-超链接"><a href="#六-超链接" class="headerlink" title="六.超链接"></a>六.超链接</h2><p><a href="https://www.csdn.net/">超链接</a></p><p>先输入“[ ]”+ “( )”在括号里面放要链接的网址就可以了</p><h2 id="七-列表"><a href="#七-列表" class="headerlink" title="七.列表"></a>七.列表</h2><ol><li>第一个</li><li>第二个</li><li></li></ol><p>这个就是直接写“1” + “.” + space</p><h3 id="无序列表"><a href="#无序列表" class="headerlink" title="无序列表"></a>无序列表</h3><ul><li>第一个</li><li>第二个</li></ul><p>输入“-”减号 + space</p><h2 id="八-表格"><a href="#八-表格" class="headerlink" title="八.表格"></a>八.表格</h2><ol><li><p>右键插入</p></li><li><p>代码形式</p><table><thead><tr><th>姓名</th><th>性别</th><th>年龄</th></tr></thead><tbody><tr><td>小明</td><td>男</td><td>18</td></tr><tr><td></td><td></td><td></td></tr></tbody></table><p>mac下：输入        |名字|性别|生日|          即可</p><p>win下：输入         |名字|性别|生日|</p></li></ol><p>​                                      |–|–|–|</p><p>​                                       |小明|男|18|                然后回车 </p><h2 id="九-代码"><a href="#九-代码" class="headerlink" title="九.代码"></a>九.代码</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> hello;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">world</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Hello, world!&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输入“···” + “语言名称”，就会出现代码框了</p><ul><li>其中的点 在键盘按键上的 Esc 的下边</li><li>语言名称指的是“java”，”c“，”python“等</li></ul>]]></content>
      
      
      <categories>
          
          <category> java笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java笔记 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
