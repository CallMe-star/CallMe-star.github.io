<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>自制神经网络数据集</title>
      <link href="/2020/09/20/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E8%87%AA%E5%88%B6%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
      <url>/2020/09/20/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E8%87%AA%E5%88%B6%E6%95%B0%E6%8D%AE%E9%9B%86/</url>
      
        <content type="html"><![CDATA[<blockquote><p>将自己领域的数据生成数据包导入神经网络</p></blockquote><a id="more"></a><h2 id="自制数据集并应用"><a href="#自制数据集并应用" class="headerlink" title="自制数据集并应用"></a>自制数据集并应用</h2><p>在曹健老师的视频课程中有两种读入数据集的方法，一种是在线下载直接调用；一种是在本地自制数据集，用于自己本领域的数据处理。</p><p>首先简单看一下在线读取数据的代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">minist = tf.keras.datasets.mnist         <span class="comment">#导入数据集</span></span><br><span class="line">(x_train, y_train)，(x_test, y_test) = mnist.load_data()  <span class="comment">#分配训练集和测试集</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;x_train.shape:\n&#x27;</span>, x_train.shape)</span><br><span class="line">print(<span class="string">&#x27;y_train.shape:\n&#x27;</span>, y_train.shape)</span><br><span class="line">print(<span class="string">&#x27;x_test.shape:\n&#x27;</span>, x_test.shape)</span><br><span class="line">print(<span class="string">&#x27;y_test.shape:\n&#x27;</span>, y_test.shape)</span><br></pre></td></tr></table></figure><h3 id="首先制作数据集"><a href="#首先制作数据集" class="headerlink" title="首先制作数据集"></a>首先制作数据集</h3><h4 id="①制作npy格式的本地数据集（label是txt形式）"><a href="#①制作npy格式的本地数据集（label是txt形式）" class="headerlink" title="①制作npy格式的本地数据集（label是txt形式）"></a>①制作npy格式的本地数据集（label是txt形式）</h4><p>在这个文件夹下放两个文件夹（一个训练集图片集和一个测试集图片集），和两个txt文件集，存放训练集和测试集所对应的标签。</p><p>其中图片集中纯黑色用0表示，纯白色用255表示；</p><p>两个txt文件中内容为：图片.jpg     label</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读入图像和标签</span></span><br><span class="line">train_path = (<span class="string">&#x27;绝对路径&#x27;</span>)</span><br><span class="line">train_txt = (<span class="string">&#x27;绝对路径&#x27;</span>)</span><br><span class="line"><span class="comment"># 存储npy数据包的位置</span></span><br><span class="line">x_train_savepath = (<span class="string">&#x27;绝对路径.npy&#x27;</span>)</span><br><span class="line">y_train_savepath = (<span class="string">&#x27;绝对路径.npy&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读入图像和标签</span></span><br><span class="line">test_path = (<span class="string">&#x27;绝对路径&#x27;</span>)</span><br><span class="line">test_txt = (<span class="string">&#x27;绝对路径&#x27;</span>)</span><br><span class="line"><span class="comment"># 存储npy数据包的位置</span></span><br><span class="line">x_test_savepath = (<span class="string">&#x27;绝对路径.npy&#x27;</span>)</span><br><span class="line">y_test_savepath = (<span class="string">&#x27;绝对路径.npy&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generateds</span>(<span class="params">path, txt</span>):</span></span><br><span class="line">  f = open(txt, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">  contents = f.readlines()</span><br><span class="line">  f.close()</span><br><span class="line">  x, y_ = [],[]</span><br><span class="line">  <span class="keyword">for</span> content <span class="keyword">in</span> contents:</span><br><span class="line">    value = content.split()</span><br><span class="line">    img_path = path + value[<span class="number">0</span>]</span><br><span class="line">    img = Image.open(img_path)</span><br><span class="line">    img = np.array(img.convert(<span class="string">&#x27;L&#x27;</span>))</span><br><span class="line">    img = img / <span class="number">255</span></span><br><span class="line">    x.append(img)</span><br><span class="line">    y_.append(value[<span class="number">1</span>])</span><br><span class="line">    print(<span class="string">&#x27;loading:&#x27;</span>, + content)</span><br><span class="line">    </span><br><span class="line">  x = np.array(x)</span><br><span class="line">  y_ = np.array(y_)</span><br><span class="line">  y_ = y_ astype(np.int64)</span><br><span class="line">  <span class="keyword">return</span> x, y_</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> os.path.exists(x_train_savepath) <span class="keyword">and</span> os.path.exists(y_train_savepath) <span class="keyword">and</span> os.path.exists(x_test_savepath) <span class="keyword">and</span> os.path.exists(y_test_savepath):</span><br><span class="line">  print(<span class="string">&#x27;------------正在读取数据集---------------&#x27;</span>)</span><br><span class="line">  x_train_save = np.load(x_train_savepath)</span><br><span class="line">  y_train = np.save(y_train_savepath)</span><br><span class="line">  x_test_save = np.load(x_test_savepath)</span><br><span class="line">  y_test = np.load(y_test_savcvepath)</span><br><span class="line">  x_train = np.reshape(x_train_save, len(x_train_save),<span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">  x_test = np.reshape(x_tet_save, len(x_test_save),<span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">  </span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(<span class="string">&#x27;------------生成矩阵中--------------&#x27;</span>)</span><br><span class="line">    x_train， y_train = generateds(train_path, train_txt)</span><br><span class="line">    x_test, y_test = generateds(test_path, test_txt)</span><br><span class="line">    </span><br><span class="line">    print(<span class="string">&#x27;----------生成数据集中------------&#x27;</span>)</span><br><span class="line">    x_train_save = np.reshape(x_train, len(x_train),<span class="number">-1</span>)</span><br><span class="line">    x_test_save = np.reshape(x_test, len(x_test), <span class="number">-1</span>) </span><br><span class="line">    np.save(x_train_savepath, x_train_save)</span><br><span class="line">    np.save(y_train_savepath, y_train)</span><br><span class="line">    np.save(x_test_savepath, x_test_save)</span><br><span class="line">    np.save(y_test_savepath, y_test)</span><br><span class="line">    </span><br></pre></td></tr></table></figure><p>下面需要自己写个函数读入数据集</p><h5 id="npy数据集的读入"><a href="#npy数据集的读入" class="headerlink" title="npy数据集的读入"></a>npy数据集的读入</h5><p>手写函数读入数据</p><p>直接调用np.load（）即可读入整个npy文件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x_train_save = np.load(x_train_savepath)</span><br><span class="line">y_train = np.save(y_train_savepath)</span><br><span class="line">x_test_save = np.load(x_test_savepath)</span><br><span class="line">y_test = np.load(y_test_savcvepath)</span><br><span class="line">x_train = np.reshape(x_train_save, len(x_train_save),<span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">x_test = np.reshape(x_tet_save, len(x_test_save),<span class="number">28</span>, <span class="number">28</span>)</span><br></pre></td></tr></table></figure><h4 id="②npy数据集简单制作（label是文件夹遍历过程中赋予的逻辑值）"><a href="#②npy数据集简单制作（label是文件夹遍历过程中赋予的逻辑值）" class="headerlink" title="②npy数据集简单制作（label是文件夹遍历过程中赋予的逻辑值）"></a>②npy数据集简单制作（label是文件夹遍历过程中赋予的逻辑值）</h4><p>此过程不用先生成一个单独的txt文件来才存储标签，但是在给图像分类并且每种图片放入指定文件夹的过程比较繁琐。此过程借鉴自<a href="https://blog.csdn.net/umbrellalalalala/article/details/86516928#commentBox">https://blog.csdn.net/umbrellalalalala/article/details/86516928#commentBox</a></p><p>这次用到的数据集是五种花的彩色图像（在一个主文件夹flower_photos中建五个子文件夹分别放对应的花，另外建一个主主文件夹放生成的npy数据集包）</p><p>代码解析：</p><ol><li>函数返回图像和标签矩阵</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> os.path</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.platform <span class="keyword">import</span> gfile</span><br><span class="line"></span><br><span class="line">INPUT_DATA = <span class="string">&#x27;flower_photo&#x27;</span>     <span class="comment">#图像的绝对路径</span></span><br><span class="line">OUTPUT_DATA = <span class="string">&#x27;processed_flower_data/flower_processed_data.npy&#x27;</span>   <span class="comment">#将整理过的图像数据通过numpy格式保存</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#测试数据和验证数据的比例</span></span><br><span class="line">VALIDATION_PERCENTAGE = <span class="number">10</span></span><br><span class="line">TEST_PERCENTAGE = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#读取数据并且为测试集和训练集还有验证集分配比例</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_image_lists</span>(<span class="params">sess, testing_percentage,validation_percentage</span>):</span></span><br><span class="line">  <span class="comment">#sub_dirs用于存储主文件夹下面的所有子文件夹目录</span></span><br><span class="line">  sub_dirs = [x[<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> os.walk(INPUT_DATA)]    <span class="comment"># os.walk()方法用于通过在目录中游走输出在目录中的文件名，向上或者向下</span></span><br><span class="line">  is_root_dir = <span class="literal">True</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">#初始化各个数据集</span></span><br><span class="line">  training_images = []</span><br><span class="line">  training_labels = []</span><br><span class="line">  testing_images = []</span><br><span class="line">  testing_labels = []</span><br><span class="line">  validition_images = []</span><br><span class="line">  validation_labels = []</span><br><span class="line">  current_label = <span class="number">0</span>    <span class="comment">#这是要赋值给每种花的一个逻辑标签，在下面循环中，到下一个子目录中要加一</span></span><br><span class="line">  count = <span class="number">1</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">#对每个在sub_dirs中的子文件夹进行操作</span></span><br><span class="line">  <span class="keyword">for</span> sub_dir <span class="keyword">in</span> sub_dirs:</span><br><span class="line">    <span class="keyword">if</span> is_root_dir:</span><br><span class="line">      is_root_dir = <span class="literal">False</span></span><br><span class="line">      <span class="keyword">continue</span>      <span class="comment">#继续下一轮循环，下一轮就无法进入条件分支而是直接执行下列语句</span></span><br><span class="line">      print(<span class="string">&quot;开始读取第%d类图片&quot;</span>， % count)</span><br><span class="line">      count + = <span class="number">1</span></span><br><span class="line">      </span><br><span class="line">      <span class="comment">#获取子目录中所有文件</span></span><br><span class="line">      extension = [<span class="string">&#x27;jpg&#x27;</span>, <span class="string">&#x27;jpeg&#x27;</span>, <span class="string">&#x27;JPG&#x27;</span>, <span class="string">&#x27;JPEG&#x27;</span>， <span class="string">&#x27;png&#x27;</span>]   <span class="comment">#列出所有拓展名</span></span><br><span class="line">      file_list = []</span><br><span class="line">      <span class="comment">#返回path最后的文件名。如果path以／或\结尾，那么就会返回空值。即os.path.split(path)的第二个元素</span></span><br><span class="line">      dir_name = os.path.basename(sub_dir)    <span class="comment">#返回子文件夹名称，如果包含文件夹地址串，去掉其地址，只保留文件夹名称</span></span><br><span class="line">      <span class="keyword">for</span> extention <span class="keyword">in</span> extensions:</span><br><span class="line">        <span class="comment"># INPUT_DATA是数据集的根文件夹，其下有五个子文件夹包含所有图像</span></span><br><span class="line">        <span class="comment">#dir_name是是存放某种花的子文件夹</span></span><br><span class="line">        <span class="comment">#file_name进行整合之后的效果是合成以下形式（“INPUT_DATA/dir_name/*.extension”）</span></span><br><span class="line">        file_glob = os.path.join(INPUT_DATA,dir_name,<span class="string">&#x27;*.&#x27;</span>+extension )</span><br><span class="line">        <span class="comment">#glob.glob()返回所有匹配得文件路径列表，此处返回的是所有在INPUT_DATA子目录下的所有后缀是extension的文件</span></span><br><span class="line">        file_list.extend(glob.glob(file_glob))</span><br><span class="line">        </span><br><span class="line">      <span class="keyword">if</span> <span class="keyword">not</span> file_list:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">      print(<span class="string">&quot;文件名列表读取完成，开始读取图像&quot;</span>)</span><br><span class="line">      </span><br><span class="line">      <span class="keyword">for</span> file_name <span class="keyword">in</span> file_list:</span><br><span class="line">        <span class="comment">#下面是两句读取文件常用的语句</span></span><br><span class="line">        image_raw_data = gfile.FastGFile(file_name,<span class="string">&#x27;rb&#x27;</span>).read()</span><br><span class="line">        image = tf.image.decode_jpeg(image_raw_data)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#如果图像类型不是发咯爱听，则进行转换</span></span><br><span class="line">        <span class="keyword">if</span> image.dtype != tf.float32:</span><br><span class="line">          image = tf.image.convert_image_dtype(image, tf.float32)</span><br><span class="line">        <span class="comment">#将图像调整成尺寸299*299，以便于inception—v3模型来处理</span></span><br><span class="line">        image = tf.image.resize_images(image, [<span class="number">299</span>, <span class="number">299</span>])</span><br><span class="line">        image_value = sess.run(image)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#用随机数生成一定比例的测试集，验证集、训练集</span></span><br><span class="line">        chance = np.random.randint(<span class="number">100</span>)</span><br><span class="line">        <span class="keyword">if</span> chance &lt; validation_percentage:</span><br><span class="line">          validation_images.append(image_value)   <span class="comment"># 由于一共有3670张图片，这样最终的validation_images的尺寸大致是(3670*validation_percentage%)*229*229*3</span></span><br><span class="line">          validation_labels.append(current_label)     <span class="comment"># 由于一共有3670张图片，这样最终的validation_labels的尺寸大致是(3670*validation_percentage%)*1</span></span><br><span class="line">          <span class="keyword">elif</span> chance &lt; (testing_percentage + validation_percentage):</span><br><span class="line">                testing_images.append(image_value)</span><br><span class="line">                testing_labels.append(current_label)</span><br><span class="line">          <span class="keyword">else</span>:</span><br><span class="line">                training_images.append(image_value)</span><br><span class="line">                training_labels.append(current_label)</span><br><span class="line">      current_label += <span class="number">1</span></span><br><span class="line">      print(<span class="string">&#x27;本类图片读取完成&#x27;</span>)</span><br><span class="line">  print(<span class="string">&quot;开始打乱训练数据集&quot;</span>)</span><br><span class="line">  state = np.random.get_state()    <span class="comment">#获取随机生成器np.random的状态</span></span><br><span class="line">  np.random.shuffle(training_images)    <span class="comment">#进行打乱操作，如果对象是多维矩阵，只对第一组打乱操作</span></span><br><span class="line">  np.random.set_state(state)  <span class="comment">#将之前随机生成器的状态设置为随机生成器状态，目的是让下面一行对标签的打乱和上一行的图片打乱一致</span></span><br><span class="line">  np.random.shuffle(training_labels)</span><br><span class="line">  print(<span class="string">&quot;数据处理完毕&quot;</span>)</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> np.asarray([</span><br><span class="line">    training_images, training_labels,</span><br><span class="line">    validation_images, validation_labels,</span><br><span class="line">    testing_images, testing_labels</span><br><span class="line">  ])</span><br></pre></td></tr></table></figure><p>2.主函数调用并生成npy包</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">  <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    processed_data = create_image_lists(</span><br><span class="line">        sess, TEST_PERCENTAGE, VALIDATION_PERCENTAGE)</span><br><span class="line">    np.save(OUTPUT_DATA, processed_data)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ = <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">  main()</span><br><span class="line">  </span><br></pre></td></tr></table></figure><ol start="3"><li>npy文件的简单使用</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data = np.load(flower_processed_data.npy)</span><br></pre></td></tr></table></figure><p>data的形式如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[training_images, training_labels,</span><br><span class="line">validation_images, validation_labels,</span><br><span class="line">testing_images, testing_labels]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> TensorFlow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow第四节</title>
      <link href="/2020/09/19/%E7%94%A8tf.keras%E6%90%AD%E5%BB%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1/"/>
      <url>/2020/09/19/%E7%94%A8tf.keras%E6%90%AD%E5%BB%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1/</url>
      
        <content type="html"><![CDATA[<blockquote><p>八股六步法搭建网络结构</p></blockquote><a id="more"></a><h2 id="用tf-keras搭建网络八股"><a href="#用tf-keras搭建网络八股" class="headerlink" title="用tf.keras搭建网络八股"></a>用tf.keras搭建网络八股</h2><h3 id="六步法："><a href="#六步法：" class="headerlink" title="六步法："></a>六步法：</h3><ol><li><p>import       导入相关模块</p></li><li><p>train,test     告知喂入网络的训练集和测试集</p></li><li><p>model = tf.keras.models.Sequential      在Sequential中搭建网络结构，逐层描述网络，相当于走了一遍前向传播</p></li><li><p>model.compile    配置训练方法（告知训练时使用的优化器、损失函数、评测指标）</p></li><li><p>model.fit      执行训练过程（告知训练集和测试集的输入特征和标签  告知每个batch是多少要迭代多少次数据集）</p></li><li><p>model.summary   打印出网络的结构和参数统计</p><p>代码展示</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x_train = datasets.load_iris().data</span><br><span class="line">y_train = datasets.load_iris().target</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">116</span>)</span><br><span class="line">np.random.shuffle(x_train)</span><br><span class="line">np.random.seed(<span class="number">116</span>)</span><br><span class="line">np.random.shuffle(y_train)</span><br><span class="line">tf.random.set_seed(<span class="number">116</span>)</span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">3</span>,activation=<span class="string">&#x27;softmax&#x27;</span>, kernel_regularizer=tf.keras.regularizers.l2())</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=tf.keras.optimizers.SGD(lr=<span class="number">0.1</span>),</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>]</span><br><span class="line">             )</span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">32</span>,epochs=<span class="number">500</span>,validation_split=<span class="number">0.2</span>,validation_freq=<span class="number">20</span>)</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><p>代码解释：</p><p>①model = tf.keras.models.Sequential([网络结构])      我们需要在sequential中搭建网络结构</p><blockquote><p>tf.keras.layers.Dense(3, activation=’softmax’, kernel_regularizer=tf.keras.l2())</p><p>3为神经元个数</p><p>activation为激活函数</p><p>kernels_regularizer为正则化方法</p></blockquote><p>②model.compile(opeimizer=tf.keras.optimizers.GSD(lr=0.1), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),metrics=[‘sparse_categorical_accuracy’])</p><blockquote><p>models.compile中配置训练方法</p><p>optimizer是优化器</p><p>loss为损失函数（sparsecategoricalcrossentropy中的False是因为神经网络末端经过了softmax函数，使得输出是概率分布而不是原始输出）</p><p>metrics为评测指标：sparse_categorical_accuracy与上方的logits=false对应，数据集标签是0,1,2为独热码，神经网络前向传播的输出是概率分布。</p></blockquote><p>③在fit中执行训练过程：model.fit(x_train, y_train, batch_size, epochs=500, validtion_split=0.2, validation_freq=20)</p><blockquote><p>validation_split告知从训练集中选择20%数据作为测试集</p><p>validation_freq每迭代20次数据集验证一次准确率</p></blockquote><p>④summary打印出网络结构和参数统计</p><h3 id="显示数据集"><a href="#显示数据集" class="headerlink" title="显示数据集"></a>显示数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">  plt.imshow(x_train[i])</span><br><span class="line">  plt.show()</span><br><span class="line">print(<span class="string">&quot;x_train[0]:\n&quot;</span>, x_train[<span class="number">0</span>])   <span class="comment">#输出的是数据集第一个元素的矩阵（是一个灰度图像或者三通道彩色图想，色彩范围在0—255之间）</span></span><br><span class="line">print(<span class="string">&quot;x_test.shape\n&quot;</span>, x_test.shape)  <span class="comment">#输出测试集的形状（三维的矩阵）</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> TensorFlow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>matlab基础操作第二节</title>
      <link href="/2020/08/26/matlab%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C2/"/>
      <url>/2020/08/26/matlab%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C2/</url>
      
        <content type="html"><![CDATA[<blockquote><p>记录matlab形态学操作及绘图操作</p></blockquote><a id="more"></a><h2 id="一、形态学操作"><a href="#一、形态学操作" class="headerlink" title="一、形态学操作"></a>一、形态学操作</h2><h3 id="lt-1-gt-形态学基础"><a href="#lt-1-gt-形态学基础" class="headerlink" title="&lt;1&gt;形态学基础"></a>&lt;1&gt;形态学基础</h3><p>​                                                                                                                                                                                                                                                        </p><p>上节记录了怎么用fspecial做滤波器（也就是掩膜），这次我们要生成的叫结构元素SE</p><p>主要用来构建形态学运算中的结构元素，使用的语法为strel(shape,parameters)。shape为形状参数，即设置什么样的结构元素；parameters为控制形状参数大小方向的参数。</p><p>就像上一节的滤波器我们也可以手动绘制，这一节的结构元素我们一样可以绘制，但是太过麻烦,下面举例子做一个正45°，长度为6的结构元素</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">SE = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>;<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>;<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>;<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>;<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>;<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>;]</span><br><span class="line">SE =</span><br><span class="line"></span><br><span class="line">     <span class="number">0</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span></span><br><span class="line">     <span class="number">0</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">0</span></span><br><span class="line">     <span class="number">0</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span></span><br><span class="line">     <span class="number">0</span>     <span class="number">0</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">0</span></span><br><span class="line">     <span class="number">0</span>     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">0</span></span><br><span class="line">     <span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">0</span>     <span class="number">0</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这样自己写太麻烦了，matlab为我们提供了一个函数，采用strel()函数则能够快速地构建如上所示的结构元素。</p><p>使用方法：</p><p>SE = strel(‘arbitrary’,NHOOD)</p><p>SE = strel(‘arbitrary’,NHOOD,HEIGHT)</p><p>SE = strel(‘ball’,R,H,N)</p><p>SE = strel(‘diamond’,R)</p><p>SE = strel(‘disk’,R,N)</p><p>SE = strel(‘line’,LEN,DEG)</p><p>SE = strel(‘octagon’,R)</p><p>SE = strel(‘pair’,OFFSET)</p><p>SE = strel(‘periodicline’,P,V)</p><p>SE = strel(‘rectangle’,MN)</p><p>SE = strel(‘square’,W)</p><p>可以构建出各种形状的结构元素。</p><h3 id="lt-2-gt-下面我们开始用结构元素对图像进行膨胀腐蚀操作。"><a href="#lt-2-gt-下面我们开始用结构元素对图像进行膨胀腐蚀操作。" class="headerlink" title="&lt;2&gt;下面我们开始用结构元素对图像进行膨胀腐蚀操作。"></a>&lt;2&gt;下面我们开始用结构元素对图像进行膨胀腐蚀操作。</h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">img = imread(<span class="string">&#x27;.......jpg&#x27;</span>);</span><br><span class="line">SE = strel(<span class="string">&#x27;ball&#x27;</span>,<span class="number">20</span>);</span><br><span class="line">dst1 = imdilate(img, SE);</span><br><span class="line">dst2 = imerode(img, SE);</span><br><span class="line"><span class="built_in">figure</span>,imshow(dst1);</span><br><span class="line"><span class="built_in">figure</span>,imshow(dst2);</span><br></pre></td></tr></table></figure><h3 id="lt-3-gt-顶帽变换，底帽变换"><a href="#lt-3-gt-顶帽变换，底帽变换" class="headerlink" title="&lt;3&gt;顶帽变换，底帽变换"></a>&lt;3&gt;顶帽变换，底帽变换</h3>]]></content>
      
      
      <categories>
          
          <category> matlab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> matlab </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>matlab基础操作第一节</title>
      <link href="/2020/08/25/matlab%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C1/"/>
      <url>/2020/08/25/matlab%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C1/</url>
      
        <content type="html"><![CDATA[<blockquote><p>记录基本的matlab对图像的操作以及简单的函数调用对图像简单处理</p></blockquote><a id="more"></a><h2 id="一、图像的读入与显示"><a href="#一、图像的读入与显示" class="headerlink" title="一、图像的读入与显示"></a>一、图像的读入与显示</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">img = imread(<span class="string">&#x27;图像在本地的地址.jpg&#x27;</span>);</span><br><span class="line"><span class="built_in">figure</span>(<span class="number">1</span>),</span><br><span class="line">imshow(img);</span><br></pre></td></tr></table></figure><p>以上就完成了最基本的图像读入与显示工作。但是为了操作简便我们经常不会对一个彩色图像进行处理，因为彩色图想有三个通道，会增加计算的复杂程度，所以我们第一步就是要对图像进行处理转换为灰度图像（简单地理解就是黑色和白色两种色彩的图像，只不过图像的黑和白的程度被细分成了256种不同程度的颜色）洗面我们来操作一下：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">img = imread(<span class="string">&#x27;图像在本地的地址.jpg&#x27;</span>);</span><br><span class="line">img1 = rgb2gray(img);</span><br></pre></td></tr></table></figure><p>如果单单对一个图片进行显示，那么我们就无法比较改变前后两个照片的细节上有什么差别，下面我们借用subplot函数，把两张或者多张图像显示在一个画布上：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">figure</span>(<span class="number">2</span>),</span><br><span class="line">subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>),imshow(img),title(<span class="string">&#x27;原图&#x27;</span>)；</span><br><span class="line">subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>),imshow(img1),title(<span class="string">&#x27;灰度图&#x27;</span>)；</span><br></pre></td></tr></table></figure><h2 id="二、相关函数调用"><a href="#二、相关函数调用" class="headerlink" title="二、相关函数调用"></a>二、相关函数调用</h2><h3 id="1、把图像转换为二值图"><a href="#1、把图像转换为二值图" class="headerlink" title="1、把图像转换为二值图"></a>1、把图像转换为二值图</h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">img = imread(<span class="string">&#x27;图像在本地的地址.jpg&#x27;</span>);</span><br><span class="line">img1 = im2bw(img);</span><br><span class="line"><span class="built_in">figure</span>,</span><br><span class="line">subplot(<span class="number">121</span>),imshow(img);</span><br><span class="line">subplot(<span class="number">122</span>),imshow(img1);</span><br></pre></td></tr></table></figure><h3 id="2、把一个对比度不清晰的图像转换成清晰的图像"><a href="#2、把一个对比度不清晰的图像转换成清晰的图像" class="headerlink" title="2、把一个对比度不清晰的图像转换成清晰的图像"></a>2、把一个对比度不清晰的图像转换成清晰的图像</h3><h4 id="lt-1-gt-下面用到两个函数imadjust-和stretchlim"><a href="#lt-1-gt-下面用到两个函数imadjust-和stretchlim" class="headerlink" title="&lt;1&gt;下面用到两个函数imadjust()和stretchlim()"></a>&lt;1&gt;下面用到两个函数imadjust()和stretchlim()</h4><p>①stretchlim函数是用来获取一个图像的最佳阈值分割矩阵的函数，将这个函数产生的矩阵直接带入下面的imadjust函数即可解决大部分对比度不清晰地问题</p><p>②imadjust（）本来括号里面有四个参数（待处理的图像，待处理图像中的灰度范围，要装换到新图片中灰度被拉伸的区间，gamma）</p><p>举个例子imadjust(img, [0,1], [1,0], 1)</p><p>就是把原图中[0,1]灰度范围内的灰度以一定的映射规则转换到[1,0]内，也就是实现了一个灰度翻转，这个例子实现的功能跟一个函数类似Jmcomplement();  </p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">img = imread(<span class="string">&#x27;图像在本地的地址.jpg&#x27;</span>);</span><br><span class="line">img = rgb2gray(img);</span><br><span class="line">dst = imcomplement(img)</span><br><span class="line"><span class="built_in">figure</span>,</span><br><span class="line">subplot(<span class="number">121</span>),imshow(img);</span><br><span class="line">subplot(<span class="number">122</span>),imshow(dst);</span><br></pre></td></tr></table></figure><p>gamma用来规定映射的规则，如图所示，gamma以1为界限，大于1的时候把灰度较高的部分拉伸的很长，相当于把图像中亮度较高的部分，灰度分配到了【0，255】范围内，因此我们可以看到更多光亮部分的细节，相反就能看到较暗部分的细节</p><p><img src="https://cdn.jsdelivr.net/gh/CallMe-star/picbed@master/20200829203428.png"></p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">img = imread(<span class="string">&#x27;图像在本地的地址.jpg&#x27;</span>);</span><br><span class="line">img = rgb2gray(img);</span><br><span class="line"><span class="comment">%下面用到两个函数imadjust（）和strtchlim()</span></span><br><span class="line">h = stretchlim(img);</span><br><span class="line">dst = imgadjust(img,h,[])</span><br><span class="line"><span class="comment">% 其中的[]是对图像对比度进行加深，让现实的图像是我们想象中的样子</span></span><br><span class="line"><span class="built_in">figure</span>，</span><br><span class="line">subplot(<span class="number">221</span>),imshow(img);</span><br><span class="line">subplot(<span class="number">222</span>),imshow(dst);</span><br><span class="line"><span class="comment">%下面用imhist函数看一下整幅图片的灰度分布图</span></span><br><span class="line">subplot(<span class="number">223</span>),imhist(img),title(<span class="string">&#x27;原图灰度&#x27;</span>);</span><br><span class="line">subplot(<span class="number">224</span>),imhist(dst),title(<span class="string">&#x27;变换后的灰度&#x27;</span>);</span><br></pre></td></tr></table></figure><h4 id="lt-2-gt-histeq"><a href="#lt-2-gt-histeq" class="headerlink" title="&lt;2&gt;histeq()"></a>&lt;2&gt;histeq()</h4><p>这个函数也是把图像进行一下智能的直方图均衡化，将对比度差的图像转换成能看到细节的图像</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">img = imread(<span class="string">&#x27;图像在本地的地址.jpg&#x27;</span>);</span><br><span class="line">img = rgb2gray(img);</span><br><span class="line">dst = histeq(img);</span><br><span class="line"><span class="built_in">figure</span>,</span><br><span class="line">subplot(<span class="number">121</span>),imshow(dst);</span><br><span class="line">subplot(<span class="number">122</span>),imhist(dst);</span><br></pre></td></tr></table></figure><h3 id="3、调用函数对图像进行去噪，求边缘等等"><a href="#3、调用函数对图像进行去噪，求边缘等等" class="headerlink" title="3、调用函数对图像进行去噪，求边缘等等"></a>3、调用函数对图像进行去噪，求边缘等等</h3><h4 id="①首先我们先认识一个函数medfilt2"><a href="#①首先我们先认识一个函数medfilt2" class="headerlink" title="①首先我们先认识一个函数medfilt2()"></a>①首先我们先认识一个函数medfilt2()</h4><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">img = imread(<span class="string">&#x27;图像在本地的地址.jpg&#x27;</span>);</span><br><span class="line">img = rgb2gray(img);</span><br><span class="line"><span class="comment">%先用一个函数给一个图像加入椒盐噪声</span></span><br><span class="line"><span class="comment">%或者还可以加高斯噪声imnoise(img,&#x27;guassian&#x27;, 0.02)</span></span><br><span class="line">img1=imnoise(img,‘salt &amp; pepper’,<span class="number">0.02</span>) </span><br><span class="line">img2 = medfilt2(img1, [<span class="number">3</span>,<span class="number">3</span>]);</span><br><span class="line"><span class="built_in">figure</span>,</span><br><span class="line">subplot(<span class="number">121</span>),imshow(img1);</span><br><span class="line">subplot(<span class="number">122</span>),imshow(img2);</span><br></pre></td></tr></table></figure><h4 id="②fspecial（）和imfilter（）"><a href="#②fspecial（）和imfilter（）" class="headerlink" title="②fspecial（）和imfilter（）"></a>②fspecial（）和imfilter（）</h4><h5 id="fspecial-是用来做滤波器的"><a href="#fspecial-是用来做滤波器的" class="headerlink" title="fspecial()是用来做滤波器的"></a>fspecial()是用来做滤波器的</h5><p>他可以做出各种类型的滤波器</p><p>Fspecial(‘滤波器名字’，hesize，sigma)</p><p>均值滤波器：h = fspecial(‘average’,5)</p><p>高斯滤波器：h = fspecial(‘gaussian’,5)</p><p>拉普拉斯滤波器：h = fspecial(‘laplacian’)</p><p>拉普拉斯高斯：h = fspecial(‘log’,3,0.2) </p><p>sobel边缘提取：h = fspecial(‘sobel’)</p><h5 id="imfilter-是用来滤波的"><a href="#imfilter-是用来滤波的" class="headerlink" title="imfilter()是用来滤波的"></a>imfilter()是用来滤波的</h5><p>imfilter（A, h, filtermode,boundary,size）</p><p>其中A是待处理图像</p><p>h是上边生成的滤波器</p><p>filtermode是滤波类型包括‘corr’即相关，还有‘conv’即卷积</p><p>boundary是边界补全的方式：有‘X’ 输入图像的边界通过用值X（无引号）来填充扩展 其默认值为0，‘repliacate’图像大小通过复制外边界的值来扩展，‘symmetric’图像大小通过镜像反射其边界来扩展，‘circular’图像大小通过将图像看成是一个二维周期函数的一个周期来扩展</p><p>size指的是：输出图像的大小，有‘same’和‘full’</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">img = imread(<span class="string">&#x27;peppers.png&#x27;</span>);</span><br><span class="line">h = fspecial(<span class="string">&#x27;average&#x27;</span>);<span class="comment">%创建一个滤波器</span></span><br><span class="line">dst = imfilter(img, h, <span class="string">&#x27;conv&#x27;</span>, <span class="string">&#x27;replicate&#x27;</span>,<span class="string">&#x27;same&#x27;</span>);</span><br><span class="line"><span class="built_in">figure</span>, </span><br><span class="line">imshow(img);</span><br><span class="line">imshow(dst);</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> matlab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> matlab </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图像分割</title>
      <link href="/2020/08/25/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/"/>
      <url>/2020/08/25/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/</url>
      
        <content type="html"><![CDATA[<blockquote><p>我对图像分割的初级认识（现在的图像分割基本概况）</p></blockquote><a id="more"></a><h2 id="一、图像分割分类"><a href="#一、图像分割分类" class="headerlink" title="一、图像分割分类"></a>一、图像分割分类</h2><h3 id="按着先进程度分"><a href="#按着先进程度分" class="headerlink" title="按着先进程度分"></a>按着先进程度分</h3><ul><li><h4 id="传统分割方法"><a href="#传统分割方法" class="headerlink" title="传统分割方法"></a>传统分割方法</h4></li></ul><p>①阈值分割</p><blockquote><p>阈值法的基本思想是基于图像的灰度特征来计算一个或多个灰度阈值，并将图像中每个像素的灰度值与阈值作比较，最后将像素根据比较结果分到合适的类别中。因此，该方法最为关键的一步就是按照某个准则函数来求解最佳灰度阈值。阈值法特别适用于目标和背景占据不同灰度级范围的图。</p></blockquote><p>②基于区域的分割</p><blockquote><p>基于区域的分割方法是以直接寻找区域为基础的分割技术，基于区域提取方法有两种基本形式：一种是区域生长，从单个像素出发，逐步合并以形成所需要的分割区域；另一种是从全局出发，逐步切割至所需的分割区域。</p></blockquote><p>③基于边缘检测的分割</p><blockquote><p>小波变换是近年来得到的广泛应用的数学工具，也是现在数字图像处理必学部分，它在时间域和频率域上都有量高的局部化性质，能将时域和频域统一于一体来研究信号。而且小波变换具有多尺度特性，能够在不同尺度上对信号进行分析，因此在图像分割方面的得到了应用，<br>而且小波变换具有检测二元函数的局部突变能力，因此可作为图像边缘检测工具。图像的边缘出现在图像局部灰度不连续处，对应于二进小波变换的模极大值点。通过检测小波变换模极大值点可以确定图像的边缘小波变换位于各个尺度上，而每个尺度上的小波变换都能提供一定的边缘信息，因此可进行多尺度边缘检测来得到比较理想的图像边缘。</p></blockquote><ul><li><h4 id="深度学习分割"><a href="#深度学习分割" class="headerlink" title="深度学习分割"></a>深度学习分割</h4><p>①VGGNet</p><p>②FCN(Fully Convolutional Networks )</p><ul><li>DeepLab</li><li>DeconvNet<ul><li>SegNet</li></ul></li><li>PSPNet(Pyramid Scene Parsing Network)</li><li>Mask-RCNN</li></ul></li></ul><h3 id="按分割目的划分"><a href="#按分割目的划分" class="headerlink" title="按分割目的划分"></a>按分割目的划分</h3><h4 id="普通分割"><a href="#普通分割" class="headerlink" title="普通分割"></a>普通分割</h4><p>将不同分属不同物体的像素区域分开。<br>如前景与后景分割开，狗的区域与猫的区域与背景分割开。</p><h4 id="语义分割"><a href="#语义分割" class="headerlink" title="语义分割"></a>语义分割</h4><p>在普通分割的基础上，分类出每一块区域的语义（即这块区域是什么物体）。<br>如把画面中的所有物体都指出它们各自的类别。</p><h4 id="实例分割"><a href="#实例分割" class="headerlink" title="实例分割"></a>实例分割</h4><p>在语义分割的基础上，给每个物体编号。<br>如这个是该画面中的狗A，那个是画面中的狗B。</p><h2 id="二、基于深度学习分割"><a href="#二、基于深度学习分割" class="headerlink" title="二、基于深度学习分割"></a>二、基于深度学习分割</h2><h3 id="lt-1-gt-基于特征编码"><a href="#lt-1-gt-基于特征编码" class="headerlink" title="&lt;1&gt;基于特征编码"></a>&lt;1&gt;基于特征编码</h3><p>在特征提取领域中VGGnet和ResNet是两个非常有统治力的方法，接下来的一些篇幅会对这两个方法进行简短的介绍</p><ol><li><h4 id="VGGNet"><a href="#VGGNet" class="headerlink" title="VGGNet"></a>VGGNet</h4><p>由牛津大学计算机视觉组合和Google DeepMind公司研究员一起研发的深度卷积神经网络。它探索了卷积神经网络的深度和其性能之间的关系，通过反复的堆叠3×3的小型卷积核和2×2的最大池化层，成功的构建了16~19层深的卷积神经网络。VGGNet获得了ILSVRC 2014年比赛的亚军和定位项目的冠军，在top5上的错误率为7.5%。目前为止，VGGNet依然被用来提取图像的特征。<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pLmxvbGkubmV0LzIwMTkvMDYvMDkvNWNmY2UxOGVjNjBlYjU1NDcxLnBuZw" alt="img"><br>​ VGGNet的优缺点</p><p>①由于参数量主要集中在最后的三个FC（全连接层）当中，所以网络加深并不会带来参数爆炸的问题；</p><p>②多个小核卷积层的感受野等同于一个大核卷积层（三个3x3等同于一个7x7）但是参数量远少于大核卷积层而且非线性操作也多于后者，使得其学习能力较强</p><p>③VGG由于层数多而且最后的三个全连接层参数众多，导致其占用了更多的内存（140M）</p></li><li><h4 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h4></li></ol><p>随着深度学习的应用，各种深度学习模型随之出现，虽然在每年都会出现性能更好的新模型，但是对于前人工作的提升却不是那么明显，其中有重要问题就是深度学习网络在堆叠到一定深度的时候会出现梯度消失的现象，导致误差升高效果变差，后向传播时无法将梯度反馈到前面的网络层，使得前方的网络层的参数难以更新，训练效果变差。这个时候ResNet恰好站出来，成为深度学习发展历程中一个重要的转折点。<br>​ ResNet是由微软研究院的Kaiming He等四名华人提出，他们通过自己提出的ResNet Unit成功训练出来152层的神经网络并在ILSVRC2015比赛中斩获冠军。ResNet语义分割领域最受欢迎且最广泛运用的神经网络.ResNet的核心思想就是在网络中引入恒等映射，允许原始输入信息直接传到后面的层中，在学习过程中可以只学习上一个网络输出的残差（F(x)），因此ResNet又叫做残差网络。、<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pLmxvbGkubmV0LzIwMTkvMDYvMDkvNWNmY2UyMmEwNDhhNDI1ODE4LnBuZw" alt="img"><br>使用到ResNet的分割模型：</p><ul><li>Efficient Neural Network（ENet）：该网络类似于ResNet的bottleNeck方法；</li><li>ResNet-38：该网络在训练or测试阶段增加并移除了一些层，是一种浅层网络，它的结构是ResNet+FCN；</li><li>full-resolution residual network(FRRN)：FRRN网络具有和ResNet相同优越的训练特性，它由残差流和池化流两个处理流组成；</li><li>AdapNey：根据ResNet-50的网络进行改进，让原本的ResNet网络能够在更短的时间内学习到更多高分辨率的特征；<br>……<br>ResNet的优缺点：<br>1）引入了全新的网络结构（残差学习模块），形成了新的网络结构，可以使网络尽可能地加深；<br>2）使得前馈/反馈传播算法能够顺利进行，结构更加简单；<br>3）恒等映射地增加基本上不会降低网络的性能；<br>4）建设性地解决了网络训练的越深，误差升高，梯度消失越明显的问题；<br>5）由于ResNet搭建的层数众多，所以需要的训练时间也比平常网络要长。</li></ul><h3 id="lt-2-gt-基于区域选择"><a href="#lt-2-gt-基于区域选择" class="headerlink" title="&lt;2&gt;基于区域选择"></a>&lt;2&gt;基于区域选择</h3><p>Regional proposal 在计算机视觉领域是一个非常常用的算法，尤其是在目标检测领域。其核心思想就是检测颜色空间和相似矩阵，根据这些来检测待检测的区域。然后根据检测结果可以进行分类预测。<br>在语义分割领域，基于区域选择的几个算法主要是由前人的有关于目标检测的工作渐渐延伸到语义分割的领域的。其大致经过了以下几个阶段：</p><h4 id="①R-CNN"><a href="#①R-CNN" class="headerlink" title="①R-CNN"></a>①R-CNN</h4><p>是首个开创性地将深度神经网络应用到目标检测的算法，由于进行特征提取时是串行，处理耗时过长。</p><h4 id="②Fast-R-CNN"><a href="#②Fast-R-CNN" class="headerlink" title="②Fast R-CNN"></a>②Fast R-CNN</h4><p>节省了串行提取特征的时间.</p><h4 id="③Faster-R-CNN"><a href="#③Faster-R-CNN" class="headerlink" title="③Faster R-CNN"></a>③Faster R-CNN</h4><p>使用RPN替换了耗时的selective search算法，对整个网络结构有了突破性的优化；Faster R-CNN中使用的RPN和selective search比起来虽然速度更快，但是精度和selective search相比稍有不及，如果更注重速度而不是精度的话完全可以只使用RPN；</p><h4 id="④Mask-R-CNN"><a href="#④Mask-R-CNN" class="headerlink" title="④Mask R-CNN"></a>④Mask R-CNN</h4><p>是何恺明大神团队提出的一个基于Faster R-CNN模型的一种新型的分割模型，此论文斩获ICCV 2017的最佳论文，在Mask R-CNN的工作中，它主要完成了三件事情：目标检测，目标分类，像素级分割。</p><h4 id="⑤Mask-Scoring-R-CNN"><a href="#⑤Mask-Scoring-R-CNN" class="headerlink" title="⑤Mask Scoring R-CNN"></a>⑤Mask Scoring R-CNN</h4><p>恺明大神的Mask R-CNN已经很好啦！但是有个小毛病，就是评价函数只对目标检测的候选框进行打分，而不是分割模板（就是上文提到的优缺点中最后一点），所以会出现分割模板效果很差但是打分很高的情况。所以黄同学增加了对模板进行打分的MaskIoU Head，并且最终的分割结果在COCO数据集上超越了恺明大神，下面就是MS R-CNN的网络结构啦~</p><h3 id="lt-3-gt-基于RNN的图像分割"><a href="#lt-3-gt-基于RNN的图像分割" class="headerlink" title="&lt;3&gt;基于RNN的图像分割"></a>&lt;3&gt;基于RNN的图像分割</h3><h4 id="①ReSeg模型"><a href="#①ReSeg模型" class="headerlink" title="①ReSeg模型"></a>①ReSeg模型</h4><h4 id="②MDRNNs模型（Multi-Dimensional-Recurrent-Neural-Networks）"><a href="#②MDRNNs模型（Multi-Dimensional-Recurrent-Neural-Networks）" class="headerlink" title="②MDRNNs模型（Multi-Dimensional Recurrent Neural Networks）"></a>②MDRNNs模型（Multi-Dimensional Recurrent Neural Networks）</h4><h3 id="lt-4-gt-基于上采样-反卷积的分割方法"><a href="#lt-4-gt-基于上采样-反卷积的分割方法" class="headerlink" title="&lt;4&gt;基于上采样/反卷积的分割方法"></a>&lt;4&gt;基于上采样/反卷积的分割方法</h3><p>卷积神经网络在进行采样的时候会丢失部分细节信息，这样的目的是得到更具特征的价值。但是这个过程是不可逆的，有的时候会导致后面进行操作的时候图像的分辨率太低，出现细节丢失等问题。因此我们通过上采样在一定程度上可以补全一些丢失的信息，从而得到更加准确的分割边界。<br>接下来介绍几个非常著名的分割模型：</p><ol><li><h4 id="FCN"><a href="#FCN" class="headerlink" title="FCN"></a>FCN</h4><p>在图像分割领域已然成为一个业界标杆，大多数的分割方法多多少少都会利用到FCN或者其中的一部分，比如前面我们讲过的Mask R-CNN。<br>在FCN当中的反卷积-升采样结构中，图片会先进性上采样（扩大像素）；再进行卷积——通过学习获得权值。FCN的网络结构如下图所示：<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pLmxvbGkubmV0LzIwMTkvMDYvMDkvNWNmYzc5MjIyZDc5YTk3MDY1LnBuZw" alt="img"><br>优缺点：</p><ul><li>FCN对图像进行了像素级的分类，从而解决了语义级别的图像分割问题；</li><li>FCN可以接受任意尺寸的输入图像，可以保留下原始输入图像中的空间信息；</li><li>得到的结果由于上采样的原因比较模糊和平滑，对图像中的细节不敏感；</li><li>对各个像素分别进行分类，没有充分考虑像素与像素的关系，缺乏空间一致性。</li></ul></li><li><h4 id="SegNet"><a href="#SegNet" class="headerlink" title="SegNet"></a>SegNet</h4></li></ol><p>SegNet是剑桥提出的旨在解决自动驾驶或者智能机器人的图像语义分割深度网络，SegNet基于FCN，与FCN的思路十分相似，只是其编码-解码器和FCN的稍有不同，其解码器中使用去池化对特征图进行上采样，并保持高频细节的完整性；而编码器不使用全连接层，因此是拥有较少参数的轻量级网络。</p><p>SetNet的优缺点：</p><ul><li>保存了高频部分的完整性；</li><li>网络不笨重，参数少，较为轻便；</li><li>对于分类的边界位置置信度较低；</li><li>对于难以分辨的类别，例如人与自行车，两者如果有相互重叠，不确定性会增加。<br>以上两种网络结构就是基于反卷积/上采样的分割方法，当然其中最最最重要的就是FCN了，哪怕是后面大名鼎鼎的SegNet也是基于FCN架构的，而且FCN可谓是语义分割领域中开创级别的网络结构。</li></ul><h3 id="lt-5-gt-基于提高特征分辨率的分割方法"><a href="#lt-5-gt-基于提高特征分辨率的分割方法" class="headerlink" title="&lt;5&gt;基于提高特征分辨率的分割方法"></a>&lt;5&gt;基于提高特征分辨率的分割方法</h3><h4 id="DeepLab"><a href="#DeepLab" class="headerlink" title="DeepLab"></a>DeepLab</h4><p>Google提出的DeepLab ,DeepLab有v1 v2 v3，第一篇名字叫做DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs。这一系列论文引入了以下几点比较重要的方法：</p><p>第一个是带洞卷积，英文名叫做Dilated Convolution，或者Atrous Convolution。带洞卷积实际上就是普通的卷积核中间插入了几个洞，如下图。</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pLmxvbGkubmV0LzIwMTkvMDYvMDkvNWNmYzdhNmNjNzZkMTYwNTI3LnBuZw" alt="img"></p><p>它的运算量跟普通卷积保持一样，好处是它的“视野更大了”，比如普通3x3卷积的结果的视野是3x3，插入一个洞之后的视野是5x5。视野变大的作用是，在特征图缩小到同样倍数的情况下可以掌握更多图像的全局信息，这在语义分割中很重要。</p><p><img src="https://pic2.zhimg.com/v2-4959201e816888c6648f2e78cccfd253_b.jpg" alt="img"></p><p>解决了DCNN的几个关于分辨率的问题：<br>1）内部数据结构丢失；空间曾计划信息丢失；<br>2）小物体信息无法重建；<br>当然空洞卷积也存在一定的问题，它的问题主要体现在以下两方面：<br>1）网格效应<br>加入我们仅仅多次叠加dilation rate 2的 3x3 的卷积核则会出现以下问题我们发现卷积核并不连续，也就是说并不是所有的像素都用来计算了，这样会丧失信息的连续性；<br>2）小物体信息处理不当<br>我们从空洞卷积的设计背景来看可以推测出它是设计来获取long-ranged information。然而空洞步频选取得大获取只有利于大物体得分割，而对于小物体的分割可能并没有好处。所以如何处理好不同大小物体之间的关系也是设计好空洞卷积网络的关键。</p><h3 id="lt-6-gt-基于特征增强的分割方法"><a href="#lt-6-gt-基于特征增强的分割方法" class="headerlink" title="&lt;6&gt;基于特征增强的分割方法"></a>&lt;6&gt;基于特征增强的分割方法</h3><h4 id="PSPNet-全局金字塔池化"><a href="#PSPNet-全局金字塔池化" class="headerlink" title="PSPNet(全局金字塔池化)"></a>PSPNet(全局金字塔池化)</h4><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pLmxvbGkubmV0LzIwMTkvMDYvMDkvNWNmYzdjMGE5NWQ4YTQyMTczLnBuZw"></p><p>类似于我们那节课讲的sift算子：为了捕捉多尺度特征，高层特征包含了更多的语义和更少的位置信息。结合多分辨率图像和多尺度特征描述符的优点，在不丢失分辨率的情况下提取图像中的全局和局部信息，这样就能在一定程度上提升网络的性能</p><p>以上均摘自下面两篇博客：</p><p><a href="https://blog.csdn.net/weixin_41923961/article/details/80946586">WeisongZhao</a></p><p><a href="https://blog.csdn.net/electech6/article/details/95242875">计算机视觉life</a></p>]]></content>
      
      
      <categories>
          
          <category> 图像处理笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图像处理笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow第三节</title>
      <link href="/2020/08/21/tensorflow3/"/>
      <url>/2020/08/21/tensorflow3/</url>
      
        <content type="html"><![CDATA[<blockquote><p>理论知识以及相关概念</p></blockquote><a id="more"></a><h3 id="学习目标"><a href="#学习目标" class="headerlink" title="学习目标"></a>学习目标</h3><ul><li><p>预备知识</p></li><li><p>神经复杂度</p></li><li><p>指数衰减学习率</p></li><li><p>激活函数</p></li><li><p>损失减数</p></li><li><p>欠拟合和过拟合</p></li><li><p>正则化减少过拟合</p></li><li><p>优化器更新网络参数</p></li></ul><h4 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h4><ul><li><p>tf.where()</p><p>tf.where(条件语句，真返回A，假返回B)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line">b = tf.constant([<span class="number">0</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">c = tf.where(tf.greater(a,b),a,b)    <span class="comment">#若a&gt;b,返回a对应位置的元素，否则返回b对应位置的元素</span></span><br><span class="line">print(c)</span><br></pre></td></tr></table></figure></li><li><p>tf.random.RandomState.rand()</p><p>tf.random.RandomState.rand(维度)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpya <span class="keyword">as</span> np</span><br><span class="line">rdm = np.random.RandomState(seed=<span class="number">1</span>)    <span class="comment">#seed相同生成的随机数相同</span></span><br><span class="line">a = rdm.rand()      <span class="comment">#返回一个随机标量</span></span><br><span class="line">b = rdm.rand(<span class="number">2</span>,<span class="number">3</span>)      <span class="comment">#返回一个两行三列的随机矩阵</span></span><br><span class="line">print(a)</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>tf.vstack()</p><p>将两个数组按垂直方向叠加</p><p>np.vstack(数组1，数组2)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">b = np.array([<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>])</span><br><span class="line">c = vstack(<span class="string">&#x27;c为：&#x27;</span>，c)</span><br></pre></td></tr></table></figure></li><li><p>np.mgrid[]  , .ravel()  , np.c_[]</p><p>用来制表</p><p>np.mgrid[起始值，结束值，步长]</p><p>x.ravel()</p><p>将x变为一维数组，把变量拉直</p><p>np.c_[数组1， 数组2]</p><p>将两个数组进行配对，补成一个大数组</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x,y = np.mgrid[<span class="number">1</span>:<span class="number">3</span>:<span class="number">1</span>, <span class="number">2</span>:<span class="number">4</span>:<span class="number">0.5</span>]</span><br><span class="line">grid = np.c_[x.ravel(),y.ravelz()]</span><br><span class="line">print(x)</span><br><span class="line">print(y)</span><br><span class="line">print(grid)</span><br></pre></td></tr></table></figure></li></ul><h4 id="复杂度学习率"><a href="#复杂度学习率" class="headerlink" title="复杂度学习率"></a>复杂度学习率</h4><p>在上节课中我们发现<br>$$<br>在式子中：w_{t+1} = w_t-lr*\frac{\partial loss}{\partial w_t}<br>$$</p><p>$$<br>损失函数: loss = (w+1)^2<br>$$</p><p>$$<br>\frac{\partial loss}{\partial w} = 2w+2<br>$$</p><p>参数w初始为5，学习率为若是太小则整个过程更新太慢，如果太大就会越过极值点，导致最后结果不收敛，在极值点附近跳跃。</p><p>在应用中可以通过<strong>指数衰减学习率</strong>来实现：</p><blockquote><p>指数衰减学习率：先用较大的学习率，快速得到较优解，然后逐步减小学习率，使模型在训练后期稳定</p></blockquote><p>$$<br>指数衰减学习率 = 初始学习率*学习率衰减率^{(当前轮次/多少轮衰减一次)}<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">epoch = <span class="number">40</span></span><br><span class="line">lr_base = <span class="number">0.2</span>      <span class="comment">#初始学习率</span></span><br><span class="line">lr_decay = <span class="number">0.99</span>    <span class="comment">#学习率衰减率</span></span><br><span class="line">lr_step = <span class="number">1</span>        <span class="comment">#多少轮衰减一次 </span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epoch):</span><br><span class="line">  lr = lr_base *lr_decay**(epoch / lr _step)</span><br><span class="line">  <span class="keyword">with</span> tf.Gradient() <span class="keyword">as</span> tape:</span><br><span class="line">    loss = tf.square(w+<span class="number">1</span>)</span><br><span class="line">  grads = tape.gradient(loss, w)</span><br><span class="line">  w.assign_sub(lr*grads)</span><br><span class="line">  print(<span class="string">&quot;after %s epoch, w is %f, loss is %5f, lr = %f&quot;</span> </span><br><span class="line">        % (epoch, w.numpy(), loss(), lr)</span><br></pre></td></tr></table></figure><h4 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h4><p> 下面介绍几种常用的激活函数</p><ol><li><p>sigmoid函数<br>$$<br>f(x)= \frac{1}{1+e^{-x}}<br>$$<br>特点:①因为需要反向求导，会造成梯度消失问题，使得参数无法更新</p><p>​        ②输出非0均值，收敛慢</p><p>​        ③幂运算复杂，训练时间长</p></li><li><p>tanh<br>$$<br>f(x) = \frac{1-e^{-2x}}{1+e^{-2x}}<br>$$<br>特点：①输出是0均值</p><p>​            ②易造成梯度消失</p><p>​            ③幂运算复杂，训练时间长</p></li><li><p>Relu<br>$$<br>f(x) = max(x,0)\<br>$$</p><p>$$<br>=\begin{cases}<br>0, x&lt;0\<br>x, x&gt;=0<br>\end{cases}<br>$$<br>优点：</p><p>①解决了梯度消失问题（在正区间）</p><p>②只需判断输入是否大于零，计算速度快</p><p>③收敛速度远快于sigmoid和tanh</p><p>缺点：</p><p>①输出非零均值，收敛慢</p><p>②某些神经元可能永远不会被激活，导致相应参数永远不更新</p></li><li><p>Leaky Relu</p><p>是对Relu在负区间上的改进<br>$$<br>f(x) = max(ax,x)<br>$$<br>理论上来讲，leaky  relu有relu的所有优点，外加不会产生死神经元的问题，但是实际操作中，并没有完全证明他总是好于relu</p></li></ol><blockquote><p>对初学者的建议：</p><ul><li><p>首选relu函数</p></li><li><p>学习率设置较小值</p></li><li><p>输入特征标准化，即让输入特征满足以零为均值，1为标准差的正态分布</p></li><li><p>$$<br>初始函数中心化，即让随机生成的参数满足以零为均值，\sqrt{\frac{2}{当前输入特征个数}}为标准差的正态分布<br>$$</p></li></ul></blockquote><h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p><strong>损失函数</strong>用来评价模型的<strong>预测值</strong>和<strong>真实值</strong>不一样的程度，损失函数越好，通常模型的性能越好。不同的模型用的损失函数一般也不一样。</p><p><strong>损失函数</strong>分为<strong>经验风险损失函数</strong>和<strong>结构风险损失函数</strong>。经验风险损失函数指预测结果和实际结果的差别，结构风险损失函数是指经验风险损失函数加上正则项。</p><ul><li><p>均方误差：<br>$$<br>MSE(y_均-y) = \frac{\sum_{i = 1}^{n}(y-y_均)^2}{n}<br>$$<br>loss_mean = tf.reduce_mean(tf.sqare(y-y_))</p></li><li><p>自定义损失函数<br>$$<br>loss(y_均,y) = \begin{cases}<br>profit*(y_均 - y), y&lt;y_均\<br>cost*(y-y_均)， y&gt;y_均<br>\end{cases}<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Loss = tf.reduce_sum(tf.where:(tf,greater(y,y_均),cost(y,y_均), profit(y,y_均)))</span><br></pre></td></tr></table></figure></li><li><p>交叉熵损失函数</p><p>交叉熵损失函数CE表征两个概率分布之间的距离，原本的公式<br>$$<br>H（y_均，y） = -\sum{y_均*lny}<br>$$<br>tensorflow有直接的公式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.losses.categorical_crossentropy(y_均,y)</span><br></pre></td></tr></table></figure><p>一般我们要经过softmax函数然后计算y与y_的交叉熵损失函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.softmax_cross_entropy_with_logits(y_,y)</span><br><span class="line"><span class="comment">#下面用两种方式都进行运算</span></span><br><span class="line">y_ = np.array([[<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>]])</span><br><span class="line">y = np.array([[<span class="number">12</span>,<span class="number">3</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">10</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">5</span>],[<span class="number">4</span>,<span class="number">6.5</span>,<span class="number">1.2</span>],[<span class="number">3</span>,<span class="number">6</span>,<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line">y_pro = tf.nn.softmax(y)</span><br><span class="line">loss_ce1 = tf.losses.categorical_crossentropy(y_,y_pro)</span><br><span class="line"></span><br><span class="line">loss_se2 = tf.nn.softmax_cross_entropy_with_logits(y_,y)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;分布计算的结果&#x27;</span>, loss_se1)</span><br><span class="line">print(<span class="string">&#x27;结合计算的结果&#x27;</span>, loss_se2)</span><br></pre></td></tr></table></figure></li></ul><h4 id="欠拟合和过拟合"><a href="#欠拟合和过拟合" class="headerlink" title="欠拟合和过拟合"></a>欠拟合和过拟合</h4><p>欠拟合图像不能有效表示出坐标点，而过拟合因为对一种情况过于细节，在另外的样本来临可能会很不准确，存在一个泛化性差的特点。</p><ul><li><p>欠拟合的解决方法：</p><p>①增加输入特征项</p><p>②增加网络参数</p><p>③减少正则化参数</p></li><li><p>过拟合的解决方法：</p><p>①数据清洗</p><p>②增大训练集</p><p>③采用正则化</p><p>④增大正则化参数</p></li></ul><blockquote><p>正则化缓解过拟合：</p><p>正则化在损失函数中引入模型复杂度指标，利用给w加权值，强化了训练数据的噪声（一般不正则化b，只对权重正则化）<br>$$<br>loss = loss(y与y_均) +　REGULARIZER*loss(w)<br>$$<br>其中的REGULARIZER给出了w在总loss中的比例，即正则化的权重。</p></blockquote><h4 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h4><p>待优化参数w，损失函数loss，学习率lr，每迭代一个batch，t表示当前batch迭代的总次数<br>$$<br>计算t时刻的损失函数关于当前参数的梯度g_t=\bigtriangledown loss = \frac{\partial loss}{\partial(w_t)}<br>$$</p><p>$$<br>计算t时刻一阶动量m_t和二阶动量V_t<br>$$</p><p>$$<br>计算t时刻下降梯度：\eta = lr * m_t/\sqrt{V_t}<br>$$</p><p>$$<br>计算t+1时刻参数：w_{t+1} = w_t-\eta_t = w_t - lr * m_t/\sqrt{V_t}<br>$$</p><blockquote><p>一阶动量是跟梯度相关的函数</p><p>二阶动量是跟梯度的平方相关的函数</p></blockquote><p>下面搜索几种优化器使用即可</p><ol><li>SGD</li><li>SGDM（含momentum 的SGD）</li><li>Adagrad（SGD增加二阶动量）</li><li>RMSProp（SGD增加二阶动量）</li><li>Adam（结合SGDM和RMSProp）</li></ol>]]></content>
      
      
      <categories>
          
          <category> TensorFlow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow第二节</title>
      <link href="/2020/08/19/tensorflow2/"/>
      <url>/2020/08/19/tensorflow2/</url>
      
        <content type="html"><![CDATA[<blockquote><p>tensorflow实战，实现鸢尾花的分类</p></blockquote><a id="more"></a><h3 id="鸢尾花分类"><a href="#鸢尾花分类" class="headerlink" title="鸢尾花分类"></a>鸢尾花分类</h3><p>三种鸢尾花，有四种特征，四个数据同时输入，权重共有3*4=12组, [1,4]✖️[4,3]</p><h4 id="鸢尾花数据读入"><a href="#鸢尾花数据读入" class="headerlink" title="鸢尾花数据读入"></a>鸢尾花数据读入</h4><p>从sklearn包dataset读入数据集，语法为：</p><blockquote><p>from sklearn.datasets import load_iris</p><p>x_data = datasets.load_isis().data</p><p>y_data = datasets.load_isis().target</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">x_data = datasets.load_isis().data    <span class="comment">#.data返回数据集的输入特征</span></span><br><span class="line">y_data = datasets.load_isis().target      <span class="comment"># 。target返回数据集的所有标签</span></span><br><span class="line">print(x_data)</span><br><span class="line">print(y_data)</span><br><span class="line"></span><br><span class="line">x_data = DataFrame(x_data,columes=[<span class="string">&quot;花萼长&quot;</span>，<span class="string">&quot;花萼宽&quot;</span>，<span class="string">&quot;花瓣长&quot;</span>，<span class="string">&quot;花瓣宽&quot;</span>])   <span class="comment"># 将数据转换成表格形式</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;display.unicode.east_asian_width&#x27;</span>,<span class="literal">True</span>)   <span class="comment">#设置列名对齐</span></span><br><span class="line">print(<span class="string">&quot;x_data add index: \n&quot;</span>,x_data)</span><br><span class="line">x_data[<span class="string">&#x27;类别&#x27;</span>] = y_data    <span class="comment">#新增加一列，标签为类别，数据为y_data</span></span><br><span class="line">print(<span class="string">&quot;x_data add a colum: \n&quot;</span>,x_data)</span><br></pre></td></tr></table></figure><p>在运行过程中会提示我们缺少数据包，然后我们用python自带的pip下载安装即可（比如：pip install sklearn）</p><h4 id="神经网络实现鸢尾花分类"><a href="#神经网络实现鸢尾花分类" class="headerlink" title="神经网络实现鸢尾花分类"></a>神经网络实现鸢尾花分类</h4><blockquote><p>1、准备数据</p></blockquote><ul><li>数据集读入</li><li>数据集乱序</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">116</span>)    <span class="comment">#使用相同的seed使输入特征标签一一对应</span></span><br><span class="line">np.random.shuffle（x_data）</span><br><span class="line">np.random.seed(<span class="number">116</span>)</span><br><span class="line">np.random.shuffle(y_data)</span><br><span class="line">tf.random.set_seed(<span class="number">116</span>)</span><br></pre></td></tr></table></figure><ul><li><p>数据集分出永不相见的训练集和测试集</p><p>训练集为前120行，测试集为最后30行</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_train = x_data[:<span class="number">-30</span>]</span><br><span class="line">y_train = y_data[:<span class="number">-30</span>]</span><br><span class="line">x_test = x_data[<span class="number">-30</span>:]</span><br><span class="line">y_test = y_data[<span class="number">-30</span>:]</span><br></pre></td></tr></table></figure><ul><li><p>配成【输入特征， 标签】对，每次喂入一小撮（batch）</p><p>每32组数据打包成一个batch</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_db = tf.data.Dataset.from_tensor_slice((x_train,y_train)).batch(<span class="number">32</span>)</span><br><span class="line">test_db = tf.data.Dataset.from_tensor_slice((x_train,y_train)).batch(<span class="number">32</span>)</span><br></pre></td></tr></table></figure><blockquote><p>搭建网络</p></blockquote><p>定义神经网络中所有可训练参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">w1 = tf.Variable(tf.random.truncated_normal([<span class="number">4</span>,<span class="number">3</span>],stddev = <span class="number">0</span>, seed =<span class="number">1</span>))</span><br><span class="line">b1 = tf.Variable(tf.random.truncated_normal([<span class="number">3</span>],stddev=<span class="number">0.1</span>,seed=<span class="number">1</span>))</span><br></pre></td></tr></table></figure><blockquote><p>参数优化</p></blockquote><p>嵌套循环迭代，with结构更新参数，显示当前loss</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epoch):   <span class="comment">#数据集级别迭代</span></span><br><span class="line">  <span class="keyword">for</span> step,(x_train,y_train) <span class="keyword">in</span> enumerate(train_db):</span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:     <span class="comment">#记录梯度信息</span></span><br><span class="line">      <span class="comment">#向前传播过程计算y</span></span><br><span class="line">      <span class="comment">#计算总的loss</span></span><br><span class="line">      y = tf.matmul(x_train,w1)+b1     <span class="comment">#神经网络乘加运算</span></span><br><span class="line">      y = tf.nn.softmax(y)    <span class="comment">#使输出y符和概率分布，此操作后和独热码同量级</span></span><br><span class="line">      y_ = tf.one_hot(y_train，depth = <span class="number">3</span>)  <span class="comment">#将标签转换为独热码形式</span></span><br><span class="line">      loss = tf.reduce_mean(tf.quare(y_-y))</span><br><span class="line">      loss_all += loss.numpy()</span><br><span class="line">    grads = tap.gradient(loss.[w1,b1])    <span class="comment">#计算loss对各个参数的梯度</span></span><br><span class="line">    <span class="comment">#实现梯度的更新：w1=w1-lr*w1_grad, b1= b1-lr*b_grad</span></span><br><span class="line">    w1.assign_sub(lr*grads[<span class="number">0</span>])     <span class="comment">#参数自更新</span></span><br><span class="line">    b1.assign_sub(lr*grads[<span class="number">1</span>])     <span class="comment">#其中的lr是学习率</span></span><br><span class="line">  print(<span class="string">&quot;Epoch &#123;&#125;,loss:&#123;&#125;&quot;</span>.format(epoch,loss_all/<span class="number">4</span>))</span><br></pre></td></tr></table></figure><blockquote><p>测试效果</p></blockquote><p>计算当前参数向前传播后的准确率，显示当前acc</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> x_test,y_test <span class="keyword">in</span> test_db:</span><br><span class="line">  y = tf.matmul(h,w)+b      <span class="comment">#y为预测结果</span></span><br><span class="line">  y = tf.nn.softmax(y)       <span class="comment">#是结果符合概率分布</span></span><br><span class="line">  pred= tf.argmax(y,axis=<span class="number">1</span>)    <span class="comment">#返回y中最大值的索引，即预测的分类</span></span><br><span class="line">  pred= tf.case(pred,dtype=y_type.dtype)    <span class="comment">#调整数据类型，与标签一致 </span></span><br><span class="line">  correct = tf.cast(tf.equal(pred,y_test),dtype = tf.int32)</span><br><span class="line">  correct = tf.reduce_sum(correct)     <span class="comment">#将每个batch的correct数加起来</span></span><br><span class="line">  total_correct += int(correct)    <span class="comment">#将所有batch中的correct数加起来</span></span><br><span class="line">  total_number +=x_test.shape[<span class="number">0</span>]</span><br><span class="line">acc = total_correct/total_number</span><br><span class="line">print(<span class="string">&quot;test_acc:&quot;</span>, acc)</span><br></pre></td></tr></table></figure><blockquote><p>acc/loss 可视化</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.title(<span class="string">&quot;acc curve&quot;</span>)  <span class="comment">#图片标题</span></span><br><span class="line">plt.xlabel(<span class="string">&quot;epoch&quot;</span>)   <span class="comment"># x轴名字</span></span><br><span class="line">plt,ylabel(<span class="string">&quot;acc&quot;</span>)      <span class="comment">#y轴名字</span></span><br><span class="line">plt.plot(test_acc,label=<span class="string">&quot;$Accuracy$&quot;</span>)    <span class="comment">#逐点画出test_acc值并连线</span></span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>本文先对代码的整个大体流程有一个感性的认识，详细过程，下面会有讲解！</p>]]></content>
      
      
      <categories>
          
          <category> TensorFlow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow第一节</title>
      <link href="/2020/08/19/tensorflow1/"/>
      <url>/2020/08/19/tensorflow1/</url>
      
        <content type="html"><![CDATA[<blockquote><p>先学习一下tensorflow的相关的基本函数</p></blockquote><a id="more"></a><h3 id="常用函数"><a href="#常用函数" class="headerlink" title="常用函数"></a>常用函数</h3><h4 id="1、类型转换"><a href="#1、类型转换" class="headerlink" title="1、类型转换"></a>1、类型转换</h4><ul><li>强制tensor转换为该数据类型</li></ul><p>tf.case(张量名, dtype=数据类型)</p><ul><li>计算张量维度上元素的最小值</li></ul><p>tf.reduce_min(张量名)</p><ul><li>计算张量维度上元素的最大值</li></ul><p>tf.reduce_max(张量名)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x1 = tf.constant([<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>], dtype = tf.float64)</span><br><span class="line">print(x1)</span><br><span class="line">x2 = tf.case(x1, tf.int32)</span><br><span class="line">print(x2)</span><br><span class="line">print(tf.reduce_min(x2), tf.reduce_max(x2))</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.Tensor([<span class="number">1.2</span><span class="number">.3</span>.], shape = (<span class="number">3</span>,), dtype = float64)</span><br><span class="line">tf.Tensor([<span class="number">1</span> <span class="number">2</span> <span class="number">3</span>], shape = (<span class="number">3</span>,), dtype = int32)</span><br><span class="line">tf.Tensor(<span class="number">1</span>, shape = (), dtype = int32)</span><br><span class="line">tf.Tensor(<span class="number">3</span>, shape = (), dtype = int32)</span><br></pre></td></tr></table></figure><h4 id="2、理解axis"><a href="#2、理解axis" class="headerlink" title="2、理解axis"></a>2、理解axis</h4><p>在一个二维向量中axis=0代表以列为单位求取最大值，axis代表以行为单位求取最大值，如果不指定，则所有元素都参与运算</p><ul><li>计算张量沿着指定维度的平均值</li></ul><p>tf.reduce_mean(张量名, axis=操作轴)</p><ul><li>计算张量沿着指定维度的和</li></ul><p>tf.reduce_sum(张量名, axis=操作轴)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = tf.constant([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>]])</span><br><span class="line">print(x)</span><br><span class="line">print(tf.reduce_mean(x))</span><br><span class="line">print(tf.reduce_sum(x,axis=<span class="number">1</span>))</span><br></pre></td></tr></table></figure><h4 id="3、运算"><a href="#3、运算" class="headerlink" title="3、运算"></a>3、运算</h4><ul><li>将变量标记为可训练</li></ul><p>tf.Variable（初始值）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.Variable(tf.random.normal([<span class="number">2</span>,<span class="number">2</span>], mean = <span class="number">0</span>, stddev = <span class="number">1</span>))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a = tf.ones([<span class="number">1</span>, <span class="number">3</span>])   <span class="comment"># 1*3的矩阵赋值为1</span></span><br><span class="line">b = tf.fill([<span class="number">1</span>,<span class="number">3</span>], <span class="number">3.</span>)  <span class="comment"># 1*3的矩阵赋值为3</span></span><br><span class="line">print(a)</span><br><span class="line">print(b)</span><br><span class="line">print(tf.add(a, b))</span><br><span class="line">print(tf.subtract(a, b))</span><br><span class="line">print(tf.multiply(a, b))</span><br><span class="line">print(tf.divide(b, a))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = tf.fill([<span class="number">1</span>,<span class="number">2</span>], <span class="number">3.</span>)</span><br><span class="line">print(a)</span><br><span class="line">print(tf.pow(a, <span class="number">3</span>))</span><br><span class="line">print(tf.square(a))</span><br><span class="line">print(tf.sqrt(a))</span><br></pre></td></tr></table></figure><h4 id="4、对应标签和数据"><a href="#4、对应标签和数据" class="headerlink" title="4、对应标签和数据"></a>4、对应标签和数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">features = tf.constant([<span class="number">12</span>, <span class="number">23</span>, <span class="number">10</span> ,<span class="number">17</span>])     <span class="comment">#获取数据</span></span><br><span class="line">labels = tf.constant([<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>])       <span class="comment">#获取标签</span></span><br><span class="line">dataset = tf.data.Dataset.from_tensor_slices((features,labels))</span><br><span class="line">print(dataset)</span><br><span class="line"><span class="keyword">for</span> element <span class="keyword">in</span> dataset：</span><br><span class="line">    print(element)</span><br></pre></td></tr></table></figure><h4 id="5、求导运算"><a href="#5、求导运算" class="headerlink" title="5、求导运算"></a>5、求导运算</h4><p>with结构记录计算过程，gradient求出张量的梯度</p><blockquote><p>with tf.GradientTape() as tape:</p><p>若干计算过程</p><p>grad=tape.gradient(函数，对谁求导)</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">  w = tf.Variable(tf.constant(<span class="number">3.0</span>))</span><br><span class="line">  loss = tf.pow(w, <span class="number">2</span>)</span><br><span class="line">grad = tape.gradient(loss, w)</span><br><span class="line">print(grad)</span><br></pre></td></tr></table></figure><h4 id="6、enumerate"><a href="#6、enumerate" class="headerlink" title="6、enumerate"></a>6、enumerate</h4><p>enumerate是python的内建函数，他可以遍历元素，元组或字符串</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">seq = [<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;three&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> i, element <span class="keyword">in</span> enumerate(seq):</span><br><span class="line">  print(i, element)</span><br></pre></td></tr></table></figure><h4 id="7、tf-one-hot-独热编码"><a href="#7、tf-one-hot-独热编码" class="headerlink" title="7、tf.one_hot      独热编码"></a>7、tf.one_hot      独热编码</h4><p>在分类问题中，常用独热码作为标签，标记类别：0代表非，1表示是</p><blockquote><p>标签：1</p><p>独热码： （0， 1， 0）</p><p>表示是标签0的概率为0，是标签1的概率是百分百，是标签2的概率是0</p></blockquote><h4 id="8、tf-one-hot-待转换数据，depth-几分类"><a href="#8、tf-one-hot-待转换数据，depth-几分类" class="headerlink" title="8、tf.one_hot(待转换数据，depth=几分类)"></a>8、tf.one_hot(待转换数据，depth=几分类)</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">classes = <span class="number">3</span></span><br><span class="line">labels = tf.constant([<span class="number">1</span>,<span class="number">0</span>,<span class="number">2</span>])</span><br><span class="line">output = tf.one_hot(labels, depth = classes)</span><br><span class="line">print(output)</span><br></pre></td></tr></table></figure><h4 id="9、tf-nn-softmax"><a href="#9、tf-nn-softmax" class="headerlink" title="9、tf.nn.softmax"></a>9、tf.nn.softmax</h4><p>tf.nn.softmax能把n个分类的n个输出转换成0到1之间的概率值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y = tf.constant([<span class="number">1.01</span>, <span class="number">2.01</span>, <span class="number">-0.66</span>])     <span class="comment">#定义一些数值</span></span><br><span class="line">y_pro = tf.nn.softmax(y)      <span class="comment">#转换成标准概率</span></span><br><span class="line">print(<span class="string">&quot;result, y_pro is &quot;</span>,y_pro)</span><br></pre></td></tr></table></figure><h4 id="10、tf-argmax"><a href="#10、tf-argmax" class="headerlink" title="10、tf.argmax"></a>10、tf.argmax</h4><p>返回张量最大值得索引，tf.argmax(张量名，axis=操作轴)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">test = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">4</span>,<span class="number">3</span>],[<span class="number">8</span>,<span class="number">7</span>,<span class="number">2</span>]])</span><br><span class="line">print(test)</span><br><span class="line">print(tf.argmax(test,axis=<span class="number">0</span>))</span><br><span class="line">print(tf.argmax(test,axis=<span class="number">0</span>))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> TensorFlow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>理解边缘检测sift</title>
      <link href="/2020/08/18/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E7%89%B9%E5%BE%81%E7%82%B9%E6%A3%80%E6%B5%8Bsift/"/>
      <url>/2020/08/18/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E7%89%B9%E5%BE%81%E7%82%B9%E6%A3%80%E6%B5%8Bsift/</url>
      
        <content type="html"><![CDATA[<blockquote><p>图像处理——sift理解</p></blockquote><a id="more"></a><h3 id="通俗的大致理解"><a href="#通俗的大致理解" class="headerlink" title="通俗的大致理解"></a>通俗的大致理解</h3><ol><li><p>首先，理解同一幅<strong>图像在不同的空间中有不同的表达方式</strong>。比如在RGB空间中，图像中的像素点可以用颜色值(r,g,b)来表示；在灰度空间中，图像中的像素点可以用灰度值来表示。类似的，你可以把梯度图像认为是图像在<strong>梯度空间</strong>中的一种表达，图像中的像素点可以<strong>用梯度方向</strong>来表示，即，梯度图像中的像素点表达的是该点的梯度方向（而不是灰度值/颜色值）。</p></li><li><p>其次，理解图像的<strong>灰度直方图是什么</strong>。图像的灰度直方图就是把<strong>灰度图像中灰度值分别为0,1,…,255的像素的个数统计起来</strong>，得到的一个一维向量。类似的，图像的梯度直方图就是把<strong>梯度图像中梯度方向分别为0°到360°的像素的个数统计起来</strong>，得到一个一维向量。</p></li></ol><p>SIFT是什么？简单来说就是图像中某个局部区域（如16*16像素的一个区域）对应的梯度直方图，这就是最简单直观的理解。当然，SIFT还包括各种细节，如量化，尺度金字塔、旋转不变性、局部归一化等，这些东西很多博客上都有“教科书般”的介绍。</p><p>SURF是什么？SURF本身不是什么新的descriptor，而是对SIFT实现上的加速，核心点在于采用<strong>积分图</strong>对计算加速。</p><p>作者：大道至简知不语<br>链接：<a href="https://www.zhihu.com/question/40736560/answer/358547318">https://www.zhihu.com/question/40736560/answer/358547318</a><br>来源：知乎</p><p><strong>知识点：积分图</strong></p><h3 id="sift深度剖析"><a href="#sift深度剖析" class="headerlink" title="sift深度剖析"></a>sift深度剖析</h3><h4 id="1、明确学习目的"><a href="#1、明确学习目的" class="headerlink" title="1、明确学习目的"></a>1、明确学习目的</h4><p>不管是Harris还是Shi-Tomas，角点检测检测即便做得再优化，也总是有不可克服的缺点：</p><ul><li><strong>对尺度很敏感，不具有尺度不变性</strong></li><li><strong>需要设计角点匹配算法</strong></li></ul><p>而SIFT算法是一种基于局部兴趣点的算法，因此</p><ul><li><strong>不仅对图片大小和旋转不敏感</strong></li><li><strong>而且对光照、噪声等影响的抗击能力也非常优秀</strong></li></ul><p>因此，该算法在性能和适用范围方面较于之前的算法有着质的改变。</p><p>在学习sift算法之前，我们先得搞明白这个算法目的是为了干什么，无非就是找到图像中的特征点，找到优质的特征点。</p><p>优质的特征点有什么特征呢？</p><ul><li><strong>尺度不变性：</strong>人类在识别一个物体时，不管这个物体或远或近，都能对它进行正确的辨认，这就是所谓的尺度不变性。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/CallMe-star/picbed@master/cat_scale.jpg"></p><ul><li><strong>旋转不变性：</strong>当这个物体发生旋转时，我们照样可以正确地辨认它，这就是所谓的旋转不变性。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/CallMe-star/picbed@master/cat_direct.jpg"></p><h4 id="2、sift过程"><a href="#2、sift过程" class="headerlink" title="2、sift过程"></a>2、sift过程</h4><h5 id="构建多尺度的高斯金字塔"><a href="#构建多尺度的高斯金字塔" class="headerlink" title="构建多尺度的高斯金字塔"></a>构建多尺度的高斯金字塔</h5><blockquote><p>①构建单尺度的空间，单尺度空间有6张图，六张图分别是经过方差大小不同的高斯滤波处理的图</p></blockquote><blockquote><p>②然后对同一尺度的一组照片中的相邻滤波处理的照片做差得到的就是图像的轮廓，轮廓就是我们要得到的最基本的特征。做差得出的图像就叫做DoG。</p></blockquote><blockquote><p>③然后再分成多个尺度，小尺度是通过上一层大尺度的第三张照片作为原图再次进行高斯滤波得到的。这一步就是要解决尺度的问题：构建金字塔，将特征值拓展到多分辨率上。</p><p><strong><em>我的疑惑点：这么多尺度的图像他是怎样提取不同尺度的图像，然后融合在一起的</em></strong></p></blockquote><h5 id="检测尺度空间的极值点"><a href="#检测尺度空间的极值点" class="headerlink" title="检测尺度空间的极值点"></a>检测尺度空间的极值点</h5><blockquote><p>直接遍历找出极值点，极值点不但要根这个点周围的八个点比较，还要跟同一层相邻的另外两张图像作比较。一共比较26个点。注意做完这一步之后，应该就可以在原图上画出来极值点坐标了示意图了。</p></blockquote><h5 id="精确定位极值点"><a href="#精确定位极值点" class="headerlink" title="精确定位极值点"></a>精确定位极值点</h5><blockquote><p>上一步我们已经找到了相关的特征点的大致坐标，接下来就要确定他们的准确位置，这里牵涉到很多数学运算。</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/CallMe-star/picbed@master/jingqueweizhi.jpg"></p><h5 id="选取特征点的方向"><a href="#选取特征点的方向" class="headerlink" title="选取特征点的方向"></a>选取特征点的方向</h5><blockquote><p>对我们已经用金字塔解决了尺度不变性问题，下面就要通过确定特征点的方向来解决旋转不变性问题。完成关键点的梯度计算后，使用直方图统计邻域内像素的梯度和方向。梯度直方图将0~360度的方向范围分为36个柱(bins)，其中每柱10度。如图所示，直方图的峰值方向代表了关键点的主方向，(为简化，图中只画了八个方向的直方图)。</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/CallMe-star/picbed@master/direction.jpg"></p><blockquote><p><strong>直方图的峰值则代表了该关键点处邻域梯度的主方向，即作为该关键点的方向；其他的达到最大值80%的方向可作为辅助方向。</strong>到这里我们已经检测出的含有位置、尺度和方向的关键点即是该图像的SIFT特征点。</p></blockquote><h5 id="生成关键描述子"><a href="#生成关键描述子" class="headerlink" title="生成关键描述子"></a>生成关键描述子</h5><p>到这里还没有结束</p><p>金字塔保证特征点的空间不变性， 严格删选保证了特征点的准确性， 方向信息保证了特征点的旋转不变性。我们如何把所有信息作为属性附加给关键点呢？</p><p>①为什么要添加描述子：通过上面的步骤，对于每一个关键点，拥有三个信息：<strong>位置、尺度以及方向</strong>。接下来就是为每个关键点建立一个描述符，用一组向量将这个关键点描述出来，使其不随各种变化而改变，比如光照变化、视角变化等等。这个描述子不但包括关键点，也包含关键点周围对其有贡献的像素点，并且描述符应该有较高的独特性，以便于提高特征点正确匹配的概率。</p><p>②添加过程：<strong>1) 确定计算描述子所需的图像区域</strong>特征描述子与特征点所在的尺度有关，因此，对梯度的求取应在特征点对应的高斯图像上进行。将关键点附近的邻域划分为d*d(Lowe建议d=4)个子区域，每个子区域做为一个种子点，每个种子点有8个方向。每个子区域的大小与关键点方向分配时相同。</p><p><img src="https://cdn.jsdelivr.net/gh/CallMe-star/picbed@master/miaoshuziimg.jpg"></p><p>以关键点为中心，4*4格为一个种子点，每个种子点8个方向。</p><p>每一个小格都代表了特征点邻域所在的尺度空间的一个像素 ，箭头方向代表了像素梯度方向，箭头长度代表该像素的幅值。然后在4×4的窗口内计算8个方向的梯度方向直方图。绘制每个梯度方向的累加可形成一个种子点。</p><ul><li><strong>2) 将坐标轴旋转为关键点的方向，以确保旋转不变性</strong></li></ul><p><img src="https://cdn.jsdelivr.net/gh/CallMe-star/picbed@master/xuanzhuanxy.jpg"></p><ul><li><strong>3) 将邻域内的采样点分配到对应的子区域内，将子区域内的梯度值分配到8个方向上，计算其权值</strong></li></ul><p><img src="https://www.zhihu.com/equation?tex=w=m(a+x,+b+y)+*+e%5E%7B-%5Cfrac%7B%5Cleft(x%5E%7B%5Cprime%7D%5Cright)%5E%7B2%7D+%5Cleft(y%5E%7B%5Cprime%7D%5Cright)%5E%7B2%7D%7D%7B2+%5Ctimes(0.5+d)%5E%7B2%7D%7D%7D" alt="[公式]"></p><p>其中a，b为关键点在高斯金字塔图像中的位置坐标。</p><ul><li><strong>4) 插值计算每个种子点八个方向的梯度</strong></li></ul><p><img src="https://cdn.jsdelivr.net/gh/CallMe-star/picbed@master/zhongzitidu.jpg"></p><ul><li><strong>5) 归一化</strong></li></ul><p>如上统计的4<em>4</em>8=128个梯度信息即为该关键点的特征向量。特征向量形成后，为了去除光照变化的影响，需要对它们进行归一化处理，对于图像灰度值整体漂移，图像各点的梯度是邻域像素相减得到，所以也能去除。</p><ul><li><strong>6） 向量门限</strong></li></ul><p>描述子向量门限。非线性光照，相机饱和度变化对造成某些方向的梯度值过大，而对方向的影响微弱。因此设置门限值(向量归一化后，一般取0.2)截断较大的梯度值。然后，再进行一次归一化处理，提高特征的鉴别性。</p><ul><li><strong>7） 排序</strong></li></ul><p>按特征点的尺度对特征描述向量进行排序。</p><p><img src="https://cdn.jsdelivr.net/gh/CallMe-star/picbed@master/paixu.jpg"></p><p>在每个4<em>4的1/16象限中，通过加权梯度值加到直方图8个方向区间中的一个，计算出一个梯度方向直方图。这样就可以对每个feature形成一个4</em>4<em>8=128维的描述子，每一维都可以表示4</em>4个格子中一个的scale/orientation. 将这个向量归一化之后，就进一步去除了光照的影响。</p><h4 id="3-sift怎么匹配"><a href="#3-sift怎么匹配" class="headerlink" title="3.sift怎么匹配"></a>3.sift怎么匹配</h4><p><strong>1、 首先还是要对图片生成特征点</strong></p><p>一张图经过SIFT算法后，会得到多个特征点，每个特征点有128维的描述子属性。那么，匹配特征点都简单多啦！</p><p>生成了A、B两幅图的描述子，（分别是k1<em>128维和k2</em>128维），就将两图中各个scale（所有scale）的描述子进行匹配，匹配上128维即可表示两个特征点match上了。</p><p><strong>2、 然后考虑怎么匹配</strong></p><p>当两幅图像的SIFT特征向量生成后，下一步我们采用关键点特征向量的欧式距离来作为两幅图像中关键点的相似性判定度量。取图像1中的某个关键点，并找出其与图像2中欧式距离最近的前两个关键点，在这两个关键点中，如果最近的距离除以次近的距离少于某个比例阈值，则接受这一对匹配点。降低这个比例阈值，SIFT匹配点数目会减少，但更加稳定。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/xfeatures2d.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv::xfeatures2d;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>** argv)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    Mat cat = imread(<span class="string">&quot;cat.png&quot;</span>);</span><br><span class="line">    Mat smallCat = imread(<span class="string">&quot;smallCat.png&quot;</span>);</span><br><span class="line">    imshow(<span class="string">&quot;cat image&quot;</span>, cat);</span><br><span class="line">    imshow(<span class="string">&quot;smallCat image&quot;</span>, smallCat);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> detector = SIFT::create();</span><br><span class="line">    <span class="built_in">vector</span>&lt;KeyPoint&gt; keypoints_cat, keypoints_smallCat;</span><br><span class="line">    Mat descriptor_cat, descriptor_smallCat;</span><br><span class="line">    detector-&gt;detectAndCompute(cat, Mat(), keypoints_cat, descriptor_cat);</span><br><span class="line">    detector-&gt;detectAndCompute(smallCat, Mat(), keypoints_smallCat, descriptor_smallCat);</span><br><span class="line"></span><br><span class="line">    Ptr&lt;FlannBasedMatcher&gt; matcher = FlannBasedMatcher::create();</span><br><span class="line">    <span class="built_in">vector</span>&lt;DMatch&gt; matches;</span><br><span class="line">    matcher-&gt;match(descriptor_cat, descriptor_smallCat, matches);</span><br><span class="line">    Mat dst;</span><br><span class="line">    drawMatches(cat, keypoints_cat, smallCat, keypoints_smallCat, matches, dst);</span><br><span class="line">    imshow(<span class="string">&quot;match-demo&quot;</span>, dst);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    waitKey(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://picb.zhimg.com/80/v2-295c77fc626560a0421be89e19516d6d_720w.jpg" alt="img"></p><p><img src="https://pic4.zhimg.com/80/v2-aac36afb03c30320918b8d3d9f7f986a_720w.jpg" alt="img"></p><p><img src="https://pic1.zhimg.com/80/v2-799a944fce5797047a6e8a18fb624d2e_720w.jpg" alt="img"></p><p>作者: lowkeyway</p><p>转载自: <a href="https://zhuanlan.zhihu.com/p/90122194">https://zhuanlan.zhihu.com/p/90122194</a></p>]]></content>
      
      
      <categories>
          
          <category> 图像处理笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图像处理笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>傅里叶变换</title>
      <link href="/2020/08/10/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/"/>
      <url>/2020/08/10/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/</url>
      
        <content type="html"><![CDATA[<blockquote><p>图像处理——傅里叶</p></blockquote><a id="more"></a><h3 id="1-傅里叶变换的理解"><a href="#1-傅里叶变换的理解" class="headerlink" title="1.傅里叶变换的理解"></a>1.傅里叶变换的理解</h3><p>傅里叶变换的相关数学公式目前还没有搞懂，先不整那个东西，我们主要是研究傅里叶变换的一些思想和应用。这个思想起源于牛顿研究那个三棱镜，白光透过棱镜之后会被分解为七种颜色的光，这些光叠加又能形成白光，所以说可以把一种事物分解成好几种事物的加和。</p><p>后来傅里叶就提出了**<em>傅里叶级数**</em>，一个等幅度不同频或者等频不同幅的波形可以由一组正弦波余弦波的加和得到（原话：任何连续周期信号可以由一组适当的正弦曲线组合而成）</p><h3 id="2-傅里叶级数"><a href="#2-傅里叶级数" class="headerlink" title="2.傅里叶级数"></a>2.傅里叶级数</h3><p>可以这么理解：原图像相当于在时间域中的一个曲线，坐标图是个二维坐标系，横轴是时间，纵轴是幅值的一个曲线，我们通过傅里叶变换可以把这条曲线变成多条正余弦函数相加的形式：傅里叶变换之后形成的是一个三维坐标系，他的x轴是频率（w），y轴是相位（因为每个正余弦函数的起点不同，有的是从零点开始，有的不是，这个曲线开始的那个幅值就是相位，相位就是后公式中的φ），z轴是振幅高度，。这样可以把一个图像从空间域转换到频率域，因为两者等价，所以可以逆变换回去。但这个傅里叶级数只能针对周期型函数才能拆分成多个正余弦函数相加，所以后来有了傅里叶变换。<br>$$<br>f(t) = \frac{a_n}{2}+\sum a_n*sin（nwt+φ_n）<br>$$</p><h3 id="3-傅里叶变换"><a href="#3-傅里叶变换" class="headerlink" title="3.傅里叶变换"></a>3.傅里叶变换</h3><p>其中推导公式中用到了欧拉公式，<br>$$<br>cos(x)+i*sin(x) = e^{ix}\<br>$$<br>$$<br>x = wt<br>$$</p><p>$$<br>F_T = \int_{-\infty}^{+\infty}f(t)e^{jwt}dt\<br>$$</p><p>然后通过逆变换可以再变回去。通过傅里叶变换就可以把一个随机的曲线，转换到频率域，只不过这次的三维坐标系对应的w和幅值的函数图像不再是离散的图像了，而是一个连续图像。y轴所对应的相位意义没变。</p><h3 id="4-应用"><a href="#4-应用" class="headerlink" title="4.应用"></a>4.应用</h3><h4 id="声音"><a href="#声音" class="headerlink" title="- 声音"></a>- 声音</h4><p>通过分析频率域，可以分析出低频可能是男生说话，高频可能是女生说话，再高的频率就是噪音了，除去这些高频信号，然后通过逆变换就可以得到处理后的音频。</p><p>在声音中，那刚才的傅里叶变换之前的x轴就是时间，y轴就是声音的振幅</p><p>如下图（copy from 知乎Heinrich）</p><p><img src="https://cdn.jsdelivr.net/gh/CallMe-star/picbed@master/fuliye1.jpg"></p><h4 id="图像"><a href="#图像" class="headerlink" title="- 图像"></a>- 图像</h4><p>通过分析频率域，他的低频部分可能就是画像的主体部分，高频部分可能是图像中的噪点，比如说是画面中的斑点噪音，旧照片中的斑点，通过去掉高频信号，然后逆变换回去，就得到去除噪点之后的图像。</p><p>在图像中，傅里叶变换之前的x轴就是图像的空间坐标位置，y轴就是他的灰度？？？</p><h3 id="5-OpenCV-，Numpy中操作一下"><a href="#5-OpenCV-，Numpy中操作一下" class="headerlink" title="5.OpenCV ，Numpy中操作一下"></a>5.OpenCV ，Numpy中操作一下</h3><h4 id="numpy中操作"><a href="#numpy中操作" class="headerlink" title="-numpy中操作"></a>-numpy中操作</h4><ol><li><p>np.fft.fft2</p><p>实现傅里叶变换并且返回一个复数数组</p></li><li><p>np.fft.fftshift</p><p>将零频率分量移动到频谱的中心</p></li><li><p>np.log（np.abs(fshift)）</p><p>刚才返回的复数数组没办法用图像的形式展示出来需要用以上函数转换到[0, 255]范围</p></li><li><p>np.fft.ifftshift</p><p>把中心化的频谱再移动回左上角</p></li><li><p>np.fft.ifft2</p><p>实现逆变换，返回一个复数数组</p></li><li><p>np.abs（逆傅里叶变换的结果）</p></li></ol><p>​        变回能显示的[0, 255]的可显示图像</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 直接读为灰度图像</span></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;你电脑本地的图像路径&#x27;</span>, <span class="number">0</span>)  </span><br><span class="line">f = np.fft.fft2(img)</span><br><span class="line">fshift = np.fft.fftshift(f)</span><br><span class="line"><span class="comment"># 取绝对值：将复数变化成实数</span></span><br><span class="line"><span class="comment"># 取对数的目的为了将数据变化到0-255</span></span><br><span class="line">s1 = np.log(np.abs(fshift))</span><br><span class="line">plt.subplot(<span class="number">131</span>), plt.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>, interpolation=<span class="string">&#x27;bicubic&#x27;</span>), plt.title(<span class="string">&#x27;original&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">132</span>), plt.imshow(s1, <span class="string">&#x27;gray&#x27;</span>, interpolation=<span class="string">&#x27;bicubic&#x27;</span>), plt.title(<span class="string">&#x27;center&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line"><span class="comment"># 逆变换</span></span><br><span class="line">f1shift = np.fft.ifftshift(fshift)</span><br><span class="line">img_back = np.fft.ifft2(f1shift)</span><br><span class="line"><span class="comment"># 出来的是复数，无法显示</span></span><br><span class="line">img_back = np.abs(img_back)</span><br><span class="line">plt.subplot(<span class="number">133</span>), plt.imshow(img_back, cmap=<span class="string">&#x27;gray&#x27;</span>, interpolation=<span class="string">&#x27;bicubic&#x27;</span>), plt.title(<span class="string">&#x27;img back&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h4 id="OpenCV中操作"><a href="#OpenCV中操作" class="headerlink" title="OpenCV中操作"></a>OpenCV中操作</h4><ol><li><p>返回结果 = cv2.dft(原始图像， 转换标识)</p><p>返回结果是双通道的，第一通道是结果的实数部分，第二通道是虚数部分</p><p>原始图像一般是整型八位位图，要转换成32位的（np.float32(img)）</p><p>转换标识一般flags = cv2.DFT_COMPLEX_OUTPUT,输出一个复数阵列</p></li><li><p>np.fft.fftshift</p><p>将零频率分量转换频谱中心</p></li><li><p>返回值 =  cv2.magnitude（参数1，参数2）</p><p>参数1：浮点的X坐标，也就是实部</p><p>参数2：浮点的Y坐标，也就是虚部</p><p>通过这个函数，将那个复数转换到[0, 255]</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;电脑本地的图像地址&#x27;</span>， <span class="number">0</span>)</span><br><span class="line">dft = cv2.dft(np.float32(img), flags = cv2.DFT_COMPLEX_OUTPUT)</span><br><span class="line">dftshift = np.fft.fftshift(dft)</span><br><span class="line">result = <span class="number">20</span>*np.log(cv2.magnitude(dftshift[:,:,<span class="number">0</span>], dftshift[:,:,<span class="number">1</span>]))</span><br><span class="line">ishift = np.fft.ifftshift(dftshift)</span><br><span class="line">iimg = cv2.idft(ishift)</span><br><span class="line">iimg = cv2.magnitude(iimg[:, :, <span class="number">0</span>], iimg[:, :, <span class="number">1</span>])</span><br><span class="line">plt.subplot(<span class="number">221</span>), plt.imshow(img,<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;img&#x27;</span>), plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">222</span>), plt.imshow(result,<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;result&#x27;</span>), plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">223</span>), plt.imshow(img, <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;img&#x27;</span>), plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">224</span>), plt.imshow(iimg, <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;result&#x27;</span>), plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="低通滤波"><a href="#低通滤波" class="headerlink" title="低通滤波"></a>低通滤波</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;/Users/star/learning_python/picture/2.png&#x27;</span>, <span class="number">0</span>)</span><br><span class="line">dft = cv2.dft(np.float32(img), flags=cv2.DFT_COMPLEX_OUTPUT)</span><br><span class="line">dshift = np.fft.fftshift(dft)</span><br><span class="line">rows, cols = img.shape</span><br><span class="line">row, col = int(rows/<span class="number">2</span>), int(cols/<span class="number">2</span>)</span><br><span class="line">mask = np.zeros((rows, cols, <span class="number">2</span>), np.uint8)</span><br><span class="line">mask[row<span class="number">-50</span>:row+<span class="number">50</span>, col<span class="number">-50</span>:col+<span class="number">50</span>] = <span class="number">1</span></span><br><span class="line">dst = dshift * mask</span><br><span class="line">idst = np.fft.ifftshift(dst)</span><br><span class="line">ishift = cv2.idft(idst)</span><br><span class="line">idst = cv2.magnitude(ishift[:, :, <span class="number">0</span>], ishift[:, :, <span class="number">1</span>])</span><br><span class="line">plt.subplot(<span class="number">121</span>), plt.imshow(img, <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;img&#x27;</span>), plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">122</span>), plt.imshow(idst, <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;img&#x27;</span>), plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h4 id="高通滤波"><a href="#高通滤波" class="headerlink" title="高通滤波"></a>高通滤波</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;电脑本地的图像地址&#x27;</span>， <span class="number">0</span>)</span><br><span class="line">f = np.fft.fft2(img)</span><br><span class="line">fshift = np.fft.fftshift(f)        </span><br><span class="line">rows,cols = img.shape[:<span class="number">2</span>]</span><br><span class="line">crow,ccol = int(rows/<span class="number">2</span>), int(cols/<span class="number">2</span>)</span><br><span class="line">fshift[crow<span class="number">-30</span>:crow+<span class="number">30</span>, ccol<span class="number">-30</span>:ccol+<span class="number">30</span>] = <span class="number">0</span></span><br><span class="line">ishift = np.fft.ifftshift(fshift)</span><br><span class="line">iimg = np.fft.ifft2(ishift)</span><br><span class="line">iimg = np.abs(iimg)</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(img, <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;img&#x27;</span>),plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">122</span>),plt.imshow(iimg, <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;iimg&#x27;</span>),plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 图像处理笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图像处理笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>学习java第三天——语言类型</title>
      <link href="/2020/08/10/%E5%AD%A6%E4%B9%A0java%E7%AC%AC%E4%B8%89%E5%A4%A9%E2%80%94%E2%80%94%E8%AF%AD%E8%A8%80%E7%B1%BB%E5%9E%8B/"/>
      <url>/2020/08/10/%E5%AD%A6%E4%B9%A0java%E7%AC%AC%E4%B8%89%E5%A4%A9%E2%80%94%E2%80%94%E8%AF%AD%E8%A8%80%E7%B1%BB%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<blockquote><span class='p red'>认识各种语言的类型</span></blockquote><a id="more"></a><h2 id="解释型语言"><a href="#解释型语言" class="headerlink" title="解释型语言"></a>解释型语言</h2><p>解释型语言的典型：python、JavaScript、Ruby等。</p><p>解释型语言的特点，我理解的就是解释一句跑一句子，如果下边语句有错误，并不会影响上边语句的执行。要想写小的程序，基本上可以忽略执行效率的基础上，还想让程序能成功跑下去，解释型语言还是很香的。</p><h2 id="编译型语言"><a href="#编译型语言" class="headerlink" title="编译型语言"></a>编译型语言</h2><p>编译型语言的典型：C和C++等</p><p>汇编型语言的特点，我理解的就是把所有语句都从头理一遍，如果其中出现一句语句有错误，整个程序都无法运行。所以要想提高程序的执行效率，要想写大工程文件，还是要转换成编译型语言的。</p><h2 id="编译型—解释型语言"><a href="#编译型—解释型语言" class="headerlink" title="编译型—解释型语言"></a>编译型—解释型语言</h2><p>典型代表:Java</p><p>严格地说，Java其实就是解释型语言，其所谓的编译过程只是将.java文件编程成.class文件，并不是向C一样编译成可执行的机器语言，在此请读者注意Java中所谓的“编译”和传统的“编译”的区别；然后生成的.class文件再逐句进行解释，在Java的虚拟机JVM中运行。在现实中，java开发工具JDK提供了两个很重要的命令来完成上面的编译和解释（翻译）过程：javac.exe是将.java文件编译成.class文件，而java.exe是将.class文件解释执行吧</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>解释器与编译器两者各有优势：当程序需要迅速启动和执行的时候，解释器可以首先发挥作用，省去编译的时间，立即执行。在程序运行后，随着时间的推移，编译器逐渐发挥作用，把越来越多的代码编译成本地代码之后，可以获取更高的执行效率。 当程序运行环境中内存资源限制较大（如部分嵌入式系统中），可以使用解释执行节约内存，反之可以使用编译执行来提升效率。</p><p>但随着硬件的升级和设计思想的变革，编译型和解释型语言越来越笼统，主要体现在一些新兴的高级语言上，而解释型语言的自身特点也使得编译器厂商愿意花费更多成本来优化解释器，解释型语言性能超过编译型语言也是必然的。</p>]]></content>
      
      
      <categories>
          
          <category> java笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>学习java第二天——终端命令</title>
      <link href="/2020/08/06/%E5%AD%A6%E4%B9%A0Java%E7%AC%AC%E4%BA%8C%E5%A4%A9%E2%80%94%E2%80%94%E7%BB%88%E7%AB%AF%E5%91%BD%E4%BB%A4/"/>
      <url>/2020/08/06/%E5%AD%A6%E4%B9%A0Java%E7%AC%AC%E4%BA%8C%E5%A4%A9%E2%80%94%E2%80%94%E7%BB%88%E7%AB%AF%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<blockquote><p>记录下我常用基本终端命令</p></blockquote><a id="more"></a><h3 id="Dos和Linux的常用命令"><a href="#Dos和Linux的常用命令" class="headerlink" title="Dos和Linux的常用命令"></a>Dos和Linux的常用命令</h3><h4 id="Dos命令——我用的windows"><a href="#Dos命令——我用的windows" class="headerlink" title="Dos命令——我用的windows"></a>Dos命令——我用的windows</h4><ol><li><p>从默认的C盘切换到D盘或者其他盘符</p><p>命令：D:</p></li><li><p>磁盘操作，进入盘符下的文件夹</p><p>命令：cd + 文件夹名称</p></li><li><p>查看当前文件夹里面有哪些目录或者文件</p><p>命令：dir</p></li><li><p>显示当前文件夹</p><p>命令：chdir</p></li><li><p>返回上一级目录</p><p>命令：cd ..</p></li><li><p>创建文件夹</p><p>命令：mkdir</p></li><li><p>创建文件</p><p>命令：cd.&gt;a.txt</p></li><li><p>显示网络设置</p><p>命令：ipconfig</p></li><li><p>清屏</p><p>命令：cls</p></li></ol><h4 id="Linux命令——我用的mac"><a href="#Linux命令——我用的mac" class="headerlink" title="Linux命令——我用的mac"></a>Linux命令——我用的mac</h4><ol><li><p>从默认的C盘切换到D盘或者其他盘符</p><p>命令：D:</p></li><li><p>磁盘操作，进入盘符下的文件夹</p><p>命令：cd + 文件夹名称</p></li><li><p>查看当前文件夹里面有哪些目录或者文件</p><p>命令：ls</p></li><li><p>显示当前文件夹</p><p>命令：pwd</p></li><li><p>返回上一级目录</p><p>命令：cd ..</p></li><li><p>创建文件夹</p><p>命令：mkdir</p></li><li><p>创建文件</p><p>命令：touch a.txt</p></li><li><p>显示网络设置</p><p>命令：ifconfig</p></li><li><p>清屏</p><p>命令：clear</p></li></ol><hr><p>上边都是些基本入门常用的命令，用到其余的可以再找^-^</p><p>通过cd命令和dir命令（mac下的ls命令），基本上就可以在终端自由访问文件夹了。</p><p>如果嫌弃文件或者文件夹名称过长，可以通过tab键来自动补全。</p>]]></content>
      
      
      <categories>
          
          <category> java笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>学习java第一天——markdown基础</title>
      <link href="/2020/08/06/%E5%AD%A6%E4%B9%A0Java%E7%AC%AC%E4%B8%80%E5%A4%A9%E2%80%94%E2%80%94markdown%E5%9F%BA%E7%A1%80/"/>
      <url>/2020/08/06/%E5%AD%A6%E4%B9%A0Java%E7%AC%AC%E4%B8%80%E5%A4%A9%E2%80%94%E2%80%94markdown%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<blockquote><span class='p yellow'>本人是一个跨考生，本科学习的农学，现在研究生跨入了计算机专业，因为底子比较薄，所以想通过看一些课程，在博客上自己记录一下学习历程，以便于督促自己。</span></blockquote><a id="more"></a><h1 id="markdown基础"><a href="#markdown基础" class="headerlink" title="markdown基础"></a>markdown基础</h1><h2 id="一-标题"><a href="#一-标题" class="headerlink" title="一.标题"></a>一.标题</h2><p>##+space+内容</p><h3 id="三级标题"><a href="#三级标题" class="headerlink" title="三级标题"></a>三级标题</h3><p>###+space+内容</p><h4 id="四级标题"><a href="#四级标题" class="headerlink" title="四级标题"></a>四级标题</h4><p>####+space+内容</p><h2 id="二-字体"><a href="#二-字体" class="headerlink" title="二.字体"></a>二.字体</h2><p><strong>hello，java</strong>            ** + 内容 + **</p><p><em>hello，java</em>                * + 内容 + *</p><p><del>hello，java</del>             <del>~ + 内容 + ~</del></p><p><strong><em>hello，java</em></strong>            ** *  +   内容   + ** *</p><h2 id="三-引用"><a href="#三-引用" class="headerlink" title="三.引用"></a>三.引用</h2><blockquote><p>学习java第一天，认认真真记笔记！</p><p>‘&gt;’ + space + 内容</p></blockquote><h2 id="四-分割线"><a href="#四-分割线" class="headerlink" title="四.分割线"></a>四.分割线</h2><hr><p>键盘输入“—”，也就是三个减号就可以了</p><p>或者也可以用三个星号，“***”</p><p>##　五.图片</p><p><img src="https://ss0.bdstatic.com/94oJfD_bAAcT8t7mm9GUKT-xh_/timg?image&quality=100&size=b4000_4000&sec=1596721861&di=2eb592e5a35f908fb45fd4b25ad82e17&src=http://a1.att.hudong.com/05/00/01300000194285122188000535877.jpg" alt="截图"></p><p>先输入“!” + 英文状态下的“[ ]” + 图片的网络地址或者本地地址</p><h2 id="六-超链接"><a href="#六-超链接" class="headerlink" title="六.超链接"></a>六.超链接</h2><p><a href="https://www.csdn.net/">超链接</a></p><p>先输入“[ ]”+ “( )”在括号里面放要链接的网址就可以了</p><h2 id="七-列表"><a href="#七-列表" class="headerlink" title="七.列表"></a>七.列表</h2><ol><li>第一个</li><li>第二个</li><li></li></ol><p>这个就是直接写“1” + “.” + space</p><h3 id="无序列表"><a href="#无序列表" class="headerlink" title="无序列表"></a>无序列表</h3><ul><li>第一个</li><li>第二个</li></ul><p>输入“-”减号 + space</p><h2 id="八-表格"><a href="#八-表格" class="headerlink" title="八.表格"></a>八.表格</h2><ol><li><p>右键插入</p></li><li><p>代码形式</p><table><thead><tr><th>姓名</th><th>性别</th><th>年龄</th></tr></thead><tbody><tr><td>小明</td><td>男</td><td>18</td></tr><tr><td></td><td></td><td></td></tr></tbody></table><p>mac下：输入        |名字|性别|生日|          即可</p><p>win下：输入         |名字|性别|生日|</p></li></ol><p>​                                      |–|–|–|</p><p>​                                       |小明|男|18|                然后回车 </p><h2 id="九-代码"><a href="#九-代码" class="headerlink" title="九.代码"></a>九.代码</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> hello;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">world</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Hello, world!&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输入“···” + “语言名称”，就会出现代码框了</p><ul><li>其中的点 在键盘按键上的 Esc 的下边</li><li>语言名称指的是“java”，”c“，”python“等</li></ul>]]></content>
      
      
      <categories>
          
          <category> java笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java笔记 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
